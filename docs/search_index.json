[["index.html", "Ciencia Social Abierta Presentación", " Ciencia Social Abierta 04 octubre 2021 Presentación "],["introducción.html", "Capítulo 1 Introducción", " Capítulo 1 Introducción Este trabajo se trata de "],["diseño-transparente.html", "Capítulo 2 Diseño transparente", " Capítulo 2 Diseño transparente Uno de los principios que guía el quehacer científico es el escepticismo organizado (Merton, 1973). Ningún hallazgo se acepta porque sí, sino que los científicos deben demostrarle a otros miembros de la comunidad científica que sus hallazgos son válidos. En orden de lograr esto es que se han desarrollado varios tipos de herramientas como los indicadores de impacto, la revisión por pares o las convenciones para el reporte de análisis estadístico. Sin embargo, casos como los de Diderik Stapel han dejado al descubierto que este tipo de herramientas pueden no ser suficientes para asegurar la credibilidad de los hallazgos científicos. Diderik Stapel fue un investigador en el campo de la psicología social. Su carrera se caracterizó por una trayectoria ejemplar: entre 1995 y 2015 publicó aproximadamente 150 artículos en revistas científicas, algunas de las más prestigiosas (e.g. Science). También, fue galardonado con el premio a la trayectoria académica por la Sociedad de Psicología Social Experimental (SSEP, por sus siglas en inglés). Stapel llegó a ser una figura reconocida en su área, sin embargo, todo cambió el año 2011 cuando se confirmó que gran parte de sus artículos contenían datos inventados. La investigación final de su caso determinó que más de 50 de sus artículos eran fraudulentos (Carey, 2011). De hecho, Stapel figura dentro de los diez investigadores con más artículos retractados (58) en Retraction Watch, una plataforma que se dedica a sistematizar y mantener una lista actualizada sobre retracciones de artículos. A efectos de este escrito, lo más destacable es que Stapel cometió mala conducta académica durante más de 15 años. ¿Cómo fue esto posible? ¿cómo ninguno de sus colegas, alumnos o coautores se dio cuenta de sus malas prácticas? La respuesta tiene que ver con el concepto central de este capítulo: por la falta de transparencia durante el proceso de investigación. Stapel se caracterizaba por hacer el trabajo solo y a puertas cerradas, es decir, nadie más que él tenía acceso a los datos brutos, ni tampoco a la ejecución de las pruebas estadísticas. Generalmente, sólo compartía con sus colegas los datos procesados y con los análisis ya efectuados. A raíz de esta forma de trabajo es que se abría la oportunidad para que Stapel inventara datos a su conveniencia. Como nadie más colaboraba con el procesamiento de datos, ni tampoco parecía extraño que así fuera, Stapel pudo sostener una trayectoria académica destacable en base a la falta de transparencia. El ejemplo de Stapel es solo una forma de poner en discusión la importancia de la transparencia en el proceso de investigación. Siguiendo esta línea, este capítulo busca presentar una primera aproximación, tanto teórica como práctica, sobre la transparencia en la investigación social. El objetivo es que investigadoras e investigadores de las ciencias sociales empíricas se introduzcan en la temática de la transparencia, así como también que conozcan las principales herramientas que se están utilizando para adoptarla. Referencias "],["sobre-la-transparencia.html", "2.1 Sobre la transparencia", " 2.1 Sobre la transparencia La transparencia es un concepto multidimensional. Elliott (2020) propone entender la transparencia en torno a cuatro preguntas: ¿por qué?, ¿quién? ¿qué? y ¿cómo? (ver Figura N° 2.1). Cada una de estas preguntas se relaciona a una dimensión. La primera pregunta (¿por qué?) se refiere a las razones y propósitos por los cuales es necesario adoptar la transparencia; la segunda pregunta (¿quién?) apunta a la audiencia que está recibiendo la información; la tercera pregunta (¿qué?) hace alusión al contenido que es transparentado y la cuarta pregunta (¿cómo?) consiste en cuatro dimensiones distintas sobre cómo adoptar la transparencia: actores, mecanismos, tiempo y espacios. También, esta taxonomía estipula una dimensión sobre las amenazas que podrían afectar a las iniciativas que busquen promover la transparencia. A raíz de estas dimensiones podemos comprender qué tipo de prácticas y situaciones caben dentro del concepto de transparencia. Figura 2.1: Taxonomía de Transparencia Basándonos en esta taxonomía, presentaremos una propuesta sobre qué se entiende por transparencia en las ciencias sociales y cómo podemos adquirir prácticas orientadas a este principio. Nuestra propuesta es entender la transparencia como la apertura pública del diseño de investigación, lo que incluye todo tipo de información importante para la ejecución del estudio, desde las hipótesis hasta el plan de análisis. Esto permitirá que las personas que lean los hallazgos de investigación (ya sean científicos o la ciudadanía) puedan evaluar la credibilidad de estos y descartar la influencia de prácticas cuestionables de investigación. Para llevar a la práctica esta propuesta, presentaremos la elaboración de preregistros como una de las principales herramientas que contribuyen a hacer público el diseño, además de otras que complementan su uso. Referencias "],["por-qué.html", "2.2 ¿Por qué?", " 2.2 ¿Por qué? La pregunta del por qué es necesario avanzar hacia la transparencia encuentra su respuesta en la existencia de prácticas de investigación que merman la credibilidad de los hallazgos científicos. A modo de entender qué es lo problemático de ciertas prácticas, es que Steneck (2006) propone el concepto de Conducta Responsable de Investigación (RCR, por sus siglas en inglés) como un ideal que engloba prácticas éticas e íntegras dentro de la investigación científica (ver Figura N° 2.2). Según este autor, la distinción entre la ética y la integridad recae en que la primera tiene que ver con seguir principios morales dentro de la investigación (e.g. usar consentimientos informados), en cambio, la segunda está más relacionada con el seguimiento de códigos de conductas y estándares profesionales (Abril Ruiz, 2019). Figura 2.2: Conducta Responsable de Investigación. Imagen de Abril Ruiz (2019) basada en Steneck (2006) Las prácticas de investigación se pueden evaluar en un continuo que representa cuánto adhieren los investigadores a los principios de integridad científica (Steneck, 2006). La Figura N° 2.3 esquematiza esta idea mostrando dos extremos, donde a la izquierda está el mejor comportamiento (RCR) y a la derecha el peor comportamiento (FFP). Las FFP son una abreviación en lengua inglesa para referirse a Fabrication, Falsification, Plagiarism (Invención, Falsificación y Plagio), también conocidas como mala conducta académica. En el medio del continuo están las prácticas cuestionables de investigación (QRP, por sus siglas en inglés) las cuales refieren a las acciones que violan los valores tradicionales de la empresa de investigación y que pueden ser perjudiciales para el proceso de investigación (National Academies of Science 1992 en Steneck, 2006, p. 58). Las QRP se caracterizan porque tienen el potencial de dañar la ciencia, en tanto las FFP la dañan directamente. Figura 2.3: Gradación del comportamiento integro en investigación. Imagen de Abril Ruiz (2019) basada en Steneck (2006) La mala conducta académica implica la violación de los principios de integridad científica. Esto se relaciona con el falseamiento de datos de cualquier forma: invención de datos, alteración de gráficos o tablas, entre otros. El caso de Diderik Stapel presentado en la introducción de este capítulo es un ejemplo que cabe dentro del concepto de mala conducta académica. Según la literatura, la prevalencia de este tipo de prácticas no es alta (e.g. Fanelli, 2009; John et al., 2012), sino que más bien son casos aislados (ver Abril Ruiz, 2019, pp. 23-128 para una revisión). En contraste, las QRP han demostrado ser más prevalentes. 2.2.1 Prácticas cuestionables de investigación (QRP) Existen una serie de estudios que han intentado medir directamente la prevalencia de estas prácticas a través de encuestas. Fanelli (2009) hizo un metaanálisis que tenía por objetivo sistematizar los resultados de estudios que hasta esa fecha habían abordado las prácticas de investigación desde encuestas cuantitativas. Los resultados mostraron que un 1.97% de investigadores había inventado datos al menos una vez (FFP) y que un 33.7% había realizado alguna vez una QRP como borrar puntos de los datos basados en un sentimiento visceral. Unos años más tarde, John et al. (2012) efectuaron otro estudio similar, demostrando que un 36.6% de quienes participaron alguna vez habían practicado alguna QRP. En detalle, analizando los porcentajes práctica a práctica los resultados muestran que el 50% de los psicólogos encuestados alguna vez reportaron selectivamente estudios que apoyaran sus hipótesis; un 35% alguna vez reportaron resultados inesperados como esperados; y un 2% alguna vez reportó datos falsos. Este estudio ha sido replicado en Italia (Agnoli et al., 2017), en Alemania (Fiedler &amp; Schwarz, 2016) y en Brasil (Rabelo et al., 2020). Más recientemente, han emergido estudios similares en otras áreas disciplinarias. Por ejemplo, a través de encuestas online Makel et al. (2021) logran constatar que existe una prevalencia considerable de las QRP en el campo de investigación educacional. De los participantes de la muestra, un 10% admitió haber rellenado datos faltantes (NAs) y un 67% señaló alguna vez haber omitido ciertos análisis de manera intencional. Siguiendo el mismo método, en el campo de la investigación comunicacional se ha encontrado evidencia parecida: 9% de los encuestados señala haber imputado datos faltantes sin reportarlo, un 34% declaró alguna vez haber excluido casos extremos de forma arbitraria y un 60% señala no haber reportado análisis con variables clave que no funcionaron. Del mismo modo, en los estudios cuantitativos sobre criminología existe un uso extendido de las QRP: un 87% de la muestra de Chin et al. (2021) ha utilizado múltiples QRP, siendo el reporte selectivo de resultados el más común (53%). Por último, fuera del área de las ciencias sociales, pero siguiendo la misma línea, Fraser et al. (2018) también encuentran evidencia a favor de la existencia de distintas QRP en el campo de la ecología y evolución. Los estudios mencionados arriba corresponden a la evidencia existente sobre la medición de QRP a través de encuestas. A modo de resumen, la Tabla N° 2.1 adaptada del trabajo de Chin et al. (2021) agrupa la información que hemos revisado (y más), ordenándose por prácticas, campos de estudio y los artículos correspondientes a cada campo de estudio. Los números dentro de las casillas representan el porcentaje de prevalencia de cada práctica reportado por los participantes del estudio, y entre paréntesis el número de casos de la muestra. Los guiones significan que este estudio no incluyó esa práctica en el cuestionario. Tabla 2.1: Porcentajes de prevelanecia por QRP según distintos trabajos.. Práctica Psicología Psicología Psicología Ecología Evolución Educación Comunicación John et al. (2012) Agnoli et al. (2017) Rabelo et al. (2020) Fraser et al. (2018) Fraser et al. (2018) Makel et al. (2021) Bakker et al. (2020) Omitir estudios o variables ni significativas 46 (485) 40 (217) 55 (232) - - 62 (783) 60 Subreportar resultados 63 (486) 48 (219) 22 (232) 64 64 67 (871) 64 Subreportar condiciones 28 (484) 16 (219) 35 (232) - - - - Muestreo selectivo 56 (490) 53 (221) 22 (232) 37 51 29 (806) 23 Excluir datos selectivamente 38 (484) 40 (219) 20 (232) 24 24 25 (806) 34 Excluir covariables selectivamente - - - - - 42 (773) 46 Cambiar análisis selectivamente - - - - - 50 (811) 45 HARK 27 (489) 37 (219) 9 (232) 49 54 46 (880) 46 Redondear valores p 22 (499) 22 (221) 18 (232) 27 18 29 (806) 24 Mal orientar respecto a los efectos de sociodemográficos 3 (499) 3 (223) 4 (232) - - - - Esconder problemas - - - - - 24 (889) - Esconder imputaciones 1 (495) 2 (220) 1 (232) 5 2 10 (898) 9 Como se observa en la Tabla N° 2.1, las encuestas sobre QRP han incluido varias prácticas relativas al tratamiento y análisis de los datos. No obstante, consideramos que existen tres términos que, en su mayoría, logran sintetizar esta tabla y que están relacionados a la transparencia en los diseños de investigación. Estas son: 1) los sesgos de publicación, 2) el p-hacking y el 3) HARKing. Sesgo de publicación El sesgo de publicación ocurre cuando el criterio determinante para que un artículo sea publicado es que sus resultados sean significativos, en desmedro de la publicación de resultados no significativos. Un ejemplo ilustrativo que usan Christensen et al. (2019) para explicar esta práctica es el cómic xkcd titulado Significant. Este cómic (Figura N 2.4) muestra cómo es que un hallazgo de investigación sufre del sesgo de publicación. Al publicarse únicamente el resultado significativo e ignorándose los otros 19 no significativos, cualquier lector tendería a pensar que efectivamente las gominolas verdes causan acné, cuando probablemente sea una coincidencia. El trabajo de Rosenthal (1979) fue de los primeros en llamar la atención respecto de esta práctica, adjudicando el concepto de file drawer problem (en español: problema del cajón de archivos), el que hace alusión a los resultados que se pierden o quedan archivados dentro de un cuerpo de literatura. Desde ese estudio en adelante varios autores han contribuido con evidencia empírica sobre el sesgo de publicación. Por ejemplo, el estudio de Franco et al. (2014) logra cuantificar esta situación encontrando que los resultados nulos tienen un 40% menos de probabilidades de ser publicados en revistas científicas, en comparación a estudios con resultados significativos. Es más, muchas veces los resultados nulos ni siquiera llegan a ser escritos: más de un 60% de los experimentos que componen la muestra del estudio de Franco et al. (2014) nunca llegaron a ser escritos, en contraste con el 10% de resultados significativos. Figura 2.4: Comic Significant de xkcd El principal problema del sesgo de publicación es que puede impactar en la credibilidad de cuerpos enteros de literatura. Por ejemplo, en economía se han hecho varios metaanálisis que han buscado estimar el sesgo de publicación en distintos cuerpos de literatura (e.g. Brodeur et al., 2016; Viscusi, 2014; Vivalt, 2015). Uno de los trabajos más concluyentes es el de Doucouliagos &amp; Stanley (2013), quienes efectúan un metaanálisis de 87 artículos de metaanálisis en economía. En este trabajo encuentran que más de la mitad de los cuerpos de literatura revisados sufren de un sesgo sustancial o severo. Si bien en economía se ha avanzado mucho en este tipo de estudios, también a partir del desarrollo de distintos métodos de detección, se ha podido diagnosticar el sesgo de publicación en importantes revistas en sociología y ciencias políticas (A. Gerber &amp; Malhotra, 2008; A. S. Gerber &amp; Malhotra, 2008). P-hacking Otra práctica bastante cuestionada es el p-hacking. El p-hacking suele englobar muchas de las prácticas que vimos en un inicio, especialmente las que refieren al manejo de datos: excluir datos arbitrariamente, redondear un valor p, recolectar más datos posterior a hacer pruebas de hipótesis, entre otras. Lo que tienen todas estas prácticas en común y lo que define el p-hacking es que se da cuando el procesamiento de los datos tiene por objetivo obtener resultados significativos. Si el sesgo de publicación afecta la credibilidad de un cuerpo de literatura, el p-hacking afecta a la credibilidad de los artículos mismos, ya que al forzar la significancia estadística la probabilidad de que en realidad estemos frente a un falso positivo aumenta. Un trabajo que da sustento a esta idea es el de Simmons et al. (2011), quienes calculan la posibilidad de obtener un falso positivo (error Tipo I) de acuerdo con el nivel de grados de libertad que son utilizados por parte de los investigadores. El resultado principal es que a medida que aumenta el uso de grados de libertad, la posibilidad de obtener un falso positivo aumenta progresivamente. El p-hacking también contribuye a sesgar cuerpos enteros de literatura. Para diagnosticar esto se ha utilizado una herramienta denominada p-curve, la cual describe la densidad de los p-values reportados en una literatura, aprovechando el hecho de que si la hipótesis nula no se rechaza (es decir, sin efecto), los p-values deben distribuirse uniformemente entre 0 y 1 (Christensen et al., 2019, p. 67.). De esta manera, en cuerpos de literatura que no sufran de p-hacking, la distribución de valores p debería estar cargada a la izquierda (siendo precisos, asimétrica a la derecha), en cambio, si existe sesgo por p-hacking la distribución de p-values estaría cargada a la derecha (asimetría a la izquierda). Simonsohn et al. (2014) proponen esta herramienta y la prueban en dos muestras de artículos de la Journal of Personality and Social Psychology (JPSP). Las pruebas estadísticas consistieron en confirmar que la primera muestra de artículos (que presentaban signos de p-hacking) estaba sesgada, en cambio la segunda muestra (sin indicios de p-hacking), no lo estaba. Los resultados corroboraron las hipótesis, esto es: los artículos que presentaban solamente resultados con covariables resultaron tener una p-curve cargada a la derecha (asimétrica a la izquierda). HARKing Por último, pero no menos importante, está la práctica del HARKing. El nombre es una nomenclatura en lengua inglesa: Hypothesizing After the Results are Known, que literalmente significa establecer las hipótesis del estudio una vez que se conocen los resultados (Kerr, 1998). El principal problema de esta práctica es que confunde los dos tipos de razonamiento que están a la base de la ciencia: el exploratorio y el confirmatorio. El objetivo principal del razonamiento exploratorio es plantear hipótesis a partir del análisis de los datos, en cambio, el razonamiento confirmatorio busca plantear hipótesis basado en teoría y contrastar esas hipótesis con datos empíricos. Como señala Nosek et al. (2018), cuando se confunden ambos tipos de análisis y se hace pasar un razonamiento exploratorio como confirmatorio se está cometiendo un sesgo inherente, ya que se está generando un razonamiento circular: se plantean hipótesis a partir del comportamiento de los datos y se confirman las hipótesis con esos mismos datos Referencias "],["qué-y-quién.html", "2.3 ¿Qué? y ¿Quién?", " 2.3 ¿Qué? y ¿Quién? Preguntarse por el qué es básicamente cuestionarse sobre lo que se está poniendo a disposición del escrutinio público. Dentro de la literatura sobre ciencia abierta, son varios los contenidos que pueden ser transparentados. Por ejemplo, la apertura de los datos es una alternativa que, ciertamente, contribuye a hacer un estudio más transparente (Miguel et al., 2014). Al estar los datos abiertos al público, la posibilidad de escrutinio por parte de las audiencias es mayor. Otro ejemplo es la idea de disclosure, la cual se refiere a la declaración que hacen los investigadores respecto a si la investigación cuenta con conflictos de interés o si está sesgada de alguna manera. En base a esta idea, recientemente han emergido propuestas cómo las de OBoyle et al. (2017) que, además de la declaración de conflicto interés, llaman a adoptar declaraciones relacionadas a las QRP. Básicamente declarar si se ha cometido QRP o no durante el transcurso de la investigación. No obstante, la apertura pública de los diseños de investigación es, sin duda, la práctica que mejor representa la transparencia en el último tiempo. Como hemos revisado anteriormente, existe una emergente preocupación en las ciencias sociales respecto a la credibilidad de los hallazgos científicos y la influencia que pueden tener las QRP. En disciplinas como la psicología la apertura de los diseños de investigación ha sido la principal herramienta ante el diagnóstico que una parte considerable de los hallazgos eran irreproducibles o irreplicables (Camerer et al., 2018; Motyl et al., 2017; Wingen et al., 2020). Ante un diagnóstico similar en sociología (Breznau et al., 2021), en ciencias de la gestión (Byington &amp; Felps, 2017) y en economía (Gall et al., 2017), por dar algunos ejemplos, también se ha reconocido la apertura del diseño de investigación como una herramienta importante para avanzar hacia la transparencia. A razón de esto, es que nuestra propuesta se focaliza en la apertura de los diseños de investigación y el uso de preregistros. Además de preguntarse por los contenidos que se transparentan, también es relevante hacer un alcance respecto al quién. Esto es tener en consideración quiénes van a recibir la información que sea transparentada. En principio, los hallazgos de la investigación científica son un bien público -o están pensados para serlo-. Si bien en algunos países o áreas especificas del conocimiento el financiamiento de la ciencia es por parte de privados, la investigación en ciencias sociales en Chile se financia con los impuestos de los habitantes. Organismos como la Agencia Nacional de Investigación y Desarrollo de Chile (ANID), quienes están encargados de la administración de fondos para la ciencia, tienen un rol público, por lo que los hallazgos no solo sirven para alimentar el avance del conocimiento dentro de la academia, sino que también son insumos relevantes para los tomadores de decisiones y/o para cualquier ciudadano que se podría beneficiar de esos hallazgos. En consiguiente, cualquier tipo de información que sea transparente es un insumo más para que distintos tipos de audiencias puedan beneficiarse de hallazgos más creíbles y robustos. Ya sean investigadores, tomadores de decisión o la ciudadanía. Referencias "],["cómo.html", "2.4 ¿Cómo?", " 2.4 ¿Cómo? Una buena forma de introducir el cómo adoptar la transparencia son las Transparency and Openess Promotion (TOP) Guidelines (Guías para la Promoción de la Transparencia y la Accesibilidad). Las TOP Guidelines son una iniciativa del Centro para la Ciencia Abierta (COS, por sus siglas en inglés) que busca fomentar la ciencia abierta a partir de la adopción de distintos principios. Su objetivo es que tanto los investigadores como las revistas científicas adhieran a prácticas transparentes. Los principios van desde temas de citación, hasta la replicabilidad (ver el detalle sobre esta propuesta en https://osf.io/9f6gx/). Si bien esta es una iniciativa que incluye principios que escapan del enfoque de este capítulo, es un buen punto de partida ya que permite situar la transparencia en el diseño de investigación y el uso de preregistros como parte de una red de principios más grandes a instalar en la ciencia. Además, permite dar cuenta que ya existe un conjunto de actores preocupados por temáticas de ciencia abierta, que han reconocido la transparencia en los diseños de investigación como un principio importante por adoptar. En lo que sigue, revisaremos cómo los preregistros logran fomentar la transparencia en los diseños de investigación. 2.4.1 Preregistros Los preregistros son una marca temporal sobre las decisiones del diseño, el método y el análisis de un artículo científico y se suelen hacer antes del levantamiento de datos (Stewart et al., 2020). Básicamente, preregistrar un estudio implica que un grupo de investigadores dejarán por escrito una pauta de investigación, la cual seguirán cuando desarrollen la investigación, especialmente la recopilación y el análisis de los datos. El objetivo del preregistro es reducir el margen de flexibilidad que tienen los investigadores a la hora de analizar los datos. El que exista una guía sobre qué hipótesis probar y qué análisis realizar hace menos probable que los científicos recurran en prácticas como el sesgo de publicación, p haking o el HARKing. Como vimos, el sesgo de publicación se trata de publicar selectivamente los resultados de investigación: resultados que no hayan sido significativos, o hipótesis que no funcionaron simplemente se omiten. Sin embargo, cuando existe un documento como un preregistro, el cual deja estipulado claramente las hipótesis que deben ponerse a prueba y los análisis que se emplearán para ello, se torna más difícil reportar selectivamente los resultados. Dicho de otra forma, cuando existe una pauta a la cual apegarse, la discrecionalidad en el reporte de los resultados disminuye. En el caso del p-hacking, el efecto del preregistro es parecido. El p-hacking consiste en abusar de las pruebas estadísticas para obtener resultados significativos. Abusar en el sentido de buscar toda vía posible para obtener un valor p que confirme las hipótesis planteadas. El hecho de preregistrar el plan de análisis y el procesamiento que se le efectuará a las variables permite evitar este tipo de búsqueda intencionada: como hay una guía que seguir, cualquier desviación debe ser justificada. En esta misma línea, un preregistro evita el HARKing ya que las hipótesis están previamente planteadas y no es posible cambiarlas una vez que se han visto los resultados. En suma, el plantear un registro a priori de la investigación, disminuye la flexibilidad que suele dar paso a las QRP. Existen resquemores respecto del uso de preregistros de los que es preciso hacerse cargo. Una de las principales preocupaciones es que el uso de preregistros tendería a coartar la creatividad y la producción de conocimiento exploratorio (Moore, 2016). La lógica es que, como cada parte de la investigación debe ser registrada detalladamente previo a la recopilación, no queda espacio para la espontaneidad durante el análisis de datos. Sin embargo, más que inhibir la investigación exploratoria, el objetivo de preregistar un estudio es separar la investigación confirmatoria (pruebas de hipótesis) y la exploratoria (generación de hipótesis) (Nosek et al., 2018). En ese sentido, es posible la investigación exploratoria bajo el modelo de preregistros, solo que hay que especificarla como tal. Una segunda creencia es que realizar un preregistro añade un nivel de escrutinio mayor del necesario, es decir, como se conoce cada detalle, la investigación se vuelve un blanco fácil de críticas. Sin embargo, la situación es todo lo contrario (Moore, 2016). Por ejemplo, haber preregistrado un plan de análisis para una regresión logística binaria con datos que originalmente eran ordinales hará más creíble los resultados, ya que quienes evalúen la investigación tendrán pruebas de que el nivel de medición no se cambió solo para obtener resultados significativos. Una tercera idea en torno a los preregistros es que conllevan una gran inversión de tiempo y energía. Si bien es cierto que se añade un paso más al proceso de investigación, el avance en la temática ha logrado que existan una variedad de plantillas que hacen el proceso más rápido y eficiente. Desde una lógica racional, el tiempo que toma este paso nuevo en la investigación es un costo bajo en contraste a los beneficios que trae. La característica más importante de los preregistros es que sean elaborados previo al análisis de datos y deseablemente previo a su recopilación. Este requisito es lo que permite asegurar la credibilidad de los resultados, ya que si no hay datos que alterar, entonces las probabilidades de que ocurra una QRP son básicamente nulas. Generalmente, para las ciencias médicas o la psicología experimental (disciplinas donde cada vez se usan más los preregistros), esto no suele ser un problema ya que se utilizan diseños experimentales. Estos se apegan al método científico clásico: se plantean hipótesis basadas en la teoría, se diseña un experimento para probar esas hipótesis y luego se recopilan y analizan los datos para ver si dan soporte a las hipótesis planteadas. Sin embargo, en muchas disciplinas de las ciencias sociales los diseños experimentales son una pequeña fracción del conjunto de la literatura (e.g. según Card et al., 2011, en 2010, solo un 3% de los artículos en las mejores revistas de economía eran experimentales), y lo que prima son los diseños observacionales con datos secundarios. A diferencia de los estudios experimentales, en los estudios con datos preexistentes se afecta el principal componente de credibilidad de los preregistros. Nada puede asegurar que los datos fueron analizados antes de la escritura del preregistro y que, por ejemplo, las hipótesis se están planteando una vez conocidos los patrones significativos (HARKing). De ahí que nace la pregunta sobre la posibilidad de utilizar preregistros en estudios con datos preexistentes. En la literatura sobre preregistros se han discutido los desafíos que implica preregistrar estudios que utilicen datos preexistentes (e.g. Editors, 2014). Existen posturas que proponen que, en realidad, no existe una forma creíble para preregistrar este tipo de estudios (Christensen &amp; Miguel, 2018). No obstante, otras posturas han profundizado en las situaciones en las que aún es posible preregistrar estudios con datos elaborados previamente. Burlig (2018) propone tres escenarios donde el preregistro de datos observacionales es valioso. El primero es, básicamente, cuando los investigadores que diseñaron la investigación generan sus propios datos, en este caso, los investigadores sí pueden elaborar un preregistro previo a la recolección de datos. El segundo escenario se da cuando se preregistra un estudio que tiene como objeto de interés un suceso que aún no ha ocurrido, lo que se conoce como estudios prospectivos. Por ejemplo, un grupo de investigadores puede estar interesado en el efecto que tendrá la introducción de una ley en las prácticas sociales, o el efecto de un tratado en las variaciones del PIB. Para esos casos, el preregistro aún mantiene su validez original ya que, si bien los datos ya existen, no es posible hacer los análisis antes del preregistro porque el evento de interés no ha ocurrido. El tercer escenario ocurre cuando los datos existen, pero no están abiertos al público. En estos casos, es la accesibilidad lo que determina la credibilidad del preregistro. Por ejemplo, el grupo de investigadores que elaboraron los datos pueden establecer que serán accesibles con previo contacto y que se solicitará un preregistro. Por ende, en orden de analizar los datos, los investigadores interesados deberán elaborar un preregistro para utilizar los datos. Conforme a lo anterior, Mertens &amp; Krypotos (2019) proponen dos prácticas para asegurar la credibilidad de un preregistro con datos secundarios. Primero, que el grupo de investigadores que analiza los datos sea distinto e independiente de quien propuso el diseño de investigación y segundo, que el equipo realice sintaxis de análisis con datos simulados, con tal de demostrar que las hipótesis ya existían previas a acceder a los datos. Estas propuestas muestran que el requisito sobre la temporalidad del preregistro puede. La recomendación más transversal y a la vez simple para preregistrar análisis con datos secundarios, es ser sincero y claro respecto a lo que se ha hecho y lo que no (Lindsay, 2020 ; Nosek et al., 2018). Por ejemplo, reportar si es que se ha leído el reporte descriptivo sobre la base de datos o si se tiene conocimiento de algún tipo de patrón de los datos. Es preciso transparentar cualquier tipo de aproximación a los datos previo haberlos analizado. Para lograr este nivel de detalle y ser eficiente con los tiempos y la comunicación hacia otros investigadores, es que existen plantillas predeterminadas para preregistrar distintos tipos de artículos en diferentes situaciones. En la siguiente sección presentaremos las plantillas más usadas. Referencias "],["herramientas-para-los-diseños-transparentes.html", "2.5 Herramientas para los diseños transparentes", " 2.5 Herramientas para los diseños transparentes Nuestra principal apuesta para promover la transparencia en los diseños de investigación son los preregistros, por lo que es a lo que le dedicaremos más espacio de esta sección. De todos modos, también revisaremos un par de herramientas que pueden complementar el uso de preregistros. Esperamos que, posterior a esta sección, el lector pueda ser capaz de utilizar estas herramientas para sus investigaciones. 2.5.1 Plantillas de preregistro En la práctica, preregistrar un artículo es básicamente sintetizar la información importante sobre nuestra investigación en una plantilla estandarizada y alojar ese documento en un lugar público. Por lo que el primer paso para elaborar un preregistro es elegir la plantilla correcta. Existen plantillas estandarizadas que están estructuradas de tal forma que son útiles para preregistrar estudios de cualquier disciplina, así como también existen plantillas dedicadas a una disciplina o a situaciones particulares. En este apartado presentaremos plantillas bajo cuatro categorías: a) plantillas genéricas, b) plantillas para experimentos y previas a recolección de datos, c) plantillas para datos existentes/secundarios, c) plantillas para estudios de replicación y d) plantillas para registered reports. Además de proveer una descripción de cada una, orientaremos al lector para elegir una plantilla de acuerdo al tipo de investigación que está desarrollando. El Open Science Framework (OSF), que en español se traduce como un marco de referencia para la ciencia abierta, actúa cómo una herramienta y un repositorio que alberga las plantillas que trataremos en esta sección (y más). Para ver todas las plantillas disponibles en OSF hacer clic en el siguiente enlace: https://osf.io/zab38/wiki/home/. 2.5.1.1 Plantillas Genéricas Las plantillas genéricas son aquellas que pueden ser utilizadas independientemente de las características del estudio, ya que suelen incluir campos que abordan distintos tipos de situaciones (e.g. si un estudio es experimental o observacional). Acá revisaremos dos plantillas genéricas, la plantilla estándar de AsPredicted, y la plantilla estándar de OSF. AsPredicted La plantilla de AsPredicted es quizás una de las más conocidas para hacer preregistros, dado que está estandarizada y puede ser utilizada en cualquier disciplina. Recomendamos utilizarla cuando lo que se busque es optimizar tiempo y energías. La plantilla cuenta solamente con nueve preguntas clave que aplican a cualquier tipo de artículo. Esta plantilla la podemos encontrar tanto en OSF, como en la página de AsPredicted, en este caso, mostraremos cómo es el proceso en la página original. Partimos por entrar a la página de AsPredicted, donde veremos algo similar a la Figura N° 2.5. Acá se nos da la opción de crear un preregistro, de ver los que ya hemos hecho (si es que ese es el caso) y también una breve descripción de AsPredicted. A grandes rasgos, la página nos dice que AsPredicted es una plataforma que busca facilitar el preregistro de estudios por parte de los investigadores a través de nueve simples preguntas. La página genera un documento .pdf y una URL asociada. También, cuenta cómo funciona el preregistro. Básicamente, un autor elabora un preregistro de un estudio y los coautores reciben un mail para aprobar ese preregistro. Una vez aprobado por todos los autores, el preregistro queda alojado en la plataforma de manera privada, y no cambia hasta que un autor decida hacerlo público. Además, en caso de que el estudio entre en revisión por pares, se puede enviar una versión anónima del preregistro. Por último, nos entrega una recomendación sobre qué hacer en el caso de que el proceso de investigación no haya podido apegarse totalmente a lo predicho. Figura 2.5: Botón para comenzar un preregistro Para elaborar un preregistro debemos hacer click en el rectángulo azul que dice Create. Una vez hecho eso, nos pedirá una dirección de email para continuar. Cuando ingresemos un email, nos enviará un enlace al email que hayamos ingresado, con ese enlace podremos comenzar el preregistro. Una vez hayamos entrado en el enlace, veremos la plantilla de preregistro. Lo primero que aparece es una sección donde debemos escribir los emails de los autores colaboradores del estudio. También, nos da la opción de añadir otros emails además del que hemos introducido. Una vez pasada esta parte, ya nos encontramos con las preguntas del preregistro, que son las siguientes: Recogida de datos. ¿Se han recogido ya datos para este estudio? Hipótesis. ¿Cuál es la pregunta principal que se plantea o la hipótesis que se pone a prueba en este estudio? Variable dependiente. Describa la(s) variable(s) dependiente(s) clave especificando cómo se medirán. Condiciones. ¿Cuántos y qué condiciones se asignarán a los participantes? Análisis. Especifique exactamente qué análisis realizará para examinar la pregunta/hipótesis principal. Valores atípicos y exclusiones. Describa exactamente cómo se definirán y tratarán los valores atípicos, así como su(s) regla(s) precisa(s) para excluir las observaciones. Tamaño de la muestra. ¿Cuántas observaciones se recogerán o qué determinará el tamaño de la muestra? Otros. ¿Hay algo más que quiera preinscribir? Nombre. Poner un título a este preregistro de AsPredicted Finalmente. A efectos de registro, indíquenos el tipo de estudio que está preinscribiendo. Las preguntas son bastante autoexplicativas, pero no está de más entregar algunos detalles adicionales. En la pregunta de recolección de datos, las opciones son tres: Sí, se han recolectado datos, No, no se han recolectado datos y Es complicado. Es importante mencionar que, en esta plantilla, la respuesta de que se han recolectado datos no es válida, por lo que si se está llevando a cabo un estudio con datos secundarios hay que responder Es complicado y en la pregunta 8 de la plantilla especificar por qué este preregistro sigue siendo válido pese a que los datos son preexistentes. Otro detalle importante es que cada pregunta está pensada para ser respuesta en aproximadamente una oración. Esta plantilla tiene el objetivo de ser lo más eficiente posible, por lo que, en general, se recomienda que todo el documento no pase de los 3200 caracteres. Otro detalle que especificar es que la pregunta acerca del tipo de estudio que se está preregistrando también es semicerrada, tenemos las opciones de: Proyecto de clase, Experimento, Encuesta, Estudio observacional y Otro. Es responsabilidad de quien hace el preregistro el seleccionar la opción que más se asemeje a su situación. Por último, es importante señalar que el preregistro, al menos en la página de AsPredicted, solo puede ser rellenado en inglés, por lo que en caso de utilizar otro idioma solicitará traducirlo. OSF Estándar La plantilla estándar de OSF también es de carácter general y busca abarcar distintas situaciones y tipos de estudios. La diferencia que tiene con la plantilla de AsPredicted es que contiene más preguntas y más detalladas. Por ejemplo, contiene preguntas relativas a en qué momento específico se está efectuando el preregistro (i.e antes de recopilar los datos, antes de cualquier observación humana a los datos, antes de acceder a los datos, entre otros) o si se harán transformaciones de las variables y su nivel de medición. La plantilla puede verse en este enlace: https://osf.io/preprints/metaarxiv/epgjd/. A continuación, veremos el inicio del proceso para registrar en OSF, el cual sirve tanto para la plantilla estándar como para otras que veremos más adelante. El primer paso es acceder a la sección específica de preregistros de la página de OSF, la cual se encuentra en el siguiente enlace: https://osf.io/prereg/ (para usar este servicio es necesario tener una cuenta). Si entramos al enlace, la apariencia de la página será algo similar a la Figura N° 2.6. Seleccionemos Start a new preregistration, le damos un nombre al proyecto y hacemos click en Continue. En la página siguiente, podemos ver que hemos creado un proyecto nuevo en OSF, el cual nos da la opción de preregistrarlo haciendo click en el botón New registration. Figura 2.6: Opciones para comenzar un preregistro en OSF En la Figura N° 2.7 podemos ver dos cosas. Primero, la descripción de lo que está haciendo OSF al comenzar un nuevo preregistro, lo que en pocas palabras es una versión no modificable del proyecto al momento que hacemos el preregistro. En otras palabras, es una versión congelada del proyecto en OSF. Segundo, también se aprecia una serie de opciones para preregistrar, estas son las plantillas que mencionamos anteriormente. OSF nos ofrece distintas plantillas de acuerdo con el carácter que tiene nuestro estudio. Figura 2.7: Opciones de plantilla de pre-reistro El primer paso es escoger la plantilla de acuerdo a la situación en la que nos encontremos. En este caso, seleccionamos la plantilla estándar de OSF. Una vez hayamos hecho eso, será necesario llenar los metadatos del estudio (e.g. Figura N° 2.8). Esta sección es transversal a todas las plantillas y consiste en registrar el título, descripción, contribuyentes, entre otras cosas que ayudan a identificar el proyecto. Figura 2.8: Ejemplo de campos de metadatos para rellenar Una vez hayamos rellenado los campos correspondientes a los metadatos, podemos rellenar la plantilla de preregistro. Con los campos rellenados podremos proceder a preregistrar nuestro proyecto. 2.5.1.2 Plantillas para diseños experimentales y previas a recolección de datos Considerando que el sentido original de un preregistro es que sea elaborado previo a la recolección y análisis de los datos, en principio cualquier plantilla genérica podría servir. Por ejemplo, la plantilla estándar de OSF ofrece preguntas detalladas que refieren al uso de diseños experimentales (i.e. cuáles son las condiciones de tratamiento o quiénes están al tanto de las manipulaciones experimentales del estudio). Sin embargo, OSF ofrece una vía alternativa para preregistrar estudios previo a la recolección de datos a través de la plantilla OSF-Standard Pre-Data Collection pre-registration. Esta plantilla es un complemento de la plantilla estándar y se utiliza solamente si es que el preregistro original está archivado en un documento. Esto quiere decir que, en el caso de que el equipo de investigación no haya usado el flujo de preregistro de OSF, sino que ya cuenta con un archivo que alberga el preregistro del estudio, entonces puede escoger esta plantilla de complemento para no efectuar todo el proceso de nuevo. Esta plantilla agrega algunas preguntas cruciales sobre la recopilación de datos, siendo las siguientes: ¿Ha comenzado la recogida de datos para este proyecto? No, la recopilación de datos no ha comenzado Sí, la recopilación de datos está en curso o se ha completado ¿Ha mirado los datos? Sí No Otros comentarios 2.5.1.3 Plantillas para datos secundarios En el último tiempo se ha comenzado a considerar cómo es que investigadores de las ciencias sociales empíricas que trabajan con datos preexistentes pueden, de todas maneras, preregistrar sus estudios para asegurar la credibilidad de sus hallazgos. Si bien OSF cuenta con una plantilla tipo para este tipo de situaciones (ver en https://osf.io/x4gzt/), nosotros recomendamos la plantilla de Mertens &amp; Krypotos (2019) dada la simpleza y exhaustividad de sus preguntas. La plantilla de Mertens &amp; Krypotos (2019) se puede ver en el siguiente enlace: ttps://osf.io/p26rq/. Esta plantilla está dirigida a investigadores que usen datos secundarios. Hace más simple el proceso de preregistro al enfocarse en las preguntas que se asemejan realmente a la situación del investigador que trabaja con grandes encuestas o datos administrativos, lo cual es muchas veces el caso en disciplinas como sociología, ciencias políticas o economía. Esta plantilla cuenta con las siguientes diez preguntas: ¿Cuál es la hipótesis que se investigará? ¿Cómo se operacionalizarán las variables cruciales? ¿Cuál es la fuente de los datos incluidos en los análisis? ¿Cómo se obtendrán estos datos? ¿Hay algún criterio de exclusión de los datos? ¿Cuáles son los análisis estadísticos previstos? ¿Cuáles son los criterios para confirmar y desconfirmar las hipótesis? ¿Se han validado los análisis con un subconjunto de datos? En caso afirmativo, facilite los archivos de datos y la sintaxis de los mismos. ¿Qué se sabe sobre los datos que podría ser relevante para las hipótesis probadas? Facilite un breve calendario para los diferentes pasos del prerregistro. Como podemos ver, además de los campos que se pueden encontrar en cualquier plantilla como la especificación de las hipótesis del estudio o los criterios de exclusión de datos, esta plantilla hace preguntas relativas al nivel de conocimiento previo de los datos. Por ejemplo, en la pregunta 4 solicita especificar la fuente de los datos. Como son datos secundarios, esto implica detallar cómo se accederá o serán solicitados los datos: si es que es necesario rellenar algún formulario o contactar a alguien en específico para obtener acceso. También, en la pregunta 9 se solicita describir cualquier conocimiento de algún patrón en los datos que sea relevante para la pregunta de investigación (e.g. la media o la mediana de una variable). Estos son ejemplos de preguntas que hacen esta plantilla útil para los investigadores que trabajen con datos preexistentes y que quieran preregistrar sus estudios. 2.5.1.4 Plantillas para estudios de replicación Tratar en extenso qué es y cómo se hace un estudio de replicación escapa de los objetivos de este capítulo, sin embargo, es una práctica de la ciencia abierta que no podemos dejar fuera ya que también cuenta con una plantilla para prerregistro. Replicar un estudio significa regenerar los hallazgos de un estudio, siguiendo sus hipótesis y plan de análisis, pero con datos distintos. OSF ofrece dos plantillas para investigadores que tienen el objetivo de replicar un estudio. La primera es una plantilla para estudios de replicación previo a su ejecución, la cual incluye una serie de preguntas relativas al estudio original, por ejemplo, qué efecto se está buscando replicar, por qué es importante replicarlo o en qué área geográfica fue conducido el estudio original. Esta plantilla se puede ver en el siguiente enlace: https://osf.io/4jd46/. La segunda plantilla es para estudios de replicación que ya han sido completados. En este caso, las pvreguntas están relacionadas a los hallazgos del estudio de replicación, por ejemplo, cuál fue el efecto obtenido en la replicación y si se considera que este efecto logra replicar los resultados originales o no. El enlace para esta plantilla se puede encontrar en este enlace: https://osf.io/9rp6j/. 2.5.1.5 Plantillas para registered reports Cómo veremos en la siguiente sección, los registered reports son un modelo alternativo de publicación donde el diseño del estudio pasa por un proceso de revisión por pares, a diferencia del modelo tradicional donde el documento que pasa por revisión por pares es el artículo finalizado. La plantilla que ofrece OSF es para estudios que han sido aceptados en la revisión por pares en una revista académica que cuenta con el modelo de registered reports. El objetivo de esta plantilla es poder dejar un registro público sobre el artículo en proceso, por lo que la plantilla de preregistro consta de, básicamente, una sección para el título del artículo, la fecha de aceptación, el manuscrito y archivos complementarios. Esta plantilla se puede ver en este enlace: https://osf.io/gm36s/. Referencias "],["otras-herramientas.html", "2.6 Otras herramientas", " 2.6 Otras herramientas Sí bien los preregistros son una de las herramientas que más ha ido tomando protagonismo para promover la transparencia, existen otras. Específicamente, queremos mencionar dos de ellas: el modelo de registered reports (en español, informes registrados) y la transparency checklist (en español, lista de transparencia). 2.6.1 Registered Reports El modelo de registered reports es una alternativa al modelo tradicional de publicación. Consiste en que el artículo atraviesa una revisión por pares en etapas tempranas de la investigación, específicamente previo a la recolección de datos. Esta práctica tiene por objetivo que el estudio sea evaluado por su innovación y calidad del diseño de investigación, más que por resultados impactantes (Chambers et al., 2015). Además, busca dejar sin efecto prácticas como el sesgo de publicación, p-hacking y HARKing, ya que no solamente existe una marca temporal que avala el diseño de investigación del estudio (como es el caso de un preregistro), sino que también existe un grupo de científicos anónimos que están de acuerdo con que el artículo es un aporte al conocimiento (Chambers, 2013; Marsden et al., 2018; Nosek &amp; Lakens, 2014). Los registered reports tienen dos características principales (Marsden et al., 2018). Primero, un manuscrito con la justificación del estudio, lo que incluye una introducción, revisión de antecedentes y una pregunta de investigación, dando la posibilidad de una aceptación preliminar (IPA, por sus siglas en inglés In principle acceptance). La segunda característica es que el IPA no puede revocarse en base a los resultados del estudio, esto evita que trabajos con resultados no significativos no sean publicados y así combatir el sesgo de publicación. Relacionado a ambas características, los informes registrados pasan por dos etapas de revisión, la primera es la del manuscrito, siendo este el determinante de se el estudio se acepta o no, y la segunda revisión que se da posterior a terminar la recolección y análisis de datos. El modelo, en comparación al sistema tradicional de publicaciones, se puede ver en la Figura N° 2.9. Figura 2.9: Método convencional y de registered reports para publicación cientifica Para enviar un artículo bajo el modelo de registered reports, primero se debe tener en conocimiento cuáles son las revistas que cuentan con este tipo de revisión. El Centro para la Ciencia Abierta cuenta con una lista actualizada de revistas aquí. Una vez escogida una revista, el proceso no es tan distinto al método convencional, en el sentido de que los investigadores envían su manuscrito con la justificación del estudio y este puede ser aceptado o rechazado por el editor, ya sea directamente o después de la corrección de algunos comentarios. Una vez se cuenta con el IPA y se efectúa la revisión en la segunda etapa, los revisores se aseguran de que el estudio ha seguido el plan de análisis inicialmente planteado y si sus conclusiones tienen sentido de acuerdo a los datos y resultados obtenidos, así como también que toda desviación del plan original sea debidamente justificada (Stewart et al., 2020). Desviaciones muy sustanciales y/o que no sean debidamente justificadas pueden conllevar el rechazo del artículo, aunque puede seguir el proceso en el método convencional de publicación (Stewart et al., 2020). 2.6.2 Transparency Checklist La transparency checklist es una herramienta complementaria elaborada por Aczel et al. (2020) que busca acompañar el proceso de reportar un estudio, contribuyendo a que estos sean más transparentes. Esta lista ha sido elaborada específicamente para investigadores de las ciencias sociales y del comportamiento que trabajan con datos primarios, aunque puede ser útil para otros enfoques y disciplinas. La lista consta de 36 items divididos en cuatro categorías: preregistro, método, resultados y discusiones y accesibilidad de datos, donde cada ítem refiere a alguna característica de un reporte transparente, preguntando si ha sido efectuada o no, es decir, las respuestas posibles de cada ítem son Sí, No y N/A. Existe una versión más corta de 12 items, los cuales son los siguientes: Sección de preregistro: Antes de analizar el conjunto completo de datos, se publicó un prerregistro con sello de tiempo en un registro independiente de terceros para el plan de análisis de datos. El estudio fue registrado antes de que cualquier dato fuera recolectado después de que algunos datos fueron recolectados, pero antes de explorarlos después de que todos los datos fueron recolectados, pero antes de explorarlos después de explorar los datos, pero antes de que cualquier análisis estadístico fuera efectuado después de efectuar algunos análisis estadísticos, pero no todos en otro momento, explicar: El análisis estadístico previsto para cada pregunta de investigación (esto puede requerir, por ejemplo, información sobre la unilateralidad de las pruebas, los criterios de inferencia, las correcciones para pruebas múltiples, los criterios de selección de modelos, las distribuciones previas, etc.). Sección de método El manuscrito describe completamente la justificación del tamaño de la muestra utilizado (por ejemplo, un análisis de potencia a priori). el diseño, los procedimientos y los materiales del estudio para permitir una réplica independiente. las medidas de interés (por ejemplo, la amabilidad) y sus operacionalizaciones (por ejemplo, un cuestionario que mide la amabilidad). ¿algún cambio en el prerregistro (como cambios en los criterios de elegibilidad, en los límites de pertenencia al grupo o en los procedimientos experimentales)? Sección de resultados y discusión El manuscrito distingue explícitamente entre la confirmación (es decir, preestablecido) y exploratorio (es decir, no preestablecidos). Sección de disponibilidad de datos, código y materiales Se han hecho públicas las siguientes los datos (procesados) en los que se han basado los análisis del manuscrito. todo el código y el software (que no esté protegido por derechos de autor). todas las instrucciones, los estímulos y los materiales de las pruebas (que no estén protegidos por derechos de autor). El manuscrito incluye una declaración sobre la disponibilidad y localización de todos los elementos de la investigación, incluidos los datos, materiales y códigos pertinentes para su estudio. Tanto la versión completa de 36 items, como la recortada de 12 están disponibles para rellenar en línea. Aquí se puede encontrar la lista online, es una aplicación de uso simple, además que permite generar el reporte final de manera automática. Referencias "],["anexos.html", "Anexos", " Anexos Tabla 2.2: Algunas situaciones de QRP Dimensión Práctica Diseño y procesamiento Ignorar ciertos aspectos de los requerimientos de las personas participantes. Pasar por alto el uso de datos cuestionables o de interpretaciones cuestionables que otros hacen. Cambiar partes de un estudio como respuesta a la presión de una fuente de financiación Eliminar observaciones de los análisis basados en la intuición de que eran inexactos. Redondear un valor p (por ejemplo, reportar que un p-value de 0,054 es menor a 0,05) Eliminación, adición o alteración de datos después de pruebas de hipótesis. Supresión selectiva o adición de variables. Invertir la dirección o reformular hipótesis para respaldar los datos Redacción, reporte y publicación Ampliar de manera innecesaria la bibliografía de un estudio. Tergiversar los logros de la investigación. Exagerar la importancia y la relevancia práctica de los resultados. Retener detalles de la metodología de investigación (e.g. no reportar todas las variables dependientes de un estudio) Retener resultados de la investigación (e.g. no presentar datos que contradicen una propia investigación previa). Establecer publicaciones o brindar apoyo a publicaciones que no cumplen el proceso de control de calidad de la investigación Publicar los mismos datos o resultados en dos o más publicaciones. Selectivamente reportar estudios que funcionaron. Reportar hallazgos inesperados como previstos desde el principio. Afirmar que los resultados no se ven afectados por variables demográficas cuando uno no está realmente seguro (o sabe que lo hacen). Citación y autoría Manipular la autoría o denigrar el papel de otros investigadores en las publicaciones. Asignar inapropiadamente los crédios de autoría. Volver a publicar partes sustanciales de publicaciones propias anteriores, incluidas las traducciones, sin citar debidamente el original (autoplagio). Citar de forma selectiva para mejorar los propios resultados o para complacer a los editores, los revisores o los colegas. Usar ideas de otros sin obtener permiso o dar crédito Uso no autorizado de información confidencial en relación con la propia investigación. Relaciones con otros Permitir que los patrocinadores pongan en peligro la independencia en el proceso de investigación con el fin de introducir sesgos. Acusar a un investigador de conducta indebida u otras infracciones de forma maliciosa. Retrasar u obstaculizar inadecuadamente el trabajo de otros investigadores. Emplear la experiencia profesional propia para alentar a que se incumpla la integridad de la investigación. Ignorar supuestos incumplimientos de la integridad de la investigación cometidos por terceros o encubrir reacciones inadecuadas a conductas indebidas. No divulgar adecuadamente la participación en empresas cuyos productos se basan en la investigación de uno. Relaciones con estudiantes, sujetos de investigación o clientes que pueden ser interpretadas como cuestionables. "],["apertura-de-datos.html", "Capítulo 3 Apertura de datos", " Capítulo 3 Apertura de datos Si alguna vez has intentado conseguir datos de una investigación social producidos por otros profesionales, probablemente sabes cuán difícil es. Si no lo has intentado, es algo como Mickey Mouse intentando pasar a la siguiente habitación, puesto que nos enfrentaremos consecutivamente a una barrera tras otra. Imagine que el investigador responsable de un Fondecyt, Dr. González, desea estudiar la calidad de vida de los inmigrantes. En su revisión bibliográfica encuentra una investigación con datos que podrían ayudar al desarrollo del proyecto. Logra conseguir el contacto de la investigadora responsable y esta pese a su voluntad de compartir los datos le advierte que tardara unas semanas en ello, puesto que está muy ocupada y no sabe la ubicación actual de los mismos. Pese a perder valioso tiempo de su proyecto, el Dr. González logra acceder a la base de datos, no obstante, esta se encuentra dispersa en distintas hojas de cálculo. Al abrirlos e intentar conectarlos, se da cuenta que no comprende el significado de cada variable, por lo cual requiere un libro de códigos de los datos. Vuelve a contactar a la investigadora, le solicita el cuestionario y el significado de cada variable. Lamentablemente, el equipo que creo la base de datos señala que no posee documentación sobre el significado de cada variable. Sin más, al no poder utilizar debidamente los datos producidos por la investigación anterior, el Dr. González se resigna, y decide volver a invertir recursos en una encuesta, la que probablemente tampoco quede a disposición de futuros investigadores. En suma, al intentar conseguir datos de otras investigaciones nos enfrentamos a diversas barreras, como pueden ser la posibilidad de contactar al equipo, la voluntad del equipo de compartir sus datos, la calidad de la documentación de los datos, los formatos que pueden estar en versiones pagadas, entre otras. ¿Qué podemos hacer los investigadores sociales para evitar estas situaciones? Para ello, el movimiento de la ciencia abierta incentiva a los investigadores a publicar sus datos de investigación (Open Data). Más aún, se señala la importancia de publicarlos cumpliendo estándares internacionales sobre los datos y la documentación, de modo tal que cualquier investigador sea capaz de reutilizar los datos sin la necesidad de contactarse con el equipo que los produjo y con la información suficiente para reconocer o citar el aporte del equipo productor de los datos. A nivel internacional existe una amplia preocupación por democratizar el conocimiento. En esta línea, la Organización para la Cooperación y el desarrollo Económicos (OCDE, 2020), ha incluido dentro de las condiciones para mantenerse en la organización la obligación de que cada país incluya políticas de ciencia abierta, transparentando los procesos y resultados, para todas las investigaciones financiadas públicamente. A nivel nacional tanto el Instituto Nacional de Estadísticas (INE), dependiente del Ministerio de Economía, como la Agencia Nacional de Investigación y Desarrollo (ANID, 2020a) dependiente del Ministerio de Ciencia, han incorporado políticas y prácticas propias de la ciencia abierta. En vista de estos cambios realizados por las instituciones chilenas de investigación, resulta evidente que aprender prácticas de ciencia abierta sobre cómo compartir los análisis y los datos producidos se vuelve una necesidad para los investigadores Chilenos que trabajan en instituciones estatales o financiadas con fondos públicos. En vista de esta necesidad el objetivo de este documento es facilitar los conocimientos necesarios para abrir la información producida por las investigaciones. Referencias "],["ventajas-de-la-apertura-de-datos-de-investigación-social.html", "3.1 Ventajas de la apertura de datos de investigación social", " 3.1 Ventajas de la apertura de datos de investigación social Las ventajas de la apertura de datos son varias. A continuación nos centramos en los tres puntos que consideramos más relevantes: las características éticas, la contribución a la calidad y la eficiencia científica y otros incentivos personales importantes de considerar. Ética: Es justo que el público general tenga acceso a los datos producidos especialmente cuando estos son producidos con fondos públicos (Bueno, 2017). Cabe destacar que Chile gasta aproximadamente $668.551 MM de pesos, lo cual equivale a un 0,35% del producto interno bruto. La apertura de los datos fomenta la ética investigativa y la confiabilidad, reduce el fraude y aumenta el valor de la sociología para los políticos y el público (Breznau, 2019). Calidad y eficiencia científica: Dejar la base de datos a libre disposición permite hacer evaluaciones sobre la rigurosidad de los resultados mediante la reproducibilidad, mejorando la calidad y la confianza en la ciencia (UNESCO, 2020). Fomenta que más investigadores utilicen los datos y produzcan información (Whyte y Pryor, 2011), aumentando la colaboración y con ello la innovación científica, según señala el Foro Abierto de Ciencias Latinoamérica y el Caribe CILIAC (Ramírez &amp; Samoilovich, 2019). Considerando que los recursos públicos asignados a investigación son escasos, la apertura de las bases de datos permite su reutilización y por ello ahorra recursos en la construcción de bases de datos, fomentando la eficiencia fiscal (Gómez et al., 2016). Facilita la preservación de información para estudios históricos que recopilen evidencia de larga data. Almacenar los datos permite resguardar el conocimiento producido a generaciones futuras. Poder acceder a los productos, procesos y discusiones propias de la investigación cualitativa, puede ayudar pedagógicamente a la formación universitaria, dando una idea más clara de lo que implica una investigación (Bishop &amp; Kuula-Luumi, 2017). Incentivos personales: Publicar los datos de la investigación fomenta un mayor impacto y visibilidad. Como señala la evidencia producida por Piwowar &amp; Vision (2013) una investigación que comparte sus datos puede ser citada un 30% más que una que no lo hace. Compartir el diseño de investigación, las hipótesis y los datos puede fomentar comentarios constructivos respecto a la dirección de la investigación, ayudando a mejorar la calidad del material (Sharan, 2020). Pese a las ventajas otorgadas por la apertura de la información producida, los investigadores poseen reticencias a la hora de publicar abiertamente sus datos (Ferguson, 2014). Estas reticencias de los investigadores, según Sharan (2020), pueden ser consideradas más bien mitos, los cuales se sustentan en prenociones que no corresponden a la realidad. A continuación, se destacan algunos de estos mitos y las razones de por qué podemos considerarlos como tal. Preocupación a las consecuencias negativas (mal uso, consecuencias legales o comerciales). En parte este problema se soluciona mediante el uso adecuado de licencias, las cuales pueden restringir el uso para ciertos fines. Además, para disminuir el posible mal uso, la preparación de datos incluye hacer anónimos los datos. Respecto a las consecuencias legales, hay que considerar que en general estas investigaciones son financiadas con fondos públicos o por instituciones humanitarias, los cuales en el contexto actual fomentan en general la apertura de los datos. Temor a la falta del reconocimiento debido de su trabajo. Como señalamos anteriormente, lejos de quitarle merito a su trabajo y disminuir su reconocimiento, el preparar y publicar los datos de modo adecuado puede ayudar a difundir la investigación y aumentar el número de citas. Además, usted también puede nutrirse de las investigaciones sobre sus datos. Disgusto frente a la carga de trabajo que implica preparar los datos para su publicación. Sin duda esta es una aprensión comprensible, no obstante, cada vez existen más herramientas que facilitan la labor de la preparación de datos cualitativos y cuantitativos. Por ejemplo, este documento le ayudará a disminuir dicha carga. Además, hay que considerar que si bien aumenta la carga de trabajo actual, disminuye la futura en tanto la buena documentación de los datos también le permitirán a usted volver a trabajar con ellos en el futuro o con datos de otra investigación. Desconocimiento de cómo y dónde compartir los datos. Esta razón, igual de comprensible, es parte de una cultura académica poco acostumbrada al trabajo colaborativo. Por ello, debemos aprender sobre plataformas que faciliten compartir nuestros datos de investigación. Para ello, este trabajo ofrece una guía para preparar los datos y sobre como subirlos a la plataforma de ciencia abierta Open Science Framework. En miras de las dudas más comprensibles de los investigadores señaladas (Ferguson, 2014; Sharan, 2020) y de la necesidad tanto ética como legal de avanzar hacia la apertura de datos en el contexto chileno, el presente documento busca facilitar la introducción al almacenamiento y publicación abierta de datos. Se busca entregar información para resolver los cuatro puntos señalados, dando cuenta de lo que debe hacerse para disminuir los riesgos, fomentar el reconocimiento del trabajo propio, facilitar el mejoramiento de la calidad de los datos y entregar información sobre dónde y cómo compartir los datos. Para ello, este documento ofrece una propuesta de pasos a seguir para mejorar la calidad de los materiales de investigación producidos antes de publicarla en la web. Esta propuesta busca conciliar los estándares considerados óptimos en materia de almacenamiento y preservación de datos con la realidad de las capacidades y herramientas de los investigadores chilenos en ciencias sociales. Dicho de otro modo, proponemos una lista de tareas a realizar para cumplir con los mínimos necesarios para mejorar la calidad de los datos a publicar. Referencias "],["consejos-para-la-apertura-de-datos-de-investigación-social.html", "3.2 Consejos para la Apertura de Datos de Investigación Social", " 3.2 Consejos para la Apertura de Datos de Investigación Social A continuación, se presenta una sencilla pauta sobre cómo y dónde publicar abiertamente información cualitativa o cuantitativa producida por investigaciones sociales, cumpliendo con estándares internacionales de almacenamiento. Esta pauta ayuda a cumplir con objetivos señalados por el Consejo Internacional para la Ciencia (ICSU, 2014), los cuales promueven el acceso oportuno a los registros científicos sin barreras, mejorando su calidad y de modo que sea perdurable en el tiempo. Igualmente, proponemos una guía de almacenamiento que permite cumplir con los principios FAIR (Findable, Accessible, Interoperable, Reusable) promovidos por organizaciones científicas del Estado Chileno, americanas y europeas (ANID, 2020a; EC, 2016; Ramírez &amp; Samoilovich, 2019). Los estándares FAIR tienen el objetivo de hacer los datos fáciles de encontrar en la web y que estén en formatos que cualquier investigador pueda utilizar (FAIR, 2020). Esta pauta para la publicación de datos fue creada en base a otros materiales de apoyo con objetivos similares, como la guía de preparación de datos creada por el Consorcio interuniversitario para la investigación política y social (ICPSR), el manual de Autoevaluación para proveedores de repositorios abiertos (RISE) del Digital Curation Center (DDC) (DDC, 2017), los planes europeos de manejo de datos (DMP) y los consejos de distintos investigadores tanto para datos cuantitativos como cualitativos (CCSDS, 2012; Kapiszewski &amp; Karcher, 2019). Para publicar los datos de investigación proponemos los siguientes tres momentos: 3.2.1 Preparar 3.2.1.1 Datos cualitativos: Considerando que al estar presente en la entrevista se cuenta con una mayor información que solo leyendo su transcripción, cualquier anotación que dé cuenta del ambiente anímico de la entrevista o del gesto que acompaña alguna frase es bienvenida. También es importante subir la pauta de la entrevista si es que existe. Asimismo, aquellos investigadores que hacen un análisis mediante codificación tienen registro del proceso por el cual llegaron a los códigos utilizados para la categorización de la información. Además, esto puede ser complementado con la descripción de las discusiones que surgieron entre el equipo de investigación para establecer tales códigos y el esquema de análisis (Kapiszewski &amp; Karcher, 2019). Igualmente necesario es cambiar en el texto y/o audio lo que sea necesario para que los sujetos de investigación no puedan ser identificados. También es conveniente compartir el cuaderno de campo de la investigación. Esta información bien almacenada no solo ayudará a las ciencias sociales por su apoyo con información a otros investigadores, sino que conjuntamente es un gran aporte a la formación de los estudiantes sobre cómo investigar cualitativamente, pues estos materiales permiten una aproximación más concreta al proceso de investigación cualitativo (Bishop &amp; Kuula-Luumi, 2017). Confidencialidad en datos cualitativos Respecto a la confidencialidad de los datos, ICPSR recomienda que: antes de enviar datos cualitativos a un archivo, los depositantes de datos deben tener cuidado de eliminar la información que permita identificar a cualquiera de sus sujetos de investigación. Este proceso se puede hacer menos arduo creando un esquema para anonimizar antes de la recopilación de datos y anonimizando los datos a medida que se crean los archivos cualitativos para el análisis. Algunas de las modificaciones que se pueden hacer a los datos cualitativos para asegurar confidencialidad del entrevistado, según Marz y Dunn (2000), son: (1) Reemplazar nombres reales con texto generalizado; (2) Reempalzar fechas; (3) Eliminar elementos únicos y/o publicitados. Dado que los investigadores están más familiarizados con sus datos, se les pide que utilicen su juicio sobre si cierta información cualitativa en combinación con el resto del texto o información cuantitativa relacionada podría permitir la identificación de un individuo. Los depositantes de datos deben documentar cualquier modificación para enmascarar información confidencial en los datos cualitativos. Esto garantizará que el personal del archivo no realice cambios innecesarios en las modificaciones del investigador cuando realice su revisión de confidencialidad. Por tanto, la información también se pondrá a disposición de los usuarios secundarios de los datos para ayudarles a utilizarlos. 3.2.1.2 Datos cuantitativos: Bases de datos Para resguardar la calidad de nuestros datos debemos asegurar una correcta codificación de las respuestas y nombramiento de las variables, ambas bases fundamentales de los datos (filas y columnas). Para esto, ICPSR propone, entre otros, los siguientes puntos: Errores de codificación Verifique cuidadosamente la coherencia entre las respuestas del cuestionario y los valores en la base de datos para el primer 5 a 10 por ciento de los registros de datos creados y luego elija registros aleatorios para controles de calidad. Posteriormente, puede realizar análisis descriptivos de distribución para evaluar si existen valores atípicos atribuibles a errores de codificación (por ejemplo 66 en la variable hijos en vez de 6). El uso de computadores y programas de encuesta y codificación puede ayudar a disminuir estos errores. Recodificación automática Deje que la computadora realice codificaciones y rectificaciones complejas si es posible. Por ejemplo, para crear una serie de variables que describen la estructura familiar, escriba un código de computadora para realizar la tarea. Los códigos de computadora no solo son precisos si las instrucciones son precisas, sino que también se puede cambiar fácilmente para corregir un error lógico o de programación. Incluya en la documentación los códigos utilizados para la recodificación. Consistencia Evalué la coherencia entre las variables, identificando a quienes poseen combinaciones incoherentes. Por ejemplo, si alguien señala que su hijo no asiste a la escuela y luego responde preguntas sobre la escuela. Identificadores individuales y grupales Proporcione variables identificadoras suficientes. Es fundamental que cada sujeto posea un id, además si la encuesta es longitudinal se puede proporcionar, junto al id de encuestado, un id por cada ocasión que contesta la encuesta. Otros identificadores dependen del tema del estudio, por ejemplo, si se trabaja con escuelas, verifique que cada escuela tiene un identificador id-escuela. Si trabaja con encuestados de modo tal que dos o más son de la misma familia y cada encuestado corresponde a un núcleo familiar, indique un id para familia. Nombres de Variables El nombre de la variable será con lo que más se trabajará con los datos, por ende, deben ser claros y utilizables por distintitos softwares. Existen distintos estándares para elegir los nombres de las variables. El primero consiste en asignar un numero único anteponiendo una V de modo tal que, siendo n el número de variables, las variables se nombran como Vn según su posición (p ej. V0001, v0002,Vn). Se antepone la V por que los softwares en general no permiten nombres de variables con solo caracteres números. El segundo modo utiliza letras y números para agrupar las variables según escalas o temas (por ejemplo Q1,Q2a,Q2b), si bien es un sistema que entrega más información, no informa sobre el contenido. El tercero consiste en utilizar abreviaturas mnemotécnicas, es decir, nombres cortos de variables que representan el significado sustantivo de las variables facilitando su memorización y comprensión. Por ejemplo educpadr como Educación del Padre. Este tipo de nombres podrían ayudar a disminuir los errores en los análisis producidos por agregar una variable incorrecta en el código. El problema es que con la limitación de caracteres de los softwares es difícil generar abreviaturas arbitrarias que sean ampliamente reconocibles por un público diverso. El cuarto consiste en Abreviaciones compartidas y registradas. Un sistema de raíces y sufijos. Por ejemplo, todas las variables que tienen que ver con la educación pueden tener la raíz ED, y podría expresarse Educación del Padre como FAED, siendo esta nomenclatura previamente documentada. Esto implica una planificación previa y capacidad de organización para compartir las abreviaturas, así como herramientas para facilitar el encontrar las abreviaturas correctas en la biblioteca o documento de sufijos y prefijos. En consideración de estas opciones expuestas por ICPSR, se recomienda utilizar la tercera, puesto que cumple con la cualidad de la primera y la segunda de identificar las variables de modo único, a la vez que cumple con el criterio de hacer más comprensible y fácil de recordar. Junto a lo señalado por ICPSR, consideramos que al crear un nombre de la variable este debe ser utilizable por los distintos softwares comúnmente utilizados como SPSS, STATA y R. En vista de lo anterior sugerimos: Dos variables no pueden tener el mismo nombre No utilizar más de 12 caracteres en el nombre Empezar con una letra Deben ser solo alfanuméricos (Números y letras, sin símbolos . ; , :  $ @) En minúscula No utilizar la letra ñ, remplazarlo por gn (agnos, en vez de años) Remplazando espacios por guion bajo. (edad_rec) Etiquetas de variables las variables deben ser correctamente etiquetadas. Las etiquetas deben partir con el número del ítem en el cuestionario para poder asociarlo. Luego debe darse información sobre el contenido de la variable o ingresar directamente la pregunta realizada al encuestado. Considerando las limitaciones de caracteres de los softwares, en base a manuales universitarios de SPSS y STATA, se sugiere que las etiquetas de las variables no superen los 120 caracteres. Codificación Variables de identificación. Proporcione campos al comienzo de cada registro para acomodar todas las variables de identificación. Las variables de identificación a menudo incluyen un número de estudio único y un número de encuestado para representar cada caso. Categorías de código. Las categorías de códigos deben ser mutuamente excluyentes, exhaustivas y estar definidas con precisión. Cada respuesta de la entrevista debe encajar en una y solo una categoría. La ambigüedad provocará dificultades de codificación y problemas con la interpretación de los datos. Conservación de la información original. Codifique tantos detalles como sea posible. Registrar datos originales, como edad e ingresos, es más útil que colapsar o poner entre corchetes la información. Con datos originales o detallados, los analistas secundarios pueden determinar otros paréntesis significativos por sí mismos en lugar de limitarse a los elegidos por otros. Preguntas cerradas. Las respuestas a las preguntas de la encuesta que están precodificadas en el cuestionario deben conservar este esquema de codificación en los datos legibles por máquina para evitar errores y confusiones. Preguntas de final abierto. Para los ítems abiertos, los investigadores pueden usar un esquema de codificación predeterminado o revisar las respuestas iniciales de la encuesta para construir un esquema de codificación basado en las categorías principales que surgen. Cualquier esquema de codificación y su derivación deben informarse en la documentación del estudio. Respuestas codificadas por el usuario. Cada vez más, los investigadores envían el texto completo de las respuestas a las preguntas abiertas a los archivos para que los usuarios puedan codificar estas respuestas ellos mismos. Debido a que dichas respuestas pueden contener información confidencial, deben ser revisadas por riesgo de divulgación y, si es necesario, tratadas por archivos antes de su publicación. Comprobar codificación. Es una buena idea verificar el código de algunos casos durante el proceso de codificación, es decir, repetir el proceso con un codificador independiente. Por ejemplo, si se asigna más de un código a la respuesta de una entrevista, esto resalta problemas o ambigüedades en el esquema de codificación. Esta codificación de verificación proporciona un medio importante de control de calidad en el proceso de codificación. Serie de respuestas. Si una serie de respuestas requiere más de un campo, organizar las respuestas en clasificaciones importantes significativas es útil. Respuestas dentro de cada especialidad o categoría se les asigna el mismo primer dígito. Los dígitos secundarios pueden distinguir respuestas específicas dentro de las categorías principales. Tal esquema de codificación permite el análisis de los datos utilizando agrupaciones amplias o categorías más detalladas. Identificar Casos perdidos ICPSR no establece un modo determinado de identificar los casos perdidos, aunque señala las ventajas y desventajas de distintos tipos de codificación. Igualmente sugiere distintos tipos de casos perdidos que deben ser identificados. Cabe destacar que, como regla general para la preservación, los casos perdidos se deben codificar del modo más similar a las categorías de las variables, de modo tal que una variable numérica de un digito se indica con (8,9) y una variable categórica con alternativas de texto con (No sabe, No responde) Rechazo / Sin respuesta. El sujeto se negó explícitamente a responder una pregunta o no la respondió cuando debería haberlo hecho. No lo sé. El sujeto no pudo responder una pregunta, ya sea porque no tenía una opinión o porque la información requerida no estaba disponible (por ejemplo, un encuestado no pudo proporcionar los ingresos familiares en dólares del año anterior). Error de proceso. Por alguna razón, no hay respuesta a la pregunta, aunque el sujeto proporcionó una. Esto puede resultar de un error del entrevistador, codificación incorrecta, falla de la máquina u otros problemas. No aplica. Al sujeto nunca se le hizo una pregunta por alguna razón. A veces, esto se debe a patrones de omisión después de preguntas de filtro, por ejemplo, a los sujetos que no están trabajando no se les pregunta sobre las características del trabajo. Otros ejemplos de inaplicabilidad son los conjuntos de elementos solicitados solo de submuestras aleatorias y los solicitados a un miembro de un hogar, pero no a otro. Sin coincidencia. Esta situación surge cuando los datos se obtienen de diferentes fuentes (por ejemplo, un cuestionario de encuesta y una base de datos administrativa) y no se puede localizar la información de una fuente. Datos no disponibles. La pregunta debería haberse formulado al encuestado, pero por otro motivo distinto de los enumerados anteriormente, no se dio ni registró ninguna respuesta. Considerando las ventajas y desventajas de las distintas formas de codificación se sugiere a título personal utilizar valores perdidos con valores altos en negativo de modo tal que sean estándar para todas las variables y no sean confundible con los valores posibles de dichas variables. Se propone utilizar los siguientes valores perdidos, usando numéricos o caracteres según corresponda. Código de texto Código numérico No responde -999 No sabe -998 Error de Proceso -997 No aplica -996 Sin coincidencia -995 No disponible -994 Para obtener información adicional sobre datos georreferenciados e imputaciones revise directamente la guía ofrecida por ICPSR disponible en este enlace 3.2.2 Documentar Existen distintos estándares sobre qué información incorporar junto con los datos, destacando la importancia de que estos materiales sean legibles por humanos y por inteligencia artificial (FAIR, 2020). A continuación, se propone un conjunto de documentos comunes que deben estar incluidos, junto con una guía de como escribirlos en formato abiertos para cumplir con las recomendaciones del libro Managing and sharing research data: a guide to good practice (Corti, 2019). Readme El readme es un documento que debe responder las siguientes preguntas sobre la producción de la información (Tierney &amp; Ram, 2020). Quién produjo la información Cuál es el contenido de los datos Cuándo fue producida la información Dónde fue recolectada Por qué se recopiló Cómo se recopiló Para crear este documento se suele utilizar el formato y lenguaje Markdowm de extensión .md. Este formato posee la ventaja de no ser un formato propietario que permite incluir de modo sencillo distintos elementos útiles como enlaces, imágenes y tablas. Le recomendamos realizar la escritura en este formato. Para ello se puede escribir el documento en RStudio señalando como extensión .md o para quienes no manejen el software, pueden crear el documento en la página Dillinger. Licencia La licencia se puede crear fácilmente al publicar los datos en OSF. En la siguiente sección se señala cómo hacerlo. Metadatos La creación de los metadatos requiere previamente que se cree el identificador y la página web en OSF que almacenara los datos. Por ello la creación de los metadatos será posterior a la publicación. Cabe desacatar que el modo de crear metadatos difiere según si el tipo de material es una transcripción de entrevista en PDF o una base de datos en formato sav, stat o rda. Documentos especiales según tipo de metodología Para publicar datos cuantitativos se recomienda recopilar y producir los siguientes materiales con el objetivo de que los usuarios de la base de datos cuenten con información suficiente para utilizarla correctamente. Los siguientes documentos deben ser subidos en PDF y Block de notas.txt con codificación utf8. Cuestionario Consentimiento informado Libro de códigos Ficha técnica Manual de usuario Descriptivos (Optativo) Publicaciones asociadas a los datos (Optativo) Descripción e información detallada para metadatos. Para publicar datos cualitativos se sugiere documentar la siguiente información. Transcripciones registros audiovisuales (de ser necesario) Investigar métodos y prácticas que estén completamente documentados Copia en blanco del formulario de consentimiento informado con el número de aprobación del IRB Detalles sobre el escenario de las entrevistas Detalles sobre la selección de los sujetos de la entrevista Instrucciones dadas a los entrevistadores Instrumentos de recopilación de datos como cuestionarios de entrevistas Medidas tomadas para eliminar identificadores directos en los datos (por ejemplo, nombre, dirección, etc.) Cualquier problema que surgió durante el proceso de selección y/o entrevista y cómo se manejaron Lista de entrevistas 3.2.3 Publicar OSF y plataformas para publicar datos La plataforma web Open Science Framework (OSF) ofrece gratuitamente servicios de infraestructura digital que permite un espacio de registro para las distintas etapas de un proyecto de investigación. Actualmente existen otras plataformas con objetivos similares como Zenovo, Dataverse, GitHub, Mendeley, Figshare, Dryad o ICPSR, y si bien todas son buenas herramientas, se remienda utilizar OSF por diversos motivos señalados por Kryvokhyzha (2019) y un documento informativo de la Librería de Universidades de la Universidad de OKLAHOMA (2020). En primer lugar, a diferencia de Dryad, OSF es una plataforma gratuita, con mejor estructura de repositorios y con posibilidades de corregir errores. En segundo lugar, Figshare tiene la capacidad de estructurar los repositorios en distintos componentes, pero no está optimizado para descargar muchos archivos a la vez y, además es una empresa con fines de lucro. Por su parte OSF, permite estructurar de diversos modos los repositorios, esta optimizado para descargas y es una organización sin fines de lucro que es financiada por el Centro para la Ciencia Abierta cos con recursos para 50 años más. En tercer lugar, a diferencia de Zenovo y GitHub, OSF si cuenta con estadísticas de descarga que nos permiten evaluar la visibilidad de los datos. En último lugar, GitHub si bien es una alternativa que ha sido utilizada para este fin, en realidad más que una plataforma para subir datos es una plataforma para crear códigos de forma colaborativa, usualmente de aplicaciones, además no nos permite crear de modo automático un DOI, lo cual es fundamental para cumplir con los principios FAIR. No obstante, si el equipo investigador lo considera conveniente podría subir sus datos a múltiples plataformas. En esta línea, además de OSF, recomendamos almacenar los datos paralelamente en OpenICPSR puesto que esto permitirá conectar nuestros datos con el buscador de ICPSR, el cual tiene amplia visibilidad dentro del campo de las ciencias sociales a nivel internacional. Un usuario de esta página puede crear un repositorio denominado proyecto, el cual puede contener a su vez componentes que pueden ser investigaciones o datos específicos dentro del proyecto. Se pueden crear más componentes de estos tipos dentro de los componentes del proyecto. Esta estructura permite almacenar conjuntamente trabajos relacionados. La página promueve que se registren productos de la investigación de las distintas etapas del proceso. En primer lugar, posee un espacio para los pre-registros que son un documento en el cual se expone brevemente el diseño de la investigación, las hipótesis y la metodología, lo cual aumenta la rigurosidad de las investigaciones. Ambas evaluaciones de OSF señalan que un problema es el límite de almacenamiento de solo 5gb por archivo. Este límite ha sido modificado el 5 de noviembre del 2020, agregando un límite de 5gb a los proyectos que estén privados y 50gb a los públicos. No obstante, el problema del espacio se puede resolver conectando OSF con otros servicios de almacenamiento con mayor capacidad. Crear Metadatos para datos cualitativos o cuantitativos. Paso 1 Para crear los metadatos de forma muy sencilla se puede utilizar un archivo csv, que se puede editar con el programa Excel o cualquier Hoja de cálculo. A continuación, entregamos un link para descargar un csv con los campos para rellenar los metadatos, cumpliendo con los campos utilizados por Dataverse Harvard y los Social Science and Humanities Metadata de ICPSR. Para crear los metadatos usted solo debe escribir en las casillas de abajo de las categorías, la respuesta para cada uno de los campos, señalando el identificador, el Título de los datos, los autores, entre otros. Es necesario que rellene los campos en inglés. Con una traducción simple de Google Traductor o Deepl es suficiente. Para descargar el archivo csv editable en Excel seleccione Descargar Metadata.cvs. Si no le ofrece directamente abrirlo con Excel, puede apretar click derecho sobre el archivo, seleccionar Abrir con, luego Excel, si no aparece seleccionamos Elegir otra aplicación, Más aplicaciones y luego Excel. A continuación, le presentamos una tabla con cada uno de los campos que debe llenar y con qué debe rellenarlos. Después de agregar la información a los metadatos solo guarde el documento desde Excel, y este se guardará automáticamente en csv delimitado por Semi-coma (;) en codificación UTF-8 (Que permite incorporar comas a los metadatos) Cabe destacar que, para el primer campo correspondiente al Identificador, antes del código entregado por OSF debe estar escrito https://doi.org/ como se muestra en el documento descargado. Esto es para cumplir con los estándares FAIR. Paso 2 Después de haber creado el documento csv con nuestra información solo debemos seleccionar al siguiente link e ir al sitio web: csvjson.com. En este sitio tenemos que apretar Select a file y buscar el documento csv creado. Posteriormente, se debe señalar output: Array y Minify, como se señala en la imagen. Con estas opciones apretamos el botón morado &gt;Convert bajo el cuadrado que posee nuestro documento CSV. Cuando esté listo apretamos el botón Download, como se señala en la Figura N° 3.1. El documento se descargará con el nombre csvjson, debe cambiarlo a metadata. Figura 3.1: Creación de documento de metadatos Paso 3 Finalmente debemos agregar los archivos csv y json al repositorio, recuerde cambiar el nombre del documento a metadata. Referencias "],["estándares-y-experiencias-internacionales.html", "3.3 Estándares y experiencias internacionales", " 3.3 Estándares y experiencias internacionales Para poder generar una ciencia social más colaborativa y eficiente, es necesario que la comunidad de las ciencias sociales compartan estándares respecto a la calidad de los datos y del almacenamiento. De este modo los trabajos de investigación y los materiales, de por sí complejos, serán más fáciles de comprender y ser utilizados por terceros. En esta sección de revisarán algunas declaraciones de instituciones relacionadas con la apertura y mantenimiento de los datos, además de documentos que fijan normas comunes para el almacenamiento. Posteriormente, se evaluan distintos repositorios a partir de los criterios de calidad sistematizados, buscando ventajas y desventajas de distintas experiencias en el almacenamiento de bases de datos de investigación social. El resultado final es una propuesta de almacenamiento acorde a los estándares internacionales y un manual que facilite a los usuarios seguir estos estándares. Los estándares internacionales revisados son los siguientes: Acceso abierto ICSU FAIR DMP 3.3.1 Estándares internacionales 3.3.1.1 Acceso abierto ICSU El Consejo Internacional para la Ciencia (ICSU, 2014) defiende los siguientes objetivos para la apertura. El registro científico debe ser: libre de barreras financieras a las que pueda contribuir cualquier investigador; libre de barreras financieras para que cualquier usuario acceda inmediatamente después de la publicación; disponible sin restricción de reutilización para cualquier propósito, sujeto a atribución adecuada; calidad garantizada y publicada de manera oportuna; y archivado y disponible a perpetuidad 3.3.1.2 Principios FAIR: Datos, Metadatos e infraestructura digital. Los principios de almacenamiento FAIR (Findable, Accessible, Interoperable, Reusable), son ampliamente reconocidos a nivel mundial. Estos principios han sido promovidos por organizaciones científicas regionales como El Foro Abierto de Ciencias de América Latina y el Caribe (CILAC) (Ramírez &amp; Samoilovich, 2019) y Europeas (EC, 2016). En Chile, la ANID del Ministerio de Ciencia, Tecnología, Conocimiento e Innovación, ha señalado que la política de acceso a datos que impulsará se guiará por los principios FAIR (para más detalles ver Capítulo V). Los principios FAIR, son sumamente compatibles con las diversas formas de información producida por las ciencias sociales, ya sean documentos de texto, audiovisuales o bases de datos. Este es un buen motivo para fomentar los principios FAIR en todos los tipos de investigaciones en ciencias sociales. El objetivo general de estos principios es que los productos de investigación estén disponibles en la web, de modo tal que puedan ser buscados directamente por investigadores o por inteligencia artificial (FAIR, 2020). A continuación, se explican estos principios y como pueden ayudar a las ciencias sociales. Los principios se refieren a tres tipos de entidades: datos (o cualquier producto de investigación como objeto digital), metadatos (información sobre ese objeto digital) e infraestructura digital (Capacidades y herramientas necesarias en repositorios web). Findable (Encontrables) El primer paso para (re) usar datos es encontrarlos. Los metadatos y los datos deben ser fáciles de encontrar tanto para humanos como para computadoras. Los metadatos legibles por máquina son esenciales para el descubrimiento automático de conjuntos de datos y servicios, por lo que este es un componente esencial para alcanzar el estándar de los principios FAIR. A continuación se enumeran cuatro características claves de los principios FAIR para encontrar los datos. F1. A los datos se les asigna un identificador único y persistente a nivel mundial. F2. Los datos se describen con metadatos enriquecidos (definidos por R1 a continuación) F3. Los metadatos incluyen de forma clara y explícita el identificador de los datos que describen F4. Los datos y metadatos se registran o indexan en un recurso de búsqueda Por un lado, los identificadores únicos eliminan la ambigüedad, facilitando que una investigación, una base de datos o cualquier producto de investigación, no sea confundido con otro producto por tener un nombre o características similares. Los ejemplos más comunes de identificadores son los URL (Localizador Uniforme de Recursos) los cuales asignan un sitio único a cada página web, como los URL www.google.com o www.youtube.com. Otro tipo de identificadores más cercano a las ciencias sociales son los ISBN (Número Internacional Normalizado del Libro) o el DOI (Identificador de Material Digital) que solemos ver asociados a los artículos de investigación. A diferencia del URL el DOI no cambia, aunque el material cambie de ubicación en la web. Así, los identificadores se asocian de forma única a los datos, como es el ejemplo de este DOI https://doi.org/10.5064/F6HTXF0H que corresponde al identificador de un conjunto de materiales y Focus Groups sobre género y participación en el desarrollo comunitario en Senegal. Estos identificadores también ayudarán a que el trabajo sea fácilmente compartido, reconocido y posea un mayor impacto. En la misma línea, facilita su citación puesto que, al ingresar estos identificadores en gestores de bibliografía como Zotero, se genera una referencia bibliográfica automática. Para generar un identificador único se pueden usar páginas especializadas que pueden encontrarse en DoiChile. También, para facilitar el trabajo, muchos repositorios de datos generarán automáticamente identificadores persistentes y únicos a nivel mundial para los conjuntos de datos depositados. Por otro lado, los metadatos son información sobre los datos. Los archivos comunes poseen metadatos automáticos, por ejemplo, Microsoft Word registra el creador y la fecha. Los principios FAIR, señalan la importancia de incluir metadatos generosos y extensos, incluida información descriptiva sobre el contexto, la calidad y condición, o las características de los datos. En ciencias sociales es importante entregar información sobre la muestra y el proceso de recopilación de datos, así como cualquier información útil para que el investigador que recurra a ellos pueda tomar decisiones correctas. Finalmente, junto con los identificadores y los metadatos, para que los datos sean fáciles de encontrar es necesario que estén disponibles en algún recurso de búsqueda. Google es el recurso de búsqueda más conocido. Para los datos de ciencias sociales es importante que estas bases de datos se encuentren disponibles en buscadores de instituciones de investigación o bibliotecas. Accesibles A1. Los datos y metadatos son recuperables por su identificador utilizando un protocolo de comunicaciones estandarizado Esto significa que los identificadores permiten la redirección a una página web específica que contiene los datos, esto se puede ver en el identificador cuando posee un http al comienzo de la URL. De este modo, basta con poner el identificador en la barra del navegador para poder acceder a la página de los datos mediante solo un click. A1.1 El protocolo es abierto, gratuito y de implementación universal Este sub-punto refiere a que la forma en que se puede acceder a la pagina web mediante el identificador es universal, es decir, cualquier persona con un computador e internet puede acceder. Lo contrario a esto sería dejar el documento en un sitio web que sea pagado o que no esté disponible a nivel mundial. A1.2 El protocolo permite un procedimiento de autenticación y autorización, cuando sea necesario Además, el modo por el cual se accede a los datos mediante el identificador puede tener algunas solicitudes o exigencias para el usuario. Así, FAIR no es sinónimo de OpenData, pues se puede tener un dato altamente restringido por distintas razones, pero si se especifican bien las condiciones para su acceso, entonces un dato no abierto puede ser FAIR. A2 . Los metadatos son accesibles, incluso cuando los datos ya no están disponibles Suele ocurrir que los datos en internet desaparecen por que mantenerlos implica un costo. Este punto señala como necesario que, pese a que desaparezcan los datos, los metadatos, que son más fáciles y económicos de almacenar, deben ser persistentes, es decir, deben mantener su existencia en la web. Interoperables Los datos normalmente deben integrarse con otros datos. Además, los datos deben interoperar con distintas aplicaciones o flujos de trabajo para análisis, almacenamiento y procesamiento. Para que esto sea posible, es necesario que los datos se encuentren en formatos que sean legibles y trabajables por distintos softwares. I1. Los datos y metadatos utilizan un lenguaje formal, accesible, compartido y de amplia aplicación para la representación del conocimiento. Para que los datos puedan ser encontrados por las herramientas como barras de búsqueda es necesario que los términos utilizados en los metadatos para describir el estudio sean parte de un vocabulario controlado, los cuales sirven para sistematizar los sinónimos dentro de un campo temático (Collins, 2015). Esto permite que, al buscar un término, por ejemplo relaciones de pareja en un repositorio de materiales de investigación también aparezcan aquellos materiales que son descritos con el término noviazgo. Los vocabularios controlados utilizados por repositorios de investigación suelen ser denominados también tesauros u ontologías. Además es necesario que los metadatos estén estructurados en base a esquemas comunes. Al respecto existen múltiples modos de organizar los metadatos como DDI, Dublin Core, JSON, entre otros. Sin la intención de profundizar en el tema es necesario señalar que no existen amplios consensos en el uso de un estándar de metadatos en ciencias sociales y humanidades (Gómez et al., 2016), por lo cual se considera adecuado que un repositorio permita almacenar los metadatos en distintos formatos. I2. Los datos y metadatos usan vocabularios que siguen los principios FAIR Es importante que los vocabularios controlados utilizados para la descripción de los datos sigan principios FAIR, es decir, posean identificadores y metadatos adecuados para poder localizar el vocabulario controlado al que se hace referencia. Un ejemplo de vocabulario controlado que sistematiza los sinónimos de distintos idiomas para journal article se puede encontrar aquí. Este ejemplo cumple en buena medida con los principios FAIR I3. Los datos y metadatos incluyen referencias calificadas a otros datos y metadatos Los datos y la información referida a ellos deben tener múltiples vínculos web que permitan acceder a información asociada. Por ejemplo, si tenemos una investigación que ha utilizado datos de una encuesta publicada, se debe hacer alusión a dicha encuesta a partir de su identificador. Del mismo modo se puede tener vínculos con instituciones asociadas, o páginas de proyectos de investigación propias o estatales. Reutilizables Los metadatos y los datos deben estar bien descritos para que puedan replicarse y/o combinarse en diferentes entornos. R1. Los datos y metadatos se describen detalladamente con una pluralidad de atributos precisos y relevantes Para que un usuario decida si utilizar los datos o no, debe contar con una gran cantidad de información detallada. Este punto es similar a F2 (Metadatos suficientes), pero destaca la importancia de información particular del campo de uso. Para ello, en ciencias sociales, es importante describir cuándo fue realizada la muestra, a quienes se le aplica, si posee control de variables experimentales, entre otras informaciones relevantes. Se debe señalar la mayor información posible, incluyendo tipo de muestreo, intención de la creación de la base de datos, entre otros. Esta información debe ser plural para fomentar el uso más allá de las ciencias sociales. R1.1. Los datos y metadatos se publican con una licencia de uso de datos clara y accesible Se recomienda en general utilizar licencias Creative Commons, estas licencias permiten a los dueños de los materiales dejar a libre disposición los datos producidos, aunque señalando aquellas condiciones en las cuales se pueden utilizar y aquellas en que no. Esta es una condición más legal que técnica para la reutilización de los datos. R1.2. Los datos y metadatos están asociados con la procedencia detallada Este punto refiere a entregar información sobre los productores y el flujo de trabajo. También en este punto se debe destacar cómo se debe citar la base de datos. Entonces, se deben responder las siguientes preguntas ¿Quién estuvo a cargo del diseño? ¿Quién a cargo del terreno y la aplicación? ¿Quién editó los datos? ¿Cómo desea que este material esté referenciado? R1.3 . Los datos y metadatos cumplen con los estándares comunitarios relevantes para el dominio Los datos y los metadatos deben estar nombrados y ordenados de modo coherente con los estándares de las ciencias sociales. Por ejemplo, las bases de datos deben estar estructuradas de tal modo que los sujetos sean las filas y las variables las columnas. La documentación que se entrega está nombrada con términos comunes, como manual de usuario o cuestionario. Según la investigación de Gómez et al. (2016), el esquema metadatos más utilizados en las ciencias sociales es el de DDC. No obstante, existe una gran divergencia respecto a cuales deben ser los metadatos incluidos. 3.3.1.3 DMP Los planes de manejo de datos (DMP) son una herramienta utilizada por la comisión europea (EC) para mejorar la producción y almacenamiento de datos producidos por investigaciones, consiste en una planificación respecto al ciclo de vida de los datos desde su creación hasta su preservación. En este sentido son una herramienta para la organización y estandarización del manejo de datos. En un documento de apoyo para investigadores la EC (2016), a modo de síntesis, proponen documentar los siguientes puntos respecto al manejo de los datos Resumen de datos Indique el propósito de la recopilación / generación de datos Explicar la relación con los objetivos del proyecto. Especificar los tipos y formatos de datos generados / recopilados Especifique si los datos existentes se están reutilizando (si corresponde) Especificar el origen de los datos Indique el tamaño esperado de los datos (si se conoce) Describa la utilidad de datos: para quién será útil Datos FAIR 2.1. Haciendo que los datos se puedan encontrar, incluidos disposiciones para metadatos Describir la capacidad de descubrimiento de datos (provisión de metadatos) Resuma la identificabilidad de los datos y consulte el mecanismo de identificación estándar. ¿Utiliza identificadores persistentes y únicos como los identificadores de objetos digitales? Esquema de convenciones de nomenclatura utilizadas Describa el enfoque hacia las palabras clave de búsqueda Describir el enfoque para versiones claras Especificar estándares para la creación de metadatos (si los hubiera). Si no hay estándares en su disciplina describe qué tipo de metadatos se crearán y cómo se hará. 2.2 Hacer que los datos sean accesibles abiertamente Especifique ¿qué datos estarán disponibles abiertamente? Si algunos datos se mantienen cerrados, proporcione justificación para hacerlo Especificar cómo estarán disponibles los datos Especifique qué métodos o herramientas de software se necesitan para acceder a los datos. ¿Es necesaria la documentación sobre el software para acceder a los datos incluidos? Es posible que incluir el software relevante sea necesario (por ejemplo, en código fuente abierto) Especificar dónde están los datos y los metadatos asociados, la documentación y el código depositado Especifique cómo se proporcionará el acceso en caso de que haya restricciones 2.3. Hacer que los datos sean interoperables Evalúe la interoperabilidad de sus datos. Especifique qué vocabularios de datos y metadatos, estándares o metodologías que seguirá para facilitar la interoperabilidad. Especifique si utilizará vocabulario estándar para todos los tipos de datos presentes en su conjunto de datos, para permitir la interoperabilidad interdisciplinaria. Si no es así, ¿proporcionará un mapeo para ontologías de uso más común? 2.4. Incrementar la reutilización de datos (mediante aclarar licencias) Especificar cómo se licenciarán los datos para permitir la mayor reutilización posible Especifique cuándo los datos estarán disponibles para su reutilización. Si corresponde, especifique por qué y por qué período se necesita un embargo de datos Especificar si los datos producidos y / o utilizados en el proyecto son utilizables por terceros. En particular después de la finalización del proyecto, si la reutilización de algunos datos es restringido, explica por qué Describir los procesos de aseguramiento de la calidad de los datos. Especifique el período de tiempo durante el cual los datos permanecerán reutilizables Asignación de recursos Estime los costos para hacer que sus datos sean FAIR. Describa cómo piensa cubrir estos costos Identifique claramente las responsabilidades de la gestión de datos en su proyecto Describir los costos y el valor potencial de la preservación a largo plazo. Seguridad de los datos Abordar la recuperación de datos, así como el almacenamiento seguro y la transferencia de datos sensibles. Aspectos éticos Para ser cubierto en el contexto de la revisión de ética, sección de ética de DoA y ética entregables. Incluya referencias y aspectos técnicos relacionados. Otro Consulte otros procedimientos nacionales / financiadores / sectoriales / departamentales para la gestión de datos. 3.3.2 Experiencias internacionales sobre el almacenamiento de datos de investigación En el presente apartado presentamos un conjunto de repositorios digitales de materiales de investigación. Se realizarán comentarios, evaluaciones y destacarán aportes de estos repositorios digitales. Para ordenar su presentación primero revisaremos aquellas experiencias internacionales que han destacado como las mejores en el ámbito. Luego veremos algunas experiencias a nivel latinoamericano y chileno, para evaluar sus fortalezas y debilidades en base a los criterios y estándares presentados en la sección anterior. 3.3.3 Exitosos repositorios internacionales ICPSR Este es un consorcio internacional de más de 750 instituciones académicas y organizaciones de investigación, el Consorcio Interuniversitario de Investigación Política y Social (ICPSR) proporciona liderazgo y capacitación en acceso a datos, curación y métodos de análisis para la comunidad de investigación en ciencias sociales. ICPSR mantiene un archivo de datos de más de 250.000 archivos de investigación en las ciencias sociales y del comportamiento. Alberga 21 colecciones especializadas de datos en educación, envejecimiento, justicia penal, abuso de sustancias, terrorismo y otros campos. Qualitative Data repository El repositorio de datos cualitativos (QDR) es un archivo dedicado a almacenar y compartir datos digitales (y la documentación adjunta), generados o recopilados a través de la investigación cualitativa y de múltiples métodos en las ciencias sociales. QDR proporciona servicios de consultoría en gestión de datos y selecciona activamente todos los proyectos de datos, manteniendo el valor y la utilidad de los datos a lo largo del tiempo y asegurando su disponibilidad y posibilidad de encontrarlos para su reutilización. Este repositorio cuenta con un identificador indicado en metadatos contundentes que además están indexados en un buscador web. También poseen un protocolo de comunicación estandarizado, además de poseer medios para la autorización del uso del material. Además, la página facilita el uso permitiendo previsualizaciones de los documentos que se encuentra abiertos, recurso que se encuentra igualmente en los otros buenos ejemplos de repositorios de datos. Otra temática importante que es trabajada por este repositorio es su apoyo en el hacer anónimos los datos, lo cual da cuenta de un compromiso por resguardar la seguridad de los investigadores y apoyarles como sugiere necesario el documento de Autoevaluación RISE. UK Data Service El Servicio de Datos del Reino Unido está financiado por el Consejo de Investigación Económica y Social (ESRC) para satisfacer las necesidades de datos de investigadores, estudiantes y profesores de todos los sectores, incluidos el mundo académico, el gobierno central y local, organizaciones benéficas y fundaciones, centros de investigación independientes, grupos de expertos y consultores empresariales y del sector comercial. La recopilación del Servicio de datos del Reino Unido incluye las principales encuestas patrocinadas por el gobierno del Reino Unido, encuestas transnacionales, estudios longitudinales, datos del censo del Reino Unido, agregados internacionales, datos comerciales y datos cualitativos. Dataverse Harvard El Proyecto Dataverse es una aplicación web de código abierto para compartir, preservar, citar, explorar y analizar datos de investigación. Facilita la puesta a disposición de los datos y le permite replicar el trabajo de otros con mayor facilidad. Los investigadores, las revistas, los autores de datos, los editores, los distribuidores de datos y las instituciones afiliadas reciben crédito académico y visibilidad en la web. De este modo, Dataverse no solo apoya el proceso de almacenamiento de materiales e información para la investigación sino que también posibilita el almacenamiento de códigos para la reproducibilidad, comprendida como la posibilidad de volver a ejecutar un análisis con los mismos datos y mismos procedimientos usualmente especificados en códigos. Un repositorio de Dataverse es la instalación del software, que luego aloja varios archivos virtuales llamados colecciones de Dataverse. Cada colección de Dataverse contiene conjuntos de datos, y cada conjunto de datos contiene metadatos descriptivos y archivos de datos (incluida la documentación y el código que acompañan a los datos). Como método de organización, las colecciones de Dataverse también pueden contener otras colecciones de Dataverse. 3.3.4 Experiencia regional LAPOP. Según su propia página web (LAPOP, 2020) LAPOP es la principal institución académica que realiza encuestas de opinión pública en las Américas, con más de 30 años de experiencia. Como centro de excelencia en investigación por encuestas, LAPOP usa enfoques y métodos innovadores con los estándares más altos para llevar a cabo encuestas nacionales; conducir estudios de evaluación de impacto, y producir reportes acerca de las actitudes, evaluaciones y experiencias de los individuos. El Barómetro de las Américas es la única encuesta comparativa y científicamente rigurosa que cubre 34 naciones incluyendo Norte, Centro y Sur América, así como también, un significativo número de países en el Caribe. Cada año publica docenas de estudios académicos de alta calidad y artículos de relevancia para la elaboración de políticas públicas. Cabe destacar que si bien esta es una experiencia de almacenamiento de datos para investigaciones, posee algunas diferencias. Por ejemplo es una plataforma solo para almacenar encuestas del proyecto LAPOP y no así de otras investigaciones afines. Por ello los servicios de clasificación de datos y priorización no son tan importantes por que no se posee un volumen tan grande de datos. Plataforma integrada de datos del MINCYT Argentina A partir de la información recopilada por el foro CILAC, se puede decir que en algunos países del continente los gobiernos están realizando esfuerzos por fomentar la apertura de los datos. Por ejemplo, en argentina, a partir de una nueva ley de Acceso abierto, se propuso una plataforma integrada para el acceso a datos. Esta plataforma entrega información sobre distintas disciplinas. Entre estos trabajos, el más cercano a las ciencias sociales son los Datos de personal de ciencia y tecnologia, que permite hacer análisis sociodemográfico de los académicos. Esta plataforma posee una previsualización y una tabla con las variables que facilita el conocimiento de los datos, los cuales están disponibles para descargar en distintos formatos. Esta previsualización se puede realizar a modo de tablas, gráficos y mapas. No obstante, la visualización mediante gráficos es relativamente ineficiente, puesto a que es difícil lograr gráficos que sean comprensibles. 3.3.5 Experiencias nacionales. Hace bastantes años que a nivel nacional se realizan esfuerzos por fomentar el registro abierto de datos. La antigua Comisión Nacional de Investigación Científica y Tecnológica (CONICYT), en la página Datos Cientificos (Programa de Información Científica, 2019), realiza una propuesta de política para datos abiertos. El primer punto de dicha propuesta exige a todos los beneficiarios de CONICYT la publicación de informes con datos producidos de la investigación. En favor de dicha política se publicaron el año 2010 y 2014 dos documentos con sugerencias para la apertura de los datos. El primero de estos informes es una revisión del estado del arte de la accesibilidad de datos (Muñoz, 2010). se destacan las siguientes recomendaciones. A partir de la experiencia de las Políticas de Intercambio de Datos Científicos en China se evidenció la dificultad de desarrollar una política nacional de gestión cuando en la cultura científica local persistió la idea de propiedad personal. Por ello, es fundamental realizar políticas de concientización respecto a los datos abiertos. En base a la recopilación de datos epidemiológicos del National Center for Health Statistics de Estados Unidos, se releva la importancia de preparar alternativas para datos sensibles. Considerando la naturaleza de los datos, es necesario en algunas ocasiones mantener los datos en la mayor confidencialidad posible. En esta línea, la organización mencionada junto con dejar los datos de acceso abierto, mantuvieron algunos datos en privado a los cuales solo se puede acceder en base a una solicitud con una propuesta de investigación y mediante una plataforma que posibilita cálculos sin permitir el acceso directo a los datos ni su transferencia. Es fundamental identificar aquellas investigaciones que requieren un resguardo mayor de datos y generar protocolos para su uso. El segundo documento, escrito el 2014, se denomina Datos Científicos Abiertos La Ciencia la hacemos entre todos, Programa de Información Científica (Hernández, 2014). Este informe posee la intención de ser un manual respecto a cómo abrir los procesos investigativos. Se destacan las siguientes recomendaciones: Utilizar una licencia de Creative Commons: permiten autorizar el uso de terceros sin perder los derechos de atribución. Utilizar repositorios interoperables: Para facilitar la recopilación automática de datos y el uso de estos desde distintos Software, se recomienda poseer buenos metadatos siguiendo los parámetros de interoperabilidad de Dublin Core. Los metadatos son los datos sobre los datos es decir aquella información que nos permite saber a qué corresponde la base de datos, quienes y cuando la crearon entre otras informaciones relevantes. Esta página propone una decena de metadatos indispensables para la interoperabilidad (Ej. creador, colaborador, editor, título, fecha, idioma, formato, tema, descripción, identificador, relación, fuente, tipo, cobertura y derechos, entre otros) (Dublin-Core, 2020). Si bien esta publicación no da cuenta de que metadatos debe ser específicamente utilizado a partir de la información anterior producida por lisa podemos decir que es beneficioso utilizar el conjunto de metadatos para social-science que es un conjunto bastante parsimonioso de información. CEP El Centro de Estudios públicos produce constantemente encuestas de opinión publica, con bastante contenido electoral. Esta es una de las bases de datos más conocidas en el campo de la sociología de Chile. Y en el último tiempo mejoro su plataforma de almacenamiento. Ahora la página posee un buscador de datos, un espacio para descargar una base consolidada longitudinal con los distintos estudios y un recurso para realizar gráficos en línea, lo cual fomenta la utilización por el público no especializado. Además, como siempre, la página cuenta con material suficiente para utilizar las bases de datos como las fichas técnicas, documentos de resultados y las bases de datos en distintos formatos (SPSS, STATA y R). Respecto a las bases de datos, es de las pocas analizadas que codificó las etiquetas de la base de datos en UTF-8. Como aspectos negativos se puede señalar que no se cuenta con recurso para descargar metadatos ni posee un identificador único Referencias "],["análisis-reproducibles.html", "Capítulo 4 Análisis reproducibles", " Capítulo 4 Análisis reproducibles En la discusión sobre los problemas de transparencia en torno a los procedimientos de investigación, se vuelve necesario precisar de qué manera es entendido el concepto de reproducibilidad en la ciencia. En esta línea, la laxitud con que se ha empleado el término ha llevado a definiciones poco claras, lo cual ha generado una tendencia a confundir lo que refiere a la transparencia de un proceso único que ya ha sido realizado, con un proceso nuevo y que puede realizarse de manera reiterativa, obteniendo los mismos resultados. Por este motivo, esta sección propone dar luces respecto a cómo entendemos el concepto de reproducibilidad, en contraste con el de replicabilidad en la ciencias sociales. La discusión en torno a cómo se entiende la reproducibilidad, habitualmente lleva al contraste respecto al concepto de replicabilidad. Al respecto Earth &amp; Behavioral (2019) mencionan que, por un lado, con el incremento de las herramientas computacionales a principios de los años 90, el término de investigación reproducible era concebido como las investigaciones que proveían un compendio detallado de la documentación, código y datos que permitieran obtener los mismos resultados publicados por los autores, enfatizando que los análisis fueran transparentes y claros con el objetivo de ser verificados por sus pares. Por otro lado, los autores sostienen que, en otras disciplinas, el concepto de reproducibilidad era asociado a investigaciones independientes entre sí en términos de los datos empleados, los materiales, métodos e implementación de un estudio, lo cual estaría orientado a robustecer o cuestionar la evidencia previa (Earth &amp; Behavioral, 2019, pp 33-34). Actualmente, a esta última práctica se la entiende como replicabilidad de una investigación y no debe ser confundida con el concepto de reproducibilidad (Barba, 2018). Barba (2018) sugiere que la confusión entre reproducibilidad y replicabilidad ha contribuido a obstaculizar las prácticas en ambas dimensiones. En una revisión reciente realizada por la autora se han identificado al menos tres escenarios o versiones de cómo se entienden ambos conceptos en una amplia gama de disciplinas que van desde las ciencias sociales hasta estudios clínicos en las ciencias médicas. El primer escenario (A), y a la vez el más común, es donde el uso de ambos conceptos es indistinto, contribuyendo a la ya mencionada confusión. El segundo escenario (B1) es cuando la reproducibilidad es entendida como la situación en que los datos originales y el código de análisis son empleados para regenerar los resultados originales, mientras que la replicabilidad es entendida cuando investigadores o equipos independientes utilizan datos nuevos para obtener los mismos resultados que la investigación previa. Finalmente, un tercer escenario (B2) es cuando la reproducibilidad es entendida cuando investigadores o equipos independientes obtienen los mismos resultados empleando sus propios datos y métodos, mientras que la replicabilidad es entendida cuando investigadores o equipos independientes llegan a los mismos resultados empleando los artefactos digitales1 originales del autor con menores o mayores modificaciones, los cuales han sido puestos previamente a disposición de sus pares. La Figura N° 4.1 ilustra cómo podemos entender los escenarios B1 y B2 en relación a la distinción entre reproducibilidad y replicabilidad. El color rojo, tanto en los datos como en los métodos, indica que los componentes empleados son idénticos a los del estudio original. Por otro lado, el color azul indica que tanto los datos como los métodos son distintos a los del estudio original. Finalmente, el color morado en los métodos se entiende como un punto intermedio y refiere a cuando se han empleado métodos que siguen las indicaciones del estudio original, pero que han incorporado modificaciones, nuevos métodos u otras innovaciones metodológicas (p. ej. métodos nuevos, pruebas de robustez u otros). Figura 4.1: Escenarios B1 y B2 en reproducibilidad y replicabilidad. En las ciencias sociales, el debate en torno a la investigación reproducible y la replicabilidad no ha estado ausente. Como fue reseñado en el capítulo de transparencia, existen casos icónicos en torno a prácticas cuestionables de investigación que han afectado la confianza en la investigación científica, lo cual ha contribuido a incrementar los esfuerzos por una ciencia social abierta y reproducible (Breznau, 2021; Nosek et al., 2015). En los tres escenarios descritos por Barba (2018), las ciencias sociales han experimentado de manera diversa el ajuste hacia una cultura de mayor apertura y precisión en torno a los problemas de la crisis de reproducibilidad, principalmente a través del estudio sistemático de dicha problemática, dentro de lo cual la psicología ha sido pionera en proveer evidencia para este debate (e.g. Open Science Collaboration, 2015; Gilbert et al., 2016). Al respecto Bishop (2019) sostiene que una de las principales amenazas para el progreso de la ciencia en general ha sido la falta de reproducibilidad de los resultados (irreproducibility), lo cual ha afectado principalmente la robustez y credibilidad de la evidencia reportada por las investigaciones, problema que también ha sido identificado en las ciencias sociales, principalmente por la falta de precisión en los procedimientos y las barreras de acceso a materiales clave del proceso de análisis (Freese &amp; Peterson, 2017). Entonces, retomando la distinción clave entre lo que entendemos por reproducibilidad y replicabilidad, en su revisión, Barba (2018) sugiere que una manera de entender y distinguir ambos conceptos de manera minimalista puede descansar en el carácter de los datos y los métodos. Al respecto Nosek et al. (2015) sostiene que en lo que refiere a estas dos dimensiones, los niveles en que una publicación los incorpora es gradual y puede entenderse como un continuo o espectro (Peng, 2011) y, por tanto, el nivel en que se cumplen bajo determinados criterios nos permite definir el carácter de una investigación en términos de su reproducibilidad. Por ejemplo, la Figura N° 4.2 nos muestra cómo podemos caracterizar una investigación publicada en torno al acceso y vinculación entre código y datos. Por un lado, se observa que en el polo donde únicamente disponemos de la publicación, se entiende como la ausencia de reproducibilidad. Por otro lado, en la medida que incrementa el acceso a los materiales, y se explicita el enlace entre ellos, se puede caracterizar a una publicación como reproducible.2 Figura 4.2: Espectro de Reproducibilidad. Traducción propia en base a Peng (2011) Como sugieren Nosek et al. (2015), el problema de la ausencia o falta de reproducibilidad debe ser abordado a través de un cambio en las prácticas de investigación, para lo cual se requiere de una disposición por parte de la comunidad científica, es decir, que se le atribuya un sentido positivo a estas prácticas. Sin embargo, Peng (2011) sostiene que una de las principales barreras para promover estas prácticas ha sido la falta de mecanismos que faciliten la distribución de la investigación reproducible, como también la poca claridad respecto de los estándares asociados a ello. Siguiendo esta autocrítica de algunos sectores dentro de la comunidad científica, dentro de los últimos años han surgido iniciativas como, por ejemplo, el Open Science Framework, al alero del Center for Open Science, desde donde se busca contribuir con herramientas para el entrenamiento y educación de la comunidad científica en general, como también proveer de una infraestructura tecnológica que facilite la transición cultural hacia una ciencia abierta, transparente y reproducible (Nosek et al., 2015). Por este motivo, proponemos revisar tres iniciativas internacionales que han puesto sus esfuerzos en la promoción de estos principios, con particular atención en la reproducibilidad de la investigación científica, y en particular de las ciencias sociales empíricas cuantitativas. Dentro de estas iniciativas encontraremos esfuerzos orientados a la educación y entrenamiento, herramientas tecnológicas y fortalecimiento de redes de colaboración. Referencias "],["qué-se-ha-hecho.html", "4.1 ¿Qué se ha hecho?", " 4.1 ¿Qué se ha hecho? 4.1.1 Berkeley Initiative for Transparency in the Social Sciences (BITSS) Objetivos y visión Esta iniciativa busca promover la credibilidad en la evidencia generada por las ciencias sociales a través de mecanismos de avanzada para la transparencia, reproducibilidad y prácticas éticas en la investigación social empírica. Desde esta premisa, se ha desarrollado y puesto a disposición de la comunidad científica una serie de herramientas en colaboración con estudiantes, investigadores, entidades académicas y fundaciones de la sociedad civil al alero de tres principios orientadores: Generar evidencia en torno a problemas y soluciones a través de los investigadores y la comunidad de BITSS, quienes han liderado investigaciones meta-analíticas, con atención en las ciencias sociales. Incrementar el acceso a la enseñanza de la ciencia abierta, a través del fortalecimiento de prácticas para reconocer y conducir investigación social transparente y reproducible a través del entrenamiento de investigadores jóvenes, acceso a materiales, apoyo financiero y la consolidación de una red de colaboración. Fortalecer el ecosistema científico, estableciendo condiciones para investigadores e instituciones para contribuir a un cambio efectivo y equitativo en las normas que permitan una consolidación de una política interna orientada a la ciencia abierta y al desarrollo de protocolos en esta dirección. Desde sus inicios, se han desarrollado una serie de componentes que buscan promover y dar soluciones a los problemas de transparencia y reproducibilidad en las ciencias sociales. En particular, nos interesa destacar algunas de las contribuciones en este ámbito que serán presentadas a continuación, las cuales se pueden resumir en Evidencia, Educación y Recursos. Contribución En el ámbito de Evidencia, desde BITSS se ha realizado un esfuerzo por producir y sistematizar evidencia centralizadamente. En este contexto existe la Research Library, una base de datos de publicaciones científicas que engloba una serie de investigaciones meta-analíticas en el ámbito de las ciencias sociales, contribuyendo con un cuerpo de evidencia sistemática en torno a los problemas y soluciones sobre transparencia y reproducibilidad en las ciencias sociales sin precedentes. En este apartado, tanto los colaboradores como investigadores de BITSS ponen a disposición de la comunidad científica las investigaciones que han sido financiadas a través de las Social Science Meta-Analysis and Research Transparency (SSMART) grants, las cuales constituyen fondos orientados a contribuir a la investigación empírica en torno a la transparencia y reproducibilidad en disciplinas como la economía, ciencia política, psicología y ciencias sociales afines. Desde la Educación y Entrenamiento podemos identificar la articulación de una serie de Training activities desarrolladas por BITSS. Dentro de los objetivos de estas actividades encontramos dos aspectos que se buscan abordar desde esta dimensión. Por un lado, se encuentra el promover una visión crítica de los investigadores en las ciencias sociales, esto considera un entendimiento de los principales problemas asociados a la investigación social de calidad al alero de los principios de la ciencia abierta, dentro de lo cual podemos encontrar los sesgos y prácticas referidas a las presiones por publicar, prácticas cuestionables de investigación, reproducibilidad y privacidad de datos. Por otro lado, se han propuesto promover el manejo de técnicas de investigación para la transparencia y reproducibilidad, principalmente a través de actividades de entrenamiento con un foco en el aprendizaje e implementación de herramientas y métodos. En esta línea destacan dos contribuciones que se fundamentan en estos principios, las cuales serán descritas a continuación. Research Transparency and Reproducibility Training Una de las contribuciones señaladas es el Research Transparency and Reproducibility Training (RT2), el cual constituye uno de los principales eventos académicos realizados anualmente por BITSS, teniendo por objetivo el poner a disposición de estudiantes e investigadores una mirada general de las herramientas y prácticas actuales para la transparencia y la reproducibilidad en la investigación empírica en ciencias sociales. Los contenidos de RT2 abordan una serie de tópicos de manera transversal que pueden ser ilustrados en seis puntos: Amenazas para la credibilidad en la ciencia y la reproducibilidad, junto con su relación con el ethos científico: Conducta y valores en la ciencia. Mejoras en las especificaciones de los diseños de investigación: pre-registros y plan de pre-analysis en investigación con datos experimentales y observacionales. Ética e investigación abierta: estándares éticos para la ciencia abierta, manejo de datos y autoría de fuentes de información abiertas (citación). Herramientas y métodos para la investigación reproducible y colaboración: control de versiones y reportes dinámicos. Sistematización de evidencia, reproducibilidad e interpretación: métodos para investigación meta-analítica y revisiones sistemáticas, transparencia y reproducibilidad usando datos administrativos; y replicabilidad en la investigación. Software para la Ciencia Abierta e innovaciones metodológicas. MOOC: Transparent and Open Social Science Research Otra de las contribuciones es el Transparent and Open Social Science Research que corresponde a un curso gratuito online de cinco semanas el cual aborda los fundamentos conceptuales y las principales herramientas para promover una ciencia social abierta y transparente. La Tabla 4.1 muestra el contenido de las sesiones, las cuales se basan en un curso de nivel de grado dictado por el director de BITSS Ted Miguel en la Universidad de California Berkeley. Tabla 4.1: Cursos por semana en el MOOC de BITSS Semana Contenido 1 Introducción a la transparencia y reproducibilidad de la investigación 2 Sesgo de publicación 3 Pre-registro, Plan de Pre-Análisis; y Meta-análisis 4 Replicación y Datos Abiertos 5 Visualización de Datos transparente y Viendo hacia adelante Una de las principales características de este curso introductorio es la sistematización de aspectos claves para la ciencia abierta con un foco particular en las ciencias sociales. Adicionalmente, tiene el objetivo de introducir conceptualmente a los problemas que se han visto presentes en las ciencias y busca dar respuestas a prácticas a través de herramientas y métodos concretos para solucionarlo. Finalmente, constituye un esfuerzo breve y preciso, dado que las sesiones semanales poseen una duración promedio de unos treinta minutos y se encuentran dosificadas en videos de corta duración subtitulados. En el ámbito de los Recursos que provee BITTS, podemos encontrar una librería de recursos o simplemente la Resource Library, la cual incluye una multiplicidad de recursos de aprendizaje digitales en torno a la transparencia y reproducibilidad, ordenados según (i) Tópico, (ii) Tipo y (iii) Disciplina de las ciencias sociales. La Figura 4.3 muestra cómo se visualizan los tópicos disponibles en la librería, lo cual puede ser ordenado según tipo y disciplina. Figura 4.3: Librería de Recursos de BITSS 4.1.2 Proyecto TIER (Teaching Integrity in Empirical Research) Objetivos y visión El proyecto TIER es una iniciativa respaldada por la Fundación Alfred Sloan que se propone contribuir a un cambio en las normas y conductas profesionales en torno a la transparencia y reproducibilidad en la investigación empírica en las ciencias sociales. Uno de los principios orientadores de sus actividades es el proveer formación en herramientas para la documentación oportuna de procedimientos que involucren datos estadísticos a través de rutinas y referencias que garanticen la reproducibilidad de estos. La idea subyacente que motiva estas acciones es que los autores puedan concebir la documentación como un componente esencial de la comunicación de sus resultados con sus pares, como también al público no especializado, de modo tal que estas medidas contribuyan a incrementar la confianza y credibilidad en la evidencia científica. En esta línea, su declaración de principios sostiene que su objetivo se puede considerar como logrado cuando: () no proporcionar documentación de replicación para un estudio empírico se considere tan aberrante como escribir un artículo teórico que no contenga pruebas de las proposiciones, un artículo experimental que no describa las condiciones de tratamiento o un artículo de revisión de leyes que no cite los estatutos legales o las decisiones judiciales. (traducción propia) Contribución Es necesario tener presente que uno de los principales campos de acción del proyecto TIER es la Educación y Entrenamiento hacia cientistas sociales en formación, tomando en consideración que es en el ciclo formativo inicial donde se deben impulsar la adopción de prácticas integrales para la investigación social empírica. En esta línea, uno de los elementos destacables es la sección de herramientas para la enseñanza titulada TIER in the Classroom, sus contenidos referidos a temas de reproducibilidad se pueden resumir de la siguiente manera: Soup-to-Nuts Exercises: No existe una traducción en el español, no obstante la expresión Soup-to-Nuts refiere a un proceso de inicio-a-fin. Como lo dice, esta sección muestra ejercicios orientados a la reproducibilidad de los análisis pasando por (1) los datos, (2) procesamiento, (3) análisis y (4) reporte. La idea fuerza de este ejercicio es introducir a estudiantes a los principios y prácticas fundamentales de la investigación social transparente y reproducible para que los implementen en sus tareas o informes. Materiales para clases: Esta sección está fuertemente orientada al análisis estadístico y a los métodos cuantitativos. Se presentan una serie de veinticuatro cursos de pregrado y postgrado que incorporan en su currículum los principios de transparencia y reproducibilidad en la enseñanza de los métodos de manera transversal. Los materiales de cada curso se encuentran disponibles para libre descarga, incorporando ejercicios de análisis estadístico (R, Stata, SPSS), reportes dinámicos (R Markdown, Markstat) y sus respectivos syllabus. Trabajos estudiantiles: En esta sección se incorporan una serie de trabajos estudiantiles/papers, los cuales están acompañados de una completa documentación basada en el Protocolo TIER (ver detalle abajo). El objetivo es presentar modelos de trabajos realizados con análisis reproducibles, de modo tal que quien esté interesado en emplear la estructura de un proyecto pueda observar un trabajo real e, idealmente, logre reproducir completamente sus resultados. Una de las contribuciones más relevantes del proyecto TIER es la elaboración de estándares para la organización, publicación y comunicación de proyectos de investigación empírica cuantitativa reproducible. Al respecto, existen dos esfuerzos orientados a este fin: Por un lado tenemos el Protocolo TIER, el cual constituye una serie de especificaciones respecto a los contenidos de la documentación para la replicación de un estudio, el cual está orientado a ser empleado para la enseñanza de la investigación que incorpore la reproducibilidad de los análisis. En este caso es importante precisar, como ya hemos identificado en un principio, que el concepto de replicación se emplea como sinónimo de reproducibilidad, entendiendo este último como la conjunción de datos y métodos originales que nos permitan regenerar los resultados de un estudio que ha sido publicado. Por lo tanto, cuando en TIER se habla de replicación se refiere a esta idea. La documentación debe incluir una serie de elementos descritos a continuación. Datos empleados por el proyecto Rutinas de código escrito en el software empleado para la preparación y análisis estadístico. Esto se incluye dado que el objetivo es proveer los datos brutos a procesar, junto con todas las instrucciones que permiten regenerar los resultados reportados en el estudio. Fuentes de información que contribuyan a comprender detalladamente cada sección del estudio de inicio a fin. Por otro lado tenemos el Protocolo DRESS (Documenting Research in the Empirical Social Sciences). Al igual que el Protocolo TIER, se incorporan los mismos estándares para la documentación de una investigación transparente que incorpore la reproducibilidad de los análisis. Sin embargo, este se encuentra adaptado a los propósitos de los investigadores profesionales, más que para el uso de los estudiantes durante su formación en investigación. 4.1.3 UK Reproducibility Network (UKRN) Objetivos y visión La UK Reproducibility Network (UKRN) es un consorcio institucional del Reino Unido que tiene por objetivo promover los principios y prácticas de la ciencia abierta con una mirada local, es decir, en las instituciones nacionales y sus investigadores. Para contribuir a este objetivo se realizan esfuerzos en torno a la investigación de los factores que determinan una investigación abierta y robusta, promoviendo el entrenamiento a través de actividades abiertas y diseminando las buenas prácticas para una ciencia abierta. En particular, se proponen profundizar en los factores que determinan la carencia de reproducibilidad y replicabilidad, para lo cual se busca: Desarrollar aproximaciones que contrarresten esta falta de transparencia. Incrementar la confianza y la calidad de la investigación científica. Abordar de manera transversal estos problemas en las distintas disciplinas científicas. Avanzar hacia un cambio cultural en la ciencia y transformar las prácticas de quienes la desarrollan. La UKRN se caracteriza por un trabajo en red, es decir, por un importante componente de vinculación entre instituciones de investigación asociadas a universidades como también a oficinas gubernamentales que desarrollan investigación (ver External Stakeholders). En esta línea, existen diversas iniciativas apoyadas por la UKRN que promueven el entrenamiento, metodologías y recursos tecnológicos para la ciencia abierta. A continuación se presentarán algunas de las contribuciones más relevantes realizadas por la red, como también algunas de las iniciativas externas que han sido respaldadas por la UKRN. Contribución En el ámbito de la Educación y Entrenamiento, es posible identificar, por un lado, las contribuciones realizadas directamente por la UKRN y, por otro lado, las iniciativas que son respaldadas por la red y que promueven la formación en torno a los principios y prácticas de la ciencia abierta, particularmente en la etapa temprana de la carrera de investigación. Respecto a una de las iniciativas elaboradas por los académicos e investigadores involucrados en la UKRN, encontramos uno de los principales recursos virtuales en un breve curso online que aborda una serie de tópicos relevantes para la promoción de la ciencia abierta, dentro de lo cual encontramos el uso de pre-prints, autorías, registered reports, datos abiertos y reproducibilidad. A continuación se puede observar la lista de sesiones que han sido desarrolladas en torno a estos temas. Junto con las sesiones, existe una serie de recursos compartidos a través de un proyecto abierto en el Open Science Framework. Aquí es posible acceder a documentos breves que abordan los tópicos de cada sesión, además de recursos adicionales sobre uso de software de código abierto y repositorios. Un ámbito de desarrollo ha sido la disposición de recursos tecnológicos que promuevan y faciliten las prácticas en ciencia abierta. Una de las iniciativas impulsadas es el Open Research Calendar, el cual consiste en un instrumento colaborativo y abierto que busca brindar a la comunidad de investigadores interesados en temas relacionados a la ciencia abierta un flujo constante de actualizaciones en torno a workshops y conferencias a nivel mundial que abordan tópicos sobre ciencia abierta unificados en un calendario. El carácter colaborativo de esta herramienta permite que usuarios previamente registrados y validados puedan contribuir con información que se centraliza en el calendario de eventos, precisando los contenidos y redireccionando a la inscripción y/o enlace para las actividades que se realizan a través de internet. Para facilitar la experiencia de usuario, el calendario se integra con Google Calendar que puede sincronizarse con la agenda personal y que se van actualizando automáticamente. Otra herramienta tecnológica patrocinada por la UKRN es la plataforma Octopus. A la fecha, la plataforma se presenta como una aplicación en desarrollo y abierta a comentarios de los usuarios. En términos generales se propone ser una alternativa para contribuir a la apertura de publicaciones. El detalle se presenta así: () sustituir a las revistas y los artículos como lugar para establecer la prioridad y registrar su trabajo con todo detalle, Octopus es de uso gratuito y publica todo tipo de trabajos científicos, ya sea una hipótesis, un método, datos, un análisis o una revisión por pares (traducción propia). La Figura 4.4 ilustra un ejemplo de cómo se ve un proyecto en Octopus. Vemos que existen siete componentes que buscan representar el flujo de una investigación. Entendiendo que los procesos de investigación no son lineales y tienden a existir iteraciones entre teoría y métodos, la virtud del registro y publicación de un proyecto permite que otros puedan conocer y evaluar nuestras hipótesis, plan de análisis, resultados y versiones de un artículo, así como también la vinculación entre cada sección. Figura 4.4: Ejemplo de un trabajo registrado en desarrollo en octopus.org Para publicar debemos ingresar con una cuenta de ORCID. Si no tienes una cuenta puedes crear un perfil aquí. Luego, se deben seguir tres pasos. El primero es elegir qué tipo de componente se desea publicar (Problema, Hipótesis, Métodos, etc). Segundo, dar detalles sobre el componente y con qué otros proyectos se relaciona. Finalmente, contribuir con un borrador de escritura que luego será publicado. "],["herramientas-para-los-análisis-reproducibles.html", "4.2 Herramientas para los análisis reproducibles", " 4.2 Herramientas para los análisis reproducibles Generalmente, cuando se habla de reproducibilidad se toma en consideración su dimensión computacional, esto es, el trabajo con código. Como investigadores de las ciencias sociales empíricas y promotores de la ciencia abierta creemos que efectivamente este es el núcleo de la reproducibilidad, sin embargo no es su única acepción. La mera existencia de un código de análisis no nos garantiza que un proyecto sea reproducible per se, dado que es importante tener en consideración cómo es que distintos elementos del proyecto se relacionan entre sí para regenerar los resultados de un trabajo publicado. Considerando esto, es que dividiremos esta sección presentando un flujo de trabajo reproducible con cuatro características: Estructura del proyecto Documentos dinámicos Control de versiones Prácticas de código Veamos cada uno de ellos. 4.2.1 Estructura del proyecto Una de las principales cosas que debemos considerar al elaborar un proyecto es su estructura de carpetas y archivos, con el fin de que esta nos permita entender e identificar los archivos existentes y rol en el flujo de trabajo. En este sentido, una de las herramientas que han sido desarrolladas son los denominados Protocolos (p. ej. TIER, DRESS, IPO), los cuales brindan una serie de orientaciones referentes a estructura digital de carpetas, documentación de archivos y rutinas para conseguir el anhelado objetivo de los análisis reproducibles. Para esto, es posible mencionar una serie de orientaciones generales referentes a dichos procedimientos, por ejemplo en el Proyecto TIER (TIER, 2020) se han desarrollado protocolos orientados a la reproducibilidad de los análisis, los cuales se fundamentan en tres principios que se describen a continuación. Reproducibilidad: La documentación debe permitir regenerar completamente los resultados del estudio original. En primer lugar, se debe comenzar con los datos originales brutos idénticos a aquellos con los que el autor comenzó la investigación. Luego, la posibilidad de realizar las mismas rutinas de código para preparar los datos finales para el análisis. Finalmente, se debe disponer de las rutinas de código que permitan regenerar los mismos resultados publicados, por ejemplo, las tablas o figuras presentes en la investigación. Independencia: Toda la información necesaria para regenerar los resultados del estudio debe estar presente en la documentación. Esto refiere a que no debe ser necesario solicitar ninguna información adicional al autor original. Realismo: La documentación debe estar organizada y presentada con suficiente claridad para que bajo un criterio realista, sea factible que un investigador independiente con un nivel de expertise razonable tenga la posibilidad de regenerar completa e independientemente los resultados del estudio sin mayores dificultades. Teniendo en cuenta lo anterior, la forma en que se encuentran organizadas las partes de un proyecto es fundamental para cumplir a cabalidad con lo que se propone cada principio. Como vimos en la sección previa, es posible entender la reproducibilidad como un espectro que involucra una tríada de tres elementos: Datos, Métodos y Resultados. ESQUEMA: Datos - Métodos - Resultados Este esquema es una síntesis que hacemos de algunos de los protocolos más usados en las ciencias sociales. Más que proponer un protocolo nuevo, buscamos describir los elementos fundamentales que contiene una estructura de proyecto reproducible y que están presentes de alguna u otra forma en la mayoría de los protocolos. 4.2.1.1 Carpeta raíz Antes de detallar los tres elementos que se deben considerar para avanzar en el espectro de reproducibilidad, es importante partir de una base. Esta es la que en distintos protocolos y otras herramientas para la reproducibilidad se conoce como la carpeta raíz (root). La carpeta raíz es donde se alberga toda la documentación de referencia general para el proyecto, lo que abarca desde bases de datos hasta el cuestionario u otros documentos similares. La carpeta raíz es el punto de partida para poder emplear otras prácticas para la reproducibilidad. A modo de ir avanzando en el espectro de reproducibilidad, es importante tener en consideración dos principios en relación con la carpeta raíz: documentar y orientar. La documentación implica exponer ordenadamente el contenido del proyecto completo de manera jerárquica, es decir, el contenido de subcarpetas y su funciones. En cambio, orientar implica conducir una correcta ejecución de las rutinas que permitan regenerar los resultados de la investigación. Una carpeta base que logre considerar estos principios debe tener los siguientes contenidos: Detalle de la base y las subcarpetas organizadas según su contenido. Una manera amigable de representar esta estructura es a través de un árbol de directorios, el cual ilustra la jerarquía de las carpetas y los principales archivos contenidos. Instrucciones para la configuración del paquete estadístico necesario para ejecutar las rutinas de código. Esto considera el número de versión del software, los complementos necesarios que sean adicionales al paquete estándar y cualquier otra información especial sobre el software que el lector necesite conocer para reproducir los resultados del estudio. Instrucciones de inicio-a-fin para regenerar los resultados a través de referencias directas al uso de los archivos de procesamiento de datos en la preparación y análisis. En este apartado se deben incluir detalladamente los objetivos de cada rutina de código de manera independiente. Los contenidos descritos se deben incluir en un archivo que lleve de nombre readme.md/txt/pdf. Una sugerencia de estructura interna de este documento es la siguiente: Estructura y contenido del proyecto reproducible Esquema tipo Árbol de directorios Descripción de cada subcarpeta, sus archivo y roles Instrucciones y rutinas de ejecución de resultados Instrucciones para configuración del software Instrucciones para la ejecución de rutinas de código de inicio-a-fin Con este archivo readme.md/txt/pdf ya contamos con el primer gran paso hacia la reproducibilidad: nuestra carpeta raíz está bien documentada y logra orientar bien a cualquier tercero que quiera reproducir nuestra investigación. Con esto descrito, pasaremos a detallar los tres elementos a considerar para adoptar un enfoque reproducible en un proyecto (Datos-Método-Resultados) 4.2.1.2 Datos En la ciencia trabajamos con datos, ya sean cualitativos o cuantitativos, primarios o secundarios. Si nos desempeñamos como científicos analizaremos datos con tal de sacar conclusiones relevantes para el avance del conocimiento. Es por esto que el cómo albergamos y documentamos los datos para nuestro estudio es uno de los primeros puntos a considerar para adoptar un enfoque orientado hacia la reproducibilidad. El objetivo es que cualquier persona sea capaz de comprender nuestros datos y utilizarlos para reproducir nuestros análisis. Si bien los protocolos varían de acuerdo a cómo se organizan los datos dentro de la carpeta raíz (i.e. en qué carpeta se alojan), algo que suele ser común entre los protocolos y que es relevante de recalcar acá es la diferenciación entre los datos originales o crudos (raw data) y los datos procesados. Los datos originales son aquellos que no han sufrido ningún tipo de modificación, en contraste a los datos procesados. El albergar ambas bases de datos permite comprender de mejor forma las modificaciones que se hicieron y las decisiones que se tomaron. Al igual que con la carpeta raíz, sugerimos ciertas prácticas de documentación y orientación para que el proyecto sea reproducible. Presentamos el detalle para los datos originales y los datos procesados. Para toda fuente de datos original, se debe proveer la siguiente información: Citación bibliográfica en un formato estándar (p. ej. American Psychological Association, Chicago, etc). Sugerimos revisar el componente de Datos Abiertos para la publicación de datos. La fecha de creación de la base de datos o el día en que se accedió por primera vez por parte del autor (en caso de que sean datos secundarios). Una descripción respecto a cómo se puede acceder a una copia de esta base de datos. Se debe ser lo suficientemente claro como para que un usuario independiente pueda acceder a los datos sin requerir información adicional. Un libro de códigos de todas las variables de la base de datos. Sugerimos revisar el apartado ¿Cómo hacer un libro de códigos?. Para toda fuente de datos procesada, es posible identificar dos tipos: Base de datos intermedia, la cual contiene información que, por un lado, puede ser complementaria con una base de datos principal. Por ejemplo, tenemos una base de datos con información de individuos pertenecientes a zonas/territorios (regiones o países), a la cual necesitamos incorporar información adicional que proviene de fuentes externas. En este caso, podemos generar una base procesada intermedia, para luego proceder a combinar ambas fuentes de datos. Base de datos final, es una versión final de una base de datos que contiene las variables completamente procesadas para realizar los análisis. En estos casos se sugiere proveer la siguiente información: Libro de códigos de la base procesada. Para ello, las variables deben estar correctamente etiquetadas. Fecha de creación y versión de la base de datos procesada. 4.2.1.3 Métodos Con los métodos nos referimos a toda información del proyecto relacionada al trabajo con los datos, específicamente al procesamiento y el análisis de datos. Ambas actividades pueden ser albergadas en un mismo archivo, no obstante e independiente del protocolo que se use, sugerimos separar ambas actividades en documentos distintos. Esto hará mucho más fácil la lectura del proceso de toma de decisiones, especialmente si son archivos de código. De esta manera, cualquier tercero podrá entender el proceso, evitando lo más posible que emerjan preguntas tipo ¿y de dónde salió esta variable?. En esta sección presentamos un flujo tanto para el documento de procesamiento como para el de análisis. Independiente del software estadístico que usted esté utilizando, será capaz de adherir a este flujo para hacer estas actividades de forma más ordenada. El procesamiento de los datos cumple una función muy importante para el desarrollo de un artículo: la de procesar los datos que darán paso a los análisis del estudio. Considerando eso, el objetivo final de este documento es generar una base de datos procesada, que contenga solamente los datos importantes para analizar. El flujo puede ser: Cargar la base de datos original: Cargar la base de datos original es el punto de partida para el procesamiento de los datos, y como tal, es muy importante que esta acción sea reproducible. En softwares como R, podemos hacer esta acción de manera reproducible al cargar los datos directamente de la web. Si esta no es una opción, podemos dejar bien documentado la forma en que se debe cargar la base de datos. Revisar la base de datos: Una vez cargada la base de datos original, recomendamos siempre revisar para que todo esté en orden. Cuando decimos ver que todo esté en orden nos referimos a diagnosticar si la base ha sido correctamente cargada. Por ejemplo, a veces podría suceder que la base de datos está en formato .csv con las columnas separadas por punto y coma (;) y nosotros la cargamos en el formato tradicional (,). Seleccionar las variables que se utilizarán: Generalmente no ocupamos todas las variables dentro de una base de datos, en especial en la investigación basada en encuestas con datos secundarios. Es por eso que el comienzo del procesamiento de datos consta de seleccionar las variables que utilizaremos para los análisis. Renombrar las variables: Si bien no es estrictamente necesario renombrar las variables, sí se recomienda para facilitar tanto el propio trabajo cómo el de alguien que vaya a emplear el mismo código. Generalmente, en la investigación de encuestas con datos secundarios nos encontramos con grandes bases de datos, con nombres técnicos y poco autoexplicativos. La principal recomendación aquí es cambiar estos nombres por nombres cortos y autoexplicativos. Procedimientos a realizar por cada variable: Una vez hemos cumplido con los aspectos generales del procesamiento, podemos pasar a la revisión de variable a variable. Aquí proponemos el siguiente flujo: Descriptivo inicial: calcular una tabla de frecuencias o de medidas de tendencia central y dispersión para conocer el estado de la variable previo a cualquier modificación. Recodificación: aquí se toman las decisiones respecto a la recodificación de los datos perdidos y otro tipo de valores a modificar (e.g. errores de tipeo). Es importante que las decisiones sobre la recodificación queden bien estipuladas y transparentadas. Por ejemplo, en caso de hacer imputación en alguna variable, dejarlo comentado en el código. Etiquetado: el etiquetado es una forma simple y eficiente de poder dar más información acerca de una variable. En el caso de bases de datos sobre encuestas, generalmente una base bien documentada trae etiquetas predeterminadas que hacen alusión a las preguntas del cuestionario. Es importante tener en consideración que no todos los softwares soportan el etiquetado en las bases de datos, en esos casos es útil elaborar un libro de códigos para nuestra base de datos procesada. Descriptivo final: recomendamos que, posterior a haber hecho las recodificaciones correspondientes, revisar de nuevo las frecuencias o las medidas de tendencia central de las variables, para diagnosticar que no hemos cometido errores en el procesamiento. Por dar un ejemplo, un error común, es etiquetar mal las categorías de la variable, lo que tendría un impacto directo en la interpretación de los datos. Otros ajustes: en esta última parte del flujo por variable, recomendamos efectuar toda modificación específica y relevante para la forma que analizaremos los datos. Por ejemplo, si fuésemos a construir un índice con algunas de las variables. El seguir este flujo de manera sistemática facilitará la lectura tanto para terceros, como para nosotros mismos en el futuro. Una vez contamos con nuestra base de datos procesada podemos analizar los datos. En el documento de análisis de datos se procede a elaborar todas las tablas, gráficos, pruebas estadísticas etc. que vayan a ser introducidos en el artículo final. Es importante que se piense en este documento como un reporte de análisis en sí mismo, es decir, debe estar dirigido al público y no solo ser un documento de trabajo interno para el equipo de investigación. Al igual que para la sección de procesamiento de datos, aquí también recomendamos un flujo de trabajo para hacer el trabajo -y el código- reproducible y eficiente. Dividimos el flujo en dos secciones, primero, una que contenga los análisis necesarios para probar las hipótesis de investigación. Segundo, una sección con análisis secundarios y/o exploratorios que sean relevantes para lo que el artículo busca plantear. Efectuar análisis descriptivos univariados de los datos. Es ideal una tabla única que sintetice el comportamiento de las variables de interés. Efectuar análisis correlacional de los datos. Es una primera aproximación a las hipótesis, además de ser esquemático. Por ejemplo, el uso de matrices de correlación o de nubes de puntos. Efectuar análisis multivariados. Modelos que suelen ser la principal herramienta para poner a prueba las hipótesis. Efectuar análisis exploratorios. Esto en el caso que se quieran explorar relaciones o patrones que no fueron previamente hipotetizados. Documentación Para una correcta comprensión de los documentos de procesamiento y análisis es importante tener una descripción adecuada de cada una de sus partes, o dicho de otra forma, una correcta documentación. Es relevante precisar de qué manera estos documentos se vinculan con otros archivos dentro del proyecto, para lo cual podemos tomar el ejemplo del Protocolo IPO. Por un lado, el documento de preparación requiere de una fuente de datos inicial, por tanto está directamente relacionada con la carpeta Input y la subcarpeta de datos originales. Por otro lado, el documento de análisis requiere de una fuente de datos procesada, por tanto está directamente relacionada con la carpeta Input y la subcarpeta de datos procesados. Para una correcta ejecución de las rutinas de código, es importante describir adecuadamente la relación entre los archivos de preparación y análisis. Para ello, se sugiere incorporar un archivo de nombre readme-proc.md/txt/pdf, en donde se describa brevemente dicha vinculación. Para ello sugerimos los siguientes puntos a describir: Para la ejecución de la preparación, precisar la ubicación de la o las fuentes de datos originales. (p.ej. input/data/original/original-data.dta) Para el cierre de la preparación, precisar la ruta donde se deben almacenar la base de datos procesada y su extensión (p.ej. input/data/original/proc-data.RData) Para la ejecución de los análisis se debe precisar el origen de la base procesada que fue creada en el punto 2. Para los archivos de resultados provenientes del análisis de los datos, tales como figuras o tablas, debemos precisar la ruta donde se almacenarán y su nombre. 4.2.1.4 Resultados Con los resultados, nos referimos a las figuras, gráficos o tablas que son producto de nuestro análisis y que serán relevantes de alguna forma para el estudio. Comúnmente, los protocolos para la organización de las carpetas proponen que todo lo que esté relacionado a los resultados se guarde en una carpeta aparte. Por ejemplo, el protocolo IPO propone albergar tablas y figuras en las subcarpetas tables e images dentro de la carpeta output. Tomando como ejemplo el uso del protocolo IPO, sugerimos que para una correcta identificación de cada archivo se sigan las siguientes indicaciones: Para las imágenes, sugerimos usar nombres breves e incorporar numeración. Por ejemplo figura01.png, según el orden de aparición en la publicación. Para el caso de los cuadros o tablas, existen distintas extensiones para almacenarlas como archivos independientes (tex/txt/md/html/xls). Para ello, sugerimos emplear nombres cortos e incorporar numeración. Por ejemplo, tabla01.xls, según el orden de aparición en la publicación. 4.2.2 Texto plano y documentos dinámicos Adoptar ciertas prácticas en lo que respecta a la estructura de un proyecto es el primer paso en el espectro de reproducibilidad. El segundo paso que proponemos acá es el uso de texto plano y documentos dinámicos. Probablemente, el programa que más se ha utilizado para la escritura, desde la formación de pregrado hasta el trabajo cotidiano como investigador, sea Microsoft Word. Sin duda, es una herramienta sumamente útil, cuenta con varias funciones que permiten ordenar y hacer más estéticos nuestros documentos, no obstante, no es reproducible. Aunque Microsoft Word sea un formato de archivo ampliamente conocido, necesitamos algún tipo de lector asociado al formato .docx (u otro similar) para poder leer los archivos. Esto implica que solamente las personas que tengan instalado algún lector para este tipo de documentos serán capaces de acceder al contenido, lo cual va en contra de la idea de reproducibilidad. Ahora, también es cierto que el formato de Word está tan extendido, que es realmente difícil que alguien no tenga disponible un lector de este tipo de archivos. Sin embargo, el real problema está con quien es dueño de ese contenido. Acá no nos inmiscuimos en temas de propiedad intelectual, pero sí es importante hacerse la pregunta sobre quién es dueño de lo que escribimos si el medio por donde estamos escribiendo no es propiedad nuestra. Es cosa de imaginarse que, de un día para otro, todo programa asociado a Microsoft desapareciera por alguna razón: todos nuestros documentos quedarían obsoletos. Aquí es donde entra el texto plano. El texto plano es, simplemente, un tipo de texto que se puede leer independiente del lector que se use. Un ejemplo simple es escribir en el bloc de notas de Windows. El texto plano es importante cuando buscamos avanzar hacia la reproducibiliad por dos razones. Primero, es un tipo de texto universal, lo que da la ventaja de que, en principio, cualquier persona será capaz de leer algo escrito en este formato. Segundo, sienta las bases para que surjan lenguajes que permiten sofisticar el formato de los documentos, pero que sigan teniendo el carácter universal del texto plano. Los ejemplos más conoocidos son LaTeX y Markdown. La descripción en detalle del lenguaje LaTeX y Markdown no son objetivo de este capítulo, pero sí es importante tenerlos en cuenta ya que han dado paso a una de las herramientas más utilizadas en la ciencia abierta: los documentos dinámicos. Estos son documentos que incluyen, a la par, texto plano y código. Es decir, ya no es necesario que utilicemos una hoja de código para generar un gráfico y luego pegarlo en un documento Word para escribir nuestro artículo, sino que podemos hacer todo esto en un mismo archivo. Además de hacer nuestro flujo de trabajo más eficiente, también hace más fácil reproducir los archivos. Por ejemplo, si quisiéramos que un colega revisara nuestro artículo, bastaría con que le enviáramos el documento dinámico que contiene tanto el código como el escrito. Así, él podría revisar la escritura del documento, y además, evaluar si los análisis han sido efectuados correctamente. Las distintas formas de documentos dinámicos dependen del software que se vaya a emplear para la programación del código. Según Schindler et al. (2021), los softwares más usados en las ciencias sociales actualmente son R y Stata, por lo que presentaremos un resumen de sus respectivos formatos de documentos dinámicos: RMarkdown y Stata Markdown. También, Python ha sido indiscutiblemente uno de los lenguajes de programación más utilizados en el último tiempo y no solo por científicos sociales. Es por esto que también presentaremos su versión de documento dinámico: Jupyter Notebook. RMarkdown RMarkdown es un tipo de documento dinámico que combina código de R con lenguaje marcado tipo Markdown (para aprender a usar Markdown click aquí). En los documentos de RMarkdown, todo lo que escribamos en el documento, el software asumirá que está en formato Markdown, por lo que si utilizamos alguna de las marcas (e.g. usar negrita en alguna palabra) en el documento final esa marca se hará efectiva. Cuando queremos utilizar código debemos escribirlo en bloques o chunks. Los chunks de código tienen distintas opciones, solo por dar un ejemplo, podemos escribir un código para elaborar un gráfico, pero no queremos que se muestre el código que se utilizó para elaborar el gráfico, pues los chunks nos dan la opción para lograr eso. Caso contrario, si queremos mostrar tanto el gráfico como el código para elaborarlo -por ejemplo, para que alguien revise si hemos cometido algún error-, los chunks de código también tienen una opción para eso. En suma, podemos utilizar las distintas marcas de edición que nos ofrece Markdown, así como las distintas opciones para los chunks de código, con tal de elaborar un documento tal y como nosotros lo queremos. Para más información sobre RMarkdown, ver el enlace aquí. La característica más importante de RMarkdown, es que la combinación del lenguaje marcado y el código se da en un documento renderizado. Renderizado significa que pasa por un proceso en el que se reconocen las distintas indicaciones de marcas y código, dando como resultado final un documento html, pdf o word. La herramienta encargada de este proceso es Pandoc, un convertidor de documentos universal (para más información ver: https://pandoc.org/) Stata Markdown Si bien en Stata han emergidos varios paquetes que buscan apoyar la elaboración de documentos dinámicos (e.g. ver aquí), el comando Markstat es quizás el más conocido. Al igual que otros tipos de documentos dinámicos, Markstat combina lenguaje Markdown con código de Stata, la principal diferencia con RMarkdown es que el código no se ejecuta en chunks, sino que está separado del texto plano con indentaciones. Es importante tener en cuenta que para ejecutar Markstat debemos tener instalado Pandoc. Para más información sobre cómo utilizar Markstat ver aquí. Jupyter Notebook Jupyter Notebook es un tipo de documento dinámico que combina lenguaje marcado tipo Markdown con código de Python. Al igual que RMarkdown, todo lo que escribamos en los Jupyter Notebook será considerado como lenguaje marcado. La diferencia que tiene con RMarkdown es que el documento va renderizando las marcas e indicaciones de código en tiempo real. Es decir, si escribimos en negrita, títulos de distinta jerarquía o añadimos gráficos o tablas el documento lo mostrará inmediatamente. Para más información sobre cómo utilizar Jupyter Notebook ver aquí. 4.2.3 Control de versiones El control de versiones es la tercera herramienta para la reproducibilidad que queremos presentar. Esas son herramientas de software para gestionar los cambios en los documentos. ¿Alguna vez has utilizado Google Docs para trabajar colaborativamente? Pues, este es un ejemplo cotidiano del control de versiones. Google Docs permite rastrear quién hizo qué cambio y cuándo. Además, permite restaurar un documento de una versión anterior. Sin embargo, Google Docs no es tan útil cuando el trabajo que debemos realizar es programar código. Para el control de versiones de códigos existen distintas herramientas, donde quizás la más conocida en el mundo de la programación es Git. Git es un sistema de control de versiones gratuito y abierto, tiene por objetivo hacer más eficiente el flujo de trabajo para proyectos grandes y pequeños. A la par existe Github, el cual es una plataforma colaborativa para el trabajo con código. Distintas disciplinas tanto de ingeniería y software, como relacionadas al ámbito científico utilizan Github como un centro de organización para el trabajo. Se utilizan repositorios, los cuales albergan todo lo relacionado a un proyecto, en el caso de la ciencia, a un proyecto de investigación. Recomendamos el uso de Git y Github como flujo de trabajo para aquellos científicos sociales que trabajan con datos cuantitativos, especialmente cuando son grandes equipos de investigación o son proyectos con varias colaboraciones. Para más información sobre Git y Github ver aquí 4.2.4 Prácticas de código Hasta ahora, hemos procurado que la presentación de la información sea lo más general posible y que no esté relacionada a un software estadístico único. Bajo esa idea, hemos presentado lo que es una estructura reproducible de un proyecto, aludiendo a los elementos comunes que se encuentran en distintos protocolos. También, revisamos cómo el control de versiones y el trabajo con documentos dinámicos pueden ser herramientas para la reproducibilidad. No obstante, no hemos abordado lo que, desde un principio, establecimos como el núcleo de la reproducibilidad: el trabajo con código. Este capítulo busca ser una primera aproximación y enseñar lo básico respecto a reproducibilidad. Con tal de mantenernos bajo esa idea, trataremos el trabajo con código de forma abstracta, sin introducirnos a trabajar con un software en particular. Específicamente, veremos algunas prácticas de código que contribuyen a hacer un trabajo más reproducible. Estas son aplicables a distintos software que utilicen código y cuando nos estemos refiriendo a un software específico lo señalaremos. Nunca hacer trabajo manual. El objetivo de la reproducibilidad es que cualquier persona pueda regenerar nuestro trabajo, y el trabajo manual es un obstáculo para el cumplimiento de ese objetivo. Trabajar con código permite automatizar los procesos de tratamiento y análisis de datos, es cómo establecer un guión paso a paso sobre lo que se ha hecho para llegar a los resultados del artículo, en contraste, documentar un proceso de análisis manual (e.g. en una planilla de datos) es una tarea sumamente compleja. Si bien es posible escribir un guión detallado de cada paso, esto tomaría una cantidad de tiempo y energía considerables, más aún teniendo en cuenta la cantidad de decisiones que tiene que tomar un equipo de investigación en el proceso de análisis de datos. Es por eso que la recomendación base es no hacer trabajo manual y trabajar con código, lo que implica evitar software como Microsoft Excel y otros relacionados. Asegurarse que el código siempre produzca el mismo resultado. Nuestra hoja de código será la receta que otro seguirá para poder elaborar el mismo producto, por lo que tenemos que asegurarnos que esta produzca siempre lo mismo. Un ejemplo es cuando por algún tipo de análisis se necesitan generar números aleatorios. En R, para poder reproducir la generación de esos números aleatorios se utiliza la función set.seed(). Trabajar con scripts. Para poder automatizar el procesamiento y análisis de los datos, la principal recomendación es trabajar con documentos script que albergan el código y permiten su rápida ejecución. En el caso de R, se pueden utilizar documentos .R. Escribir con minúscula, sin espacios, sin ñ y sin tildes. Gran parte de los software disponibles para análisis de datos traen el inglés como idioma nativo, por lo que existe una alta probabilidad de que tengamos problemas si utilizamos caracteres especiales que no se encuentran en ese idioma. Respecto al uso de mayúsculas, existen software que diferencian cuando un código incluye mayúsculas y cuándo no, esto es una característica conocida como case sensitive. Sin embargo, no todos los software cuentan con esta característica, por lo que es mejor evitar su uso. Indentar el código. La indentación es una característica del trabajo con código en general (no solo a nivel de software estadístico) y se refiere a la jerarquía en los niveles del código. Indentar permite una lectura más fácil del código, ya que permite comprender visualmente el orden y la estructura del código. Uno de los ejemplos más conocidos es la elaboración de funciones condicionales de tipo if-else. Comentar el código. Comentar el código es sustancial para que cualquier persona no asociada al proyecto (o incluso uno mismo en el futuro) pueda entender para qué sirve cada función y reproducir el documento sin problemas. Aquí el lema es: nunca es mucho cuando se refiere a comentar el código. Mientras mejor explicado esté qué hace cada cosa y por qué, la receta será más fácil de seguir. Especificar las versiones de paquetes. Gran parte de los software estadísticos trabajan en base a la idea de paquetes. Estos son un conjunto de herramientas que facilitan el trabajo con datos. Existen paquetes tanto para tareas simples como el tratamiento de bases de datos o la generación de gráficos, así como para técnicas estadísticas avanzadas. No obstante, una característica a tener en cuenta es que los paquetes tienen versiones, ya que van mejorando día tras día. Esto ocurre especialmente en software de código abierto como R o Python. A raíz de esto, es que una de las recomendaciones para la reproducibilidad es conocer con qué versión de los paquetes se está trabajando y documentarlo. Inclusive, en software como R existen herramientas que permiten facilitar esta tarea (ver groundhog) Elaborar código autocontenido. Existen dos formas de trabajar con código. La primera es el trabajo tipo cascada, donde el código es como agua que fluye desde arriba hacia abajo. Esta metáfora significa que cada código es parte de un todo interdependiente, y como tal, cada bloque depende del anterior. Un ejemplo simple es que con un bloque de código se carga una base de datos y con otro se presenta un gráfico de la misma. En contraste a esta forma de trabajo, existe una segunda de tipo autocontenida. Esta forma implica que, en vez de que el código sea interdependiente entre sí, cada bloque de código es una tarea que inicia y finaliza en el mismo bloque. Siguiendo el ejemplo, esto implicaría que cargar la base de datos y mostrar un gráfico de ella es una tarea que comienza y termina en el mismo bloque de código. Si bien el trabajar con código ya es un avance hacia la reproducibilidad, trabajar de manera autocontenida es un paso mucho mayor, ya que minimiza la probabilidad de que el código no pueda ser reproducido por un tercero. Nombrar variables de manera óptima. Como se señaló anteriormente, muchas veces los nombres de las variables en las bases de datos siguen una lógica más técnica que sustantiva. Es por eso que, para poder trabajar de manera óptima y que, al mismo tiempo, el código sea más fácil de leer se sugiere renombrar las variables de forma sustantiva y corta. Por ejemplo, si una variable de edad de una encuesta tiene por nombre m01, sugerimos cambiarlo a edad. Etiquetado o buen diccionario de variables. Además de renombrar las variables, recomendamos etiquetar de forma sustantiva las variables que se utilizarán y/o hacer un buen diccionario de ellas. Esto tiene por objetivo que la base de datos que hayamos elaborado para nuestros análisis sea más fácil de leer y reproducir. Utilizar UTF8. Como señalamos, recomendamos evitar el uso de caracteres especiales en trabajo con código, esto implica el uso de tildes o ñ. No obstante, para ciertas situaciones será indispensable que escribamos en nuestro idioma nativo (en este caso español), y por ende utilizar caracteres especiales. Un ejemplo es cuando establecemos los títulos y categorías de una tabla o un gráfico. En estos casos, sugerimos establecer el formato del documento de código en formato UTF-8. Este formato es de tipo universal y acepta todo tipo de caracteres, incluyendo los especiales. Trabajar con rutas relativas. Las rutas relativas son una ubicación en el computador que es relativa a un directorio base o carpeta raíz. En el caso del trabajo con datos, generalmente la carpeta raíz es la que alberga todos los documentos que refieren a ese proyecto y las rutas relativas son direcciones hacia distintos archivos teniendo como base la carpeta raíz. Esta es una forma reproducible de ordenar los archivos ya que no depende de quién está trabajando. Uso de software libre. Con los nuevos avances en la tecnología y en el acceso a ella han emergido iniciativas colaborativas de desarrollo de software. Esto implica que en vez de estar centralizado por una compañía, quien está detrás de los avances en el desarrollo del software es una comunidad activa de usuarios. Software como R y Python son ejemplos de este tipo de iniciativas. Recomendamos el uso de software libre porque, además de alinearse con los principios de la ciencia abierta, proveen un ambiente y herramientas mucho más propenso a adoptar prácticas que avancen hacia la reproducibilidad. Estar en contacto con la comunidad de investigadores y/o desarrolladores de herramientas computacionales. Más que una práctica relacionada al código, es una recomendación respecto a cómo hacer más óptimo nuestro trabajo. Con internet y las nuevas herramientas computacionales, existen varias comunidades a las cuales recurrir en caso de necesitar ayuda con el desarrollo del código. Por ejemplo, Stack Overflow es un foro donde programadores, ingenieros y en general cualquier persona que utiliza código en su día a día puede hacer o responder preguntas respecto a código. Es una gran herramienta para cuando los códigos no funcionan o cuando queremos conocer formas más eficientes de hacer una tarea. Incluimos esta recomendación porque participar de estos foros y ser parte activa de la comunidad implica adoptar prácticas para la reproducibilidad, con tal de que otros puedan entender nuestras preguntas y respuestas. Referencias "],["publicaciones-libres.html", "Capítulo 5 Publicaciones libres", " Capítulo 5 Publicaciones libres Un agricultor hace uso de sus herramientas, talentos y conocimientos para aprovechar lo mejor posible las ventajas del bien común que es la tierra. Una vez que termina la temporada, el agricultor entrega la cosecha a un distribuidor que se encarga de comercializar el fruto de su trabajo y el de otros agricultores. ¿Cuánto recibe realmente el agricultor por su trabajo? ¿Cuáles son las posibilidades reales que tiene la ciudadanía de acceder al bien común de manera autónoma? El problema del agricultor, el distribuidor y la ciudadanía no es una historia del pasado. El producto de un trabajo que hace uso de un bien común, y el cómo este se distribuye y retribuye dentro de la sociedad, es un tema que cada vez suscita más interés no solo en los gobiernos y la ciudadanía, sino que también en la ciencia. Esto debido a que, como el agricultor elaboró cosechas a partir de la tierra, el científico construirá evidencia nueva a partir de conocimientos previos. Ambos crean productos que son bienes esenciales para la ciudadanía a partir de bienes comunes de la humanidad. El problema para ambos está en que parte de ese quehacer ha sido privatizado, restringiendo a la ciudadanía del libre acceso a tales bienes. Esta problemática también es extrapolable a la situación que ocurre con las patentes de vacunas y, en específico, con las patentes de las vacunas de COVID-19, donde gran parte de los organismos internacionales llaman a que estas sean consideradas bienes públicos. Así como la privatización al acceso de un conocimiento médico produce desigualdad entre los países más y menos ricos, también el acceso al conocimiento por parte de la sociedad en general -evidencia de cómo mejorar el cumplimiento de las medidas de cuidado, por ejemplo- implicó un daño invaluable en cómo se produjo y se distribuyó la información para combatir la pandemia. Así, a pesar de que con la globalización y la era digital la labor científica ha podido crear conocimientos con mayor facilidad y divulgarlos de manera inmediata, el desconocimiento y los mitos sobre las leyes que amparan la propiedad intelectual han sido el principal obstáculo para dar el paso hacia la apertura de la creación científica (Fernández et al., 2018). El miedo a ser sancionado por la editorial, el temor al plagio y la pérdida de reconocimiento autoral, destacan entre las principales razones, sin mencionar el dominio que poseen las revistas científicas sobre el conocimiento que se genera y que es publicado por ellas. Dicho esto, la apuesta por destinar los esfuerzo hacia una libre circulación del conocimiento apunta a la necesidad de reapropiarse de los beneficios, resultados y saberes científicos. En este sentido, Banzato (2019) hace un llamado a los organismos de América Latina para generar espacios de evaluación y difusión que sirvan para la democratización del conocimiento, siendo esta una estrategia cultural y política que busca promover los procesos de producción y reproducción social del saber. La apertura de nuestras investigaciones traen más beneficios que dificultades: no solo contribuimos a nutrir el conocimiento colectivo sobre un problema, sino que incluso podemos alcanzar mejor visibilidad de nuestro trabajo científico. Por eso, en el siguiente capítulo te presentaremos aspectos que debes considerar para lograr una exitosa apertura de tus publicaciones y resultados de investigación. Referencias "],["propiedad.html", "5.1 Propiedad intelectual", " 5.1 Propiedad intelectual Esta sección busca comprender la importancia de la propiedad intelectual abordando los elementos centrales de la producción científica y su resguardo legal. Es importante conocer los elementos que nos servirán en el momento de definir el carácter y el modo en que permitiremos que nuestras creaciones sean utilizadas y difundidas. La propiedad intelectual no es un elemento accesorio, pues nos habla de facultades exclusivas que posee el autor sobre su obra y que le permiten gozar de su uso y explotación (Loredo, 2012). Para nuestros efectos, se concibe como el peldaño inicial para abordar los esfuerzos hacia la publicación libre. 5.1.1 Sobre la Propiedad Intelectual y las Licencias La Propiedad Intelectual (PI) es una normativa que permite el reconocimiento autoral de toda invención de la mente humana (World Intelectual Propiety Organization, 2020), su objetivo es fomentar la creación e innovación al mismo tiempo que regula el uso y difusión de las obras. La PI es un tipo de ley cuya rigurosidad varía según el país y funciona en base a dos grandes acepciones: Common Law: rige en Estados Unidos e Inglaterra y regula la reproducción (copia) de la obra, su distribución, su exhibición pública y su transformación ya sea traducida o adaptada (Fernández, 2009). A partir de lo que señala Omatos (2013) se comprende que es una facultad que poseen los autores y su particularidad es que puede ser transferida ya sea por voluntad propia o por prescripción, siendo así ampliados los derechos del uso de la obra bajo distintos tipos de licencias de Copyrigth, Creative Commons, Copyleft y Dominio Público. Derechos de autor: rige en Europa continental y Latinoamérica y regula las facultades patrimoniales y el derecho moral que posee el autor sobre su obra, esto quiere decir que se reconoce la paternidad sobre la creación y se protege la integridad original del trabajo (Loredo, 2012). El derecho moral, a diferencia del Common Law es irrenunciable e inalienable, por lo que no se puede traspasar. A modo de contexto, en el caso de Chile se han suscrito tratados internacionales que permiten el resguardo internacional de cualquier obra intelectual que se haya elaborado en territorio nacional, los más importantes son dos: Tratado de Berna (rectificado en 1973): establece indicaciones a los países asociados para resguardar las obras internacionales en el propio territorio. Convenio de OMPI (rectificado en 1975): establece una suerte de guía a los países adherentes que sirve para la elaboración de leyes que atiendan el resguardo de la propiedad intelectual dentro del mundo digital (Fernández, 2009). 5.1.2 Tipos de Licencias Las licencias sobre la propiedad intelectual regulan los derechos patrimoniales de la obra y establecen las reglas para su uso. Las licencias más conocidas son: Copyright: Esta licencia permite que el autor se reserve todos los derechos sobre la obra y solo se puede hacer uso de ella bajo permiso del autor. Creative Commons (CC): Esta licencia, inspirada en la General Public License - GPL (Licencia Pública General en español),3 tiene el propósito de desarrollar herramientas digitales estandarizadas que faciliten la distribución de la obra, pues entrega al autor, empresa o institución la responsabilidad de autorizar reglamentariamente el modo de uso, difusión y citación de su obra. Existen seis tipos de licencias CC (véase Figura N° 5.1) y cada una de ellas tiene como base la CC-BY que permite hacer uso de la obra con la correspondiente atribución, el resto de licencias funcionan a modo de capas que se superponen a la principal. De este modo, cada capa entrega una especificidad sobre cómo utilizar la obra Creative Commons (2019). Figura 5.1: Capas de las licencias Creative Commons. Elaboración propia. Copyleft: Este tipo de licencia proviene del movimiento Open Access y se orienta a abrir el uso, aplicación, distribución y creación de obras. Además de permitir el uso libre, indica la obligación de que todo proyecto que nazca a partir del original contenga los principios del acceso abierto. Dominio Público: Si bien no corresponde a una licencia como tal, es un estado en el que la obra no posee protección patrimonial pues ha prescrito el plazo de su protección. 5.1.3 El conocimiento es poder pero ¿de quién? Tanto organismos de investigación pública como universidades crean conocimiento científico por medio de la investigación y la docencia con el fin de aportar al bien público. Si bien la apertura de las publicaciones puede ser lo ideal para tales objetivos, en ocasiones la confidencialidad de los resultados científicos permite a sus autores obtener beneficios económicos de su trabajo. Sin importar cuál sea el camino, la propiedad intelectual juega un papel importante al orientar la toma de decisiones en torno al desarrollo, difusión y utilización del conocimiento intelectual (WIPO, 2020). Por ello contar con una política intelectual de calidad es el primer paso para gestionar estratégicamente la difusión y transferencia de los resultados científicos. A continuación, se presentan dos experiencias chilenas que se consideran como buenas prácticas en términos de políticas institucionales, pues promueven la apertura de publicaciones. Política de Acceso Abierto de ANID La Agencia Nacional de Investigación y Desarrollo (ANID) que nace en 2020 como una estructura que reemplaza a la Comisión Nacional de Investigación Científica y Tecnológica (CONICYT), es hoy la institución que encabeza el Ministerio de Ciencia, Tecnología, Conocimiento e Innovación. Siguiendo el legado de su antecesora, su objetivo es apoyar con recursos al desarrollo de la ciencia y la innovación en Chile. Desde el 2021, bajo el principio de que todo conocimiento generado con fondos públicos debe resultar en beneficios para la sociedad, ANID ha implementado una Política de Acceso Abierto con el objetivo de asegurar la disponibilidad del conocimiento científico que resulte de investigaciones financiadas por la institución (Agencia Nacional de Investigación y Desarrollo, 2020). Esta política busca ser un curso de acción progresivo implementado en dos fases: Fase I: En el plazo inicial de dos años se pretende incentivar la apertura de las publicaciones y sus datos. Esta primera fase servirá para la recopilación de antecedentes sobre el uso y gastos asociados a la investigación abierta. En esta primera etapa de la política toman gran relevancia los principios FAIR. FAIR es la abreviatura en lengua inglesa para referirse a Findability, Accessibility, Interoperability y Reusability (Encontrable, Accesible, Interoperable y Reutilizable). El diseño de estos principios tienen el objetivo de ser una guía medible para que los investigadores realicen una eficaz gestión de los datos y para que posteriormente puedan ser replicados (Wilkinson &amp; Dumontier, 2016). Fase II: Los resultados de la primera fase servirán para que en la segunda se implemente -de manera más rigurosa- la publicación libre mediante la Ruta Dorada, la cual corresponde a un formato de publicación que permite eliminar los periodos de embargo, dejando las publicaciones disponibles en acceso abierto de manera inmediata tras el pago del Article Processing Charges - APC a las editoriales. El APC es una tarifa que costea el procesamiento del artículo final para que se adapte al diseño de la revista y, en ocasiones, son las propias instituciones públicas las que costean el APC, devolviendo así un monto no menor a las editoriales. En la sección de Herramientas Para Públicar profundizaremos en ello. ANID ha detectado de manera temprana el conflicto que acarrea la industria editorial, que lidera un mercado donde los conocimientos se tranzan como un bien. Esto beneficia principalmente a las editoriales con un alto margen de ganancias y, por ello, en la propuesta de ANID se especifica que: Esta política busca ser un curso de acción que esté en constante revisión y que permita, de manera progresiva, avanzar hacia un sistema transparente y abierto, donde el acceso, la re-utilización y la constante oferta de nueva información y datos científicos contribuyan de manera real y concreta al desarrollo social, cultural, científico y económico de Chile (ANID, 2020b). Repositorio Institucional, Universidad de Chile La Universidad de Chile es a la fecha la institución de educación superior pionera en desarrollar un repositorio institucional abierto. Este recoge documentos digitales e impresos con previa autorización, tales como tesis de pregrado y postgrado, pre y post-print, libros y capítulos, material didáctico y presentaciones, informes técnicos, recursos audiovisuales e imágenes. El Repositorio Académico de la Universidad de Chile conserva, difunde y proporciona acceso a material científico generado por docentes e investigadores de la institución y cuenta actualmente con más de 68.000 publicaciones. Este repositorio académico hace uso de un protocolo de interoperabilidad que permite que se conecte con otros repositorios, con el propósito de incrementar la visibilidad de los documentos. Bajo este objetivo, los autores deben proteger sus obras con licencias Creative-Commons, de este modo aseguran el reconocimiento e identificación de la propiedad intelectual y favorece la visibilidad del trabajo. Ambos ejemplos de políticas institucionales proveen una exitosa colaboración entre el mundo científico y el público general, ya que orientan la toma de decisiones al finalizar el ejercicio investigativo y permiten la apertura del conocimiento. Según Alperin et al. (2014), en América Latina se ha desarrollado el ejercicio del Open Access mediante el financiamiento -casi exclusivo- de agencias estatales y agencias de cooperación internacional. Sus resultados se publican principalmente en revistas locales o repositorios regionales. Un ejemplo de ello es Argentina, país donde el 80% de los artículos científicos se encuentran indexados en revistas locales (Alperin et al., 2014), ya que la nación se ha inclinado en promover políticas de autoarchivo como la Ley Nacional de Repositorios promulgada en 2013 y la creación del Sistema Nacional de Repositorios Digitales creado en 2011 (Monti &amp; Unzurrunzaga, 2020). La evidencia da cuenta que para el caso Latinoamericano son los organismos universitarios y de investigación pública los responsables de desarrollar eficaces políticas de ciencia abierta con el objetivo de aportar a la libre circulación de los resultados científicos, pues como se ilustra en la Figura N° 5.2, dentro de sus beneficios no solo se evidencia la mayor exposición de los trabajos científicos, sino que también existe un aporte en términos de desarrollo a nivel país, influencia de políticas, entre otros aspectos positivos. Figura 5.2: Beneficios del Open Access. Traducción propia en base a Kingsley, D. &amp; Brown, S. (2021). Referencias "],["formas-open-access.html", "5.2 Formas open access", " 5.2 Formas open access El quehacer científico de las ciencias sociales es una arena de lucha continua, donde investigadores deben mantenerse en constante entrenamiento para no perder el reconocimiento académico que brinda oportunidades laborales y estatus social. Publica o perece es más una realidad que una frase retórica, pues los científicos sociales están en la obligación de investigar y publicar para mantener su carrera laboral a flote. Este agotador panorama da pie a lo que muchos investigadores de las ciencias sociales han denominado como la crisis de la ciencia (Breznau, 2021), un nuevo panorama donde el conocimiento científico es menos confiable producto de prácticas antiéticas en el proceso de investigación. Falta de consistencia, sesgos no controlados, presión editorial, entre otros factores, son los que influyen en un tipo de ciencia con problemas de credibilidad, como es el emblemático caso de Diederik Stapel que se mencionó en el capítulo I. Quizás muchos confiarán la solución de la crisis a las instituciones revisoras de las revistas, quienes aplican rigurosos métodos de control de calidad. Sin embargo, del papel a la práctica hay un gran trecho. La falta de transparencia en la manipulación de información, los métodos de análisis y la recolección de datos hacen imposible corroborar la veracidad total de un trabajo. Actualmente, muchas editoriales han abordado el problema mediante la adopción del Open Access para promover la transparencia de los datos y la apertura de las publicaciones, pues con esto se permite usar la reproducción de los procesos como un mecanismo de control. Por ello, en esta sección conoceremos las particularidades del Open Access, las rutas por las cuales compartir publicaciones, los repositorios y las revistas que recomendamos. 5.2.1 ¿Qué es el Open Access? Open Access - OA (Acceso Abierto en español) es un movimiento cuyo objetivo es promover el acceso libre a la producción de conocimiento científico digital y hacer uso de él sin restricciones de copyright. Esto en base a estándares internacionales que permiten instalar la posibilidad de que cualquier persona pueda reutilizar la información de la investigación en cuanto datos, procesos y resultados. Hace algún tiempo, científicos advirtieron del problema asociado al oligopolio del conocimiento científico del que disfrutan revistas y editoriales de gran renombre, sin mencionar conflictos entre investigadores en torno a la competencia de estatus académico, la manipulación de resultados, los problemas de intersubjetividad y la falta de transparencia en el proceso de investigación (Breznau et al., 2021). De este modo, los primeros vestigios del Open Access aparecieron a la par con la creación de Internet, pero no fue hasta el 2002 con la declaración de Budapest que se definió el concepto de Open Access y que posteriormente sería reforzado con las declaraciones que dieron lugar en Bethesda 2003 y Berlín 2003. Uno de los aspectos destacables de la primera declaración indica que: Retirar las barreras de acceso a esta literatura acelerará la investigación, enriquecerá la educación, compartirá el aprendizaje de los ricos con los pobres y el de los pobres con el de los ricos, hará esta literatura tan útil como sea posible y sentará los cimientos para unir a la humanidad en una conversación intelectual común y búsqueda del conocimiento (Initiative, s. f.). Según Melero &amp; Abad (2008), las causas que gatillan el desarrollo del Open Access son principalmente dos: La constitución de Internet y las nuevas tecnologías como el medio para la divulgación científica permitió abaratar costos de impresión y acelerar el transporte de los conocimientos. Los elevados precios de suscripción a revistas científicas digitales se presentaron como barreras económicas y de copyright para acceder al conocimiento y resultados de investigaciones. ¿Por qué hacer uso del Open Access en mis publicaciones? El estudio de Piwowar et al. (2019) demuestra que desde la década de los noventa ha habido un aumento constante de publicaciones que se adscriben al Open Access y, si bien el fenómeno se desarrolla en mayor medida dentro de las ciencias exactas, las ciencias sociales no se quedan atrás (Swan, 2013). Según Hernández (2016), los beneficios atribuídos a las prácticas científicas de carácter abierto no difieren sobre la disciplina y traen consigo efectos positivos ligados a: Mayor accesibilidad y conservación de los productos científicos. Difusión rápida e inmediata de las publicaciones. Facilita la comunicación directa de los conocimientos científicos ayudando a avanzar en el mejoramiento de la calidad en la investigación. Abre la posibilidad de reutilizar información, datos y procesos para nuevos proyectos. 5.2.2 Las distintas rutas para publicar de manera abierta Swan (2013) -representante de UNESCO- define dos rutas principales (tipos de repositorios) donde depositar publicaciones con el rótulo del Open Access (Dorado y Verde), pero en la práctica se pueden diferenciar en cinco. Según Abierto (2019) las principales características de cada una son: Repositorios de Ruta Dorada: Corresponden a repositorios que publican trabajos de investigación en forma gratuita para el lector, por lo que se puede leer cualquier artículo inmediatamente después de ser publicado. Cabe destacar que, para su publicación, detrás hay un cobro Article Processing Charges - APC (Cargo por Procesamiento de Artículo en español) cuyo costo es pagado por los autores o las instituciones que les financian. Repositorios de Ruta Híbrida: Gran parte de las editoriales académicas utilizan este modelo con el objetivo de ofrecer Acceso Abierto al mismo tiempo en el que mantienen su modelo de negocio habitual basado en suscripciones. Esto permite a los autores optar por pagar una cuota de publicación y tener sus artículos con Acceso Abierto en revistas por suscripción. Repositorios de Ruta Verde: Consiste en un proceso de auto-archivo o auto-depósito donde los autores comparten sus post-print (artículo final) en sus páginas personales o en revistas que no son gratuitas, pero que poseen repositorios de acceso libre. Estos repositorios antes mencionados se adhieren a un conjunto de reglas y técnicas de inter-operación, formando una red interconectada de bases de datos. Repositorios de Ruta Diamante: Es un modelo que intenta dar solución a los inconvenientes que surgen en las rutas anteriores. Este posibilita la revisión por pares de los trabajos enviados por medio de investigadores que trabajan como voluntarios, obteniendo de esta forma reconocimiento académico y social. Esta ruta es considerada como el único modelo que garantiza la sostenibilidad de la publicación de acceso abierto. Repositorios de Ruta Bronce: Según Piwowar et al. (2019) esta es una nueva categoría donde los editores alojan artículos embargados en sitios web de su preferencia, de modo que los trabajos carecen de licencias que permitan su uso autorizado. Figura 5.3: Proyección de la cantidad de visitas y artículos publicados por cada ruta del Open Access. Traducción propia en base al estudio de Piwowar et al. (2019). La Figura N° 5.3 ilustra el modelo elaborado por Piwowar et al. (2019). Este estudio se basa en el análisis de 70 millones de artículos publicados entre 1950 y 2019 que comparten el rasgo de haber sido publicados en acceso abierto y estar alojados en la base de datos de Unpaywall. La técnica utilizada permitió estimar la trayectoria de los artículos hasta el 2025, poniendo énfasis en el porcentaje de visitas y el porcentaje de artículos publicados según cada ruta. De esta manera, en la Figura N° 5.3 se proyecta que para el 2025, los artículos publicados por la vía dorada alcanzarán un aumento de sus visitas en un 33%, la ruta verde un 19% y la ruta híbrida un 10%; mientras que la ruta bronce seguirá la misma trayectoria pero en menor medida. En cuanto al porcentaje de artículos publicados en acceso abierto, esta Figura indica que tanto la ruta verde, dorada e híbrida tendrán un aumento desde el 2019 al 2025, mientras que la ruta bronce en sus categorías inmediata y retrasada se mantendrán uniforme sin aumento ni descenso. Lo importante aquí es un notable aumento de la publicación en abierto en 13 puntos porcentuales, mientras que se estima el descenso de la publicación cerrada en 13 puntos porcentuales. 5.2.3 ResearchGate, Academia.edu y Sci-Hub: ¿Plataformas de aceso abierto? De seguro conoces las plataformas de ResearchGate y Academia.edu o quizás en alguna ocasión has recurrido a estas páginas para compartir tus publicaciones o descargar archivos científicos para uso personal. Sobre estas plataformas hay que mencionar que no son un ejemplo de Open Access, debido a que funcionan como redes sociales similares a Facebook o LinkedIn, pues su objetivo es crear redes de contactos entre colegas e investigadores con intereses afines. Según Fortney &amp; Gonder (2015), ResearchGate y Academia.edu, al ser empresas con fines de lucro, no cumplen con la característica principal de los repositorios de Open Access, los cuales son administrados por universidades, agencias gubernamentales, asociaciones internacionales o editoriales que persigan el objetivo de poner los conocimientos al servicio y disponibilidad pública. Estas páginas al ser de tipo auto-archivo presentan similitudes con los repositorios de ruta verde, ya que los documentos se guardan en sitios personales creados por el propio autor, sin embargo, dadas las características de ResearchGate y Academia.edu, estas no permiten corroborar los estándares de calidad y seguridad de las publicaciones, ni tampoco se asegura su permanencia perpetua. Dicho lo anterior, publicar la producción científica en cualquier plataforma digital no implica estar desarrollando prácticas acordes al Open Access. Las restricciones de pago empujaron al desarrollo de sitios piratas que funcionan como bases de datos integrando diversas publicaciones, estos son denominados como la vía negra del Acceso Abierto que buscan hacer frente a las barreras de pago (Björk, 2017). Un claro ejemplo es el sitio web Sci-Hub que desde el 2011 posibilita el libre acceso a literatura científica (tanto pagada como libre) y para el 2021 alberga más de 85 millones de documentos. Su eslogan Sci-Hub para remover todas las barreras en el camino de la ciencia se instaura bajo tres principios: (1) El conocimiento es para todos, (2) No al Copyright y (3) Apoyo al Open Access. Sin embargo, Monti &amp; Unzurrunzaga (2020) indica que el carácter ilegal del sitio es la razón de que exponentes de la ciencia lo restrinjan, dado que no tiene la injerencia para modificar los aspectos legales de las publicaciones, transgrede los derechos de explotación indicados por los autores y puede conducir a un desprestigio del Open Access. Es evidente que lo atractivo de estos sitios es la posibilidad de acceder de manera libre a las publicaciones. Un hecho corroborable es la investigación de Bohannon (2016), en ella se ha concluido que el 25% de los países que registran la mayor cantidad de descargas desde Sci-hub, corresponden a las naciones más ricas del mundo en Europa y Estados Unidos. Björk (2017) es el primer autor en considerar la plataforma como una vía dentro del Acceso Abierto, y es quizás una reflexión de orden ético-moral la decisión de integrar (o no) los sitios con estas características dentro del Open Access. 5.2.4 Revistas de acceso abierto: Con la invención de Internet también aumentaron las oportunidades de divulgación científica y, si bien el concepto de Open Access no fue precisado hasta los 2000, en la década anterior ya venían gestándose proyectos como The public-access computer systems review (1990), una revista electrónica tipo boletín que era distribuida por correo electrónico. Posteriormente, en 1991 revistas como Surfaces y Psycoloquy fueron pioneras en instalar la metodología de acceso gratuito a sus publicaciones. Hoy en día son muchos los sitios de repositorios que cumplen con políticas de Acceso Abierto, pero con licencias particulares que es necesario conocer para adentrarnos en su uso. Uno de los sitios que se recomienda usar es el de SocArxiv, pues cuenta con un servicio gratuito de acceso, una base de datos completa y que permite a los autores obtener un DOI para su publicación. Sin mencionar la posibilidad de un contador de descargas y otras particularidades que no poseen las plataformas de ResearchGate y Academia.edu (véase Tabla N° 5.1). En la siguiente sección abordaremos en mayor profundidad su uso. Tabla 5.1: Tabla comparativa del uso de SocArXiv versus otros sitios Características ResearchGate, Academia.edu Sitio web personal Repositorio Institucional SocArXiv Acceso libre para leer Requiere Registro Si Si Si Servicio de acceso publico - sin lucro No Solo si es alojado por tu universidad Solo si es alojado por tu universidad Si Metadatos completos, incluidos coautores, DOI, ORCID, etc. Quizás No Quizás Si Enlace para el repositorio para base de datos, codigo, etc. No Solo si tu lo construyes Quizás Si Url persistente en todas las versiones - No No Si Entrega DOI para el paper - No Solo Algunos Si Contador de descargas Solo Algunos Quizás Quizás Si Contribuye al futuro de la comunicación académica abierta No Débilmente Quizás Si Fuente: Traducción propia a partir de tabla comparativa de SocArXiv. Referencias "],["herramientas-para-publicar.html", "5.3 Herramientas para publicar", " 5.3 Herramientas para publicar Imagine que usted es parte de un equipo de investigación que finalizó un estudio sobre las repercusiones socio-económicas que tuvo la pandemia de Covid-19 en el país, desarrollando un aporte significativo para la toma de decisiones en materias de políticas económicas y levantando las bases para nuevas líneas de investigación. Dado el aporte que significan para el bien público los resultados de esta investigación, es necesaria su divulgación inmediata, pero es una realidad que la publicación regular en cualquier editorial toma un periodo largo de revisión y aceptación, es por ello que una alternativa es la pre-publicación del documento en un repositorio de Acceso Abierto. En la siguiente guía abordaremos un marco de referencia para empezar a adoptar prácticas ligadas al Open Access. 5.3.1 El camino hacia la publicación Todo proyecto de investigación tiene la potencialidad de ser publicado pero, como ya se ha ido ilustrando en las secciones anteriores, publicar de manera abierta trae consigo beneficios de visibilidad e impacto social. Para desarrollar una estrategia eficaz de publicación abierta hay que seguir un flujo que se divide tres pasos, como se ilustra en la Figura N° 5.4. Este flujo inicia con la elección de la revista de Acceso Abierto, sigue con la identificación de la etapa del artículo y finaliza con la selección del servicio de publicación. Figura 5.4: Guía paso a paso para publicar libre (Elaboración propia). Paso 1: Pre-rint (Pre-publicación) Es lo que conocemos comúnmente como el borrador del artículo, el mismo que enviamos al proceso de revisión por pares. Este documento tiene la posibilidad de ser publicado en cualquier repositorio de ruta verde (pre-print server) con el objetivo de ser difundido abiertamente para permitir su disponibilidad inmediata. La gran particularidad de este método de pre-publicación es que se obtiene un código alfanumérico que identifica y ubica el documento dentro de Internet, esto se conoce como un Digital Object Identifier - DOI (Identificador de Objeto Digital en español), por lo que se convierte de manera inmediata en un documento referenciable y sin posibilidad de plagio. Algunas personas tendrán el temor de que al pre-publicar un informe de investigación, las posibilidades de que el documento sea aceptado y posteriormente publicado en una revista es menor. Sin embargo, los datos empíricos demuestran que en realidad esto no es un impedimento para su posterior publicación. En la investigación de Abdill &amp; Blekhman (2019) que analizó cerca de 37.648 pre-print alojados en bioRxiv -una extensión centrada en biología del sitio ArXiv-, una de las grandes conclusiones tiene que ver con que la tasa de preprints publicados en 2018 alcanzó un máximo de 2,100 por mes y, de manera más específica, en la Figura N° 5.5 se puede identificar a las diez principales revistas que han publicado la mayor cantidad de pre-print. En esta figura, cada barra indica la cantidad de documentos publicados por cada revista. Figura 5.5: Destino final de los Preprint. Traducción propia en base al estudio de Abdill &amp; Blekhman (2019) Para el caso de las ciencias sociales, el servicio de pre-print que recomendamos utilizar es SocArxiv y particularmente para la disciplina de la psicología PsyArxiv. Estos servicios permiten subir archivos PDF desde la plataforma Open Science Framework - OSF (Marco de Ciencia Abierta en español) -un software de código abierto que permite la reproducibilidad de los procesos- y de este modo se obtiene el beneficio de acceder a un DOI que asegure su correcta citación. Ambos repositorios son extensiones de ArXiv, la plataforma pionera de acceso abierto que en la actualidad alberga alrededor de dos millones de artículos categorizados en ocho áreas temáticas. ArXiv no posee tarifas asociadas a la publicación de los artículos, puesto que los documentos se someten a un proceso de clasificación y no a una revisión por pares. Paso 2: Post-print La segunda etapa es clave para el camino hacia la publicación, pues el post-print corresponde al artículo aceptado tras la revisión por pares, pero cuyo formato de presentación no ha sido adaptado al requerido. Por lo tanto no ha sido publicado de manera oficial por la revista y para lograr ello, interviene un equipo especializado de la editorial que se encarga de tales aspectos, ya sean márgenes, tipos de citación, estructura, entre otros. Hoy en día si bien son varias las editoriales que entregan la posibilidad de publicar el post-print en cualquier repositorio abierto, esto es solo tras el periodo de embargo, el cual consiste en un tiempo determinado donde la editorial se reserva los derechos patrimoniales del artículo para su distribución. Dicho esto, recomendamos tener conocimiento de las posibilidades que tiene el autor de publicar un documento previo a la publicación oficial. Paso 3: Print En la última etapa del flujo, recomendamos optar por abrir la publicación del Print (artículo final). El artículo final que es publicado oficialmente por una revista permite que la editorial conserve para sí los beneficios de los derechos patrimoniales de la obra, mientras que los equipos de investigación solo conservan el derecho al reconocimiento. Publicar en una revista de reconocimiento que integre políticas de acceso abierto brinda la posibilidad de que una vez finalizado el periodo de embargo, los autores puedan abrir sus artículos, pero no todas las revistas tienen las mismas políticas y directrices, por ello plantean formas y periodos distintos para el depósito del artículo en un repositorio abierto. Al momento de realizar el envío de un artículo a una revista cualquiera, puede ocurrir que el autor tenga que firmar un Acuerdo de Transferencia de Derechos (CTA por sus siglas en inglés), transfiriéndole al editor todo derecho sobre la obra y, por lo tanto, imposibilitando toda acción posterior del propio creador sobre la investigación. Para que la publicación dentro de una revista no afecte a la posterior decisión de abrir el acceso a una investigación, en ocasiones las editoriales plantean periodos de embargo en cuyo tiempo gozan de los beneficios económicos sobre la obra, pero al finalizar, el autor es libre de difundir en abierto su publicación. En estos casos los editores tienen una licencia que sirve únicamente para publicar, mientras que los autores deben retener para sí los derechos sobre la obra. En síntesis, para que cualquier recurso científico sea abierto, este debe contener una licencia que explicite a sus usuarios las acciones que pueden realizar sobre la obra e indicar la correcta acreditación de la fuente (Swan, 2013). 5.3.2 Revistas para publicar con Open Access Por lo general, cuando llevamos tiempo investigando y publicando tenemos ciertas nociones de las revistas a las que les puede interesar los temas que estamos trabajando o incluso tenemos ciertas certezas de las posibles revistas en las cuales nuestro proyecto tiene una mayor probabilidad de ser publicado. El paso lógico para la publicación es elegir aquella editorial donde queremos que aparezca nuestro trabajo, ya sea por reconocimiento, por recomendaciones, por el tema que trabajamos o por cualquier otro motivo que tengamos. Una vez elegida la revista, se recomienda revisar las políticas de autoarchivo y para ello recomendamos acceder a Sherpa Romeo y buscar la revista escogida. Sherpa Romeo es un sitio web que funciona como una base de datos que recopila la información básica sobre las políticas de autoría y acceso abierto de las principales revistas científicas de todo el mundo que utiliza un código de cuatro colores para diferenciar los tipos de políticas de cada revista, los que se definen en la Figura N° 5.6: Figura 5.6: Etiquetas de colores de Sherpa Romeo según tipo de acceso abierto (Elaboración propia). El mundo del Open Access es bastante grande y en ocasiones costoso, toda revista de ruta dorada posee costos de APC que deben ser financiados por los investigadores o sus patrocinantes, lo que se vuelve una barrera económica para los equipos de investigación que deseen abrir sus publicaciones, por ello el proceso de autoarchivo surge como una alternativa al alcance de cualquiera y, en su mayoría, cientistas sociales utilizan la vía verde y la diamante para depositar sus manuscritos o tesis en repositorios como Dialnet, Latindex, Scielo, Redalyc y CLACSO. Adicionalmente, existen revistas de ciencias sociales cuyo foco se encuentra en el diseño de metodologías de investigación cualitativa y que, además, poseen un alto factor de impacto, como las resumidas en la Tabla N° 5.2, pues son indexadas a Scopus (Ulloa &amp; Mardones, 2017). Tabla 5.2: Descripción de Revistas de Open Access de orden Cualitativo Revista País Asunto o Categoría Qualitative Sociology Review Polonia Ciencias Sociales diversas The International Journal Qualitative Methods Canadá Educación Forum Qualitative Sozialforscung Alemania Ciencias Sociales diversas Fuente: Adaptación propia a partir de tabla extraída del estudio de Ulloa &amp; Mardones (2017). 5.3.3 Pagos asociados a la publicación abierta El Open Access está redefiniendo la forma en que el capital científico se define, se moviliza y se trata. Este es un nuevo paradigma que choca con las reglas de un mercado académico que por décadas ha mantenido el monopolio económico del conocimiento científico por medio de barreras de pago, un modelo que no siempre es receptivo a alteraciones y novedades (Sadaba, 2014), pero que ha tenido la obligación de adaptarse al nuevo panorama cibernético digital. El modelo de suscripción se presenta como un muro de pago que al ser costeado permite acceder al material científico. Detrás de cada ejemplar físico existe un costo de adaptación, impresión y envío, lo que obligaba a las editoriales a publicar una cantidad determinada. Sin embargo, con el advenimiento de Internet, la digitalización y la inmediatez de la información, las razones y argumentos que daban sustento al modelo se volvieron obsoletas. La era digital permitió avanzar a pasos agigantados en el desarrollo de nuevos conocimientos, en la difusión masiva e instantánea de los trabajos académicos y, por consecuencia, abrió paso al cuestionamiento de las suscripciones pagadas como método de acceso al conocimiento. En este sentido, la declaración que tuvo lugar en Bethesda (2003) fue precisa en indicar que Internet ha cambiado fundamentalmente las realidades prácticas y económicas relacionadas con la distribución del conocimiento científico y el patrimonio cultural. En la nueva era digital, el modelo de suscripción sigue estando presente, pero convive con el paradigma del open access, el que intenta superar las barreras de pago poniendo la responsabilidad de la apertura del conocimiento en el propio autor. Algunos repositorios de ruta dorada e híbrida solicitan un pago de APC para publicar en acceso abierto, esto corresponde a un modelo de negocios cuyo propósito es financiar los gastos asociados a la gestión de la publicación. En estricto rigor, no existe un monto estandarizado del APC, por lo que su costo dependerá únicamente de la revista. Su valor fluctúa según el pago de impuestos adicionales, lo que se puede evidenciar en la Tabla N° 5.3. Según Socha (2018), de las revistas de mayor renombre en la industria académica como Elsevier, Springer, Wiley y Taylor &amp; Francis se han adscrito al acceso abierto cobrando a los autores un costo de APC pero manteniendo su modelo de suscripción. Tabla 5.3: Fluctuación del precio en dolares del APC en las principales revistas científicas Repositorio APC mínimo APC máximo ¿Open Acces o Híbrido? ELSEVIER $100 $5.000 Híbrido SPRINGER $3.000 $3.000 Híbrido WILEY $1.300 $5.200 Híbrido Taylor y Francis $500 $2.950 Open Access Fuente: Adaptación propia a partir de información recopilada en University of Cambridge (2018). Spinak (2019) indica que tanto en Estados Unidos como en países Europeos ha habido un aumento exponencial del costo del APC a través de los años. A modo de ejemplo, el APC promedio de 319 revistas asociadas a las editoriales BMC, Frontiers, MDPI e Hindawi aumentó entre 2,5 y 6 veces la inflación entre el 2012 y el 2018, al alero de un considerable crecimiento en la cantidad de volúmenes que paso de 58.007 hasta 127.528 en aquellos años. Los editores han admitido que el costo del APC lo fijan según el valor económico de la revista que es atribuido según el valor de impacto. La introducción de un sistema de pagos por procesamiento de artículos hace frente al modelo de suscripción, pero no logra reemplazarlo. En cambio, funciona de manera paralela dentro del mercado científico, presentándose como una nueva barrera que obstaculiza la decisión de abrir las publicaciones de aquellas investigaciones que son autónomas o que dispongan de un presupuesto acotado. Los APC tienen sus propios cuestionamientos y uno de ellos refiere a que el pago no tiene mucho que ver con el procesamiento y posterior publicación del artículo, sino que más bien los equipos de investigación pagan por el reconocimiento de ser publicados en una revista de alto factor de impacto (Velterop, 2018). Pareciera ser que el nuevo ciclo de la ciencia que apuntaba a la democratización del conocimiento se vio inmerso en las lógicas económicas en donde las editoriales obtienen los principales beneficios monetarios. ¿Pagar por hacer ciencia o pagar por reconocimiento? Claro esta que existen otras vías gratuitas para publicar de manera abierta, sin embargo la ciencia -y principalmente las ligadas a la medicina, la física y las matemáticas- ha tenido la necesidad imperiosa de ser creíble, reconocida y citada, y por ello existe una mayor competencia en torno al reconocimiento que otorga la publicación en revistas de alto impacto. Sin embargo, el quehacer en pos del conocimiento y su disposición como bien público para la sociedad y su desarrollo poco tiene que ver con una distinción simbólica que sirve dentro del mundo científico. La ciencia social, a diferencia de las ciencias exactas, se ha podido desarrollar con mayor libertad por medio de las vías gratuitas en importantes repositorios de ruta verde, como es el ejemplo del caso latinoamericano que profundizaremos en la siguiente sección. Referencias "],["cuál-es-el-destino-de-las-ciencias-sociales-en-el-mundo-del-open-access.html", "5.4 ¿Cuál es el destino de las ciencias sociales en el mundo del Open Access?", " 5.4 ¿Cuál es el destino de las ciencias sociales en el mundo del Open Access? La dicotomía entre ciencias naturales y sociales es una discusión epistemológica de años que no solo remite al objeto de estudio, sino que también a las metodologías de investigación, a los criterios de validez y quizás lo más importante, a la reflexión en torno al carácter objetivo de la propia ciencia. Es claro que el movimiento del Open Access no pretende dar respuestas ni reflexiones profundas sobre este tipo de cuestionamientos de orden epistemológico, y aunque se abre en extenso como una herramienta que sirve para la libre difusión de los conocimientos en el plano de Internet, una cosa es clara y es que las ciencias sociales han llegado algo tarde en comparación a las ciencias exactas (Sadaba, 2014). La comunidad científica ligada al campo de lo social ha hecho los esfuerzos por adquirir prácticas abiertas y, de este modo, han comenzado a trazar una próspera trayectoria en el campo del Open Access con un fuerte componente político. Las barreras de pago no son el único obstáculo que enfrenta la libre circulación del conocimiento científico, Banzato (2019) indica que la industria editorial ha instalado la idea de una ciencia del centro o bien denominada mainstream, un concepto consolidado globalmente gracias al trabajo hecho por los servicios de Web Of Science WoS y Scopus que han creado indicadores bibliométricos que segmentan a las investigaciones científicas, fomentan el uso del inglés como la lengua ilustre de la ciencia, entregan prestigio a aquellos trabajos que siguen los estándares de publicación y son indexadas en las revistas de gran renombre. En suma, generan un sistema restrictivo donde existe poca representatividad de las revistas de ciencias sociales. Según Beigel (2018), las bases de datos comerciales no solo contribuyeron en la ilusión de una ciencia del centro, sino que también desarrollaron la idea de un tipo de ciencia Periférica, que refiere al trabajo que se reclusa en el terreno de la academia regional-local (como es el caso Latinoamericano). Este tipo de ciencia se indexa en revistas subvaloradas y comprendidas como endogámicas y de baja calidad, pues en su gran mayoría producen y re-producen el conocimiento dentro de la propia región, teniendo así un rol subsidiario en el desarrollo de la ciencia y no protagónico como es el caso anterior. La apuesta del Open Access de hacer frente al oligopolio de la industria editorial y lograr un cambio sociocultural en la ciencia a menudo tiene que luchar con condiciones sociales, culturales y económicas que terminan modelando la forma en que los cambios tecnológicos se convierten en cambios sociales. Por ello el Open Access es un proceso diferencial no solo entre las disciplinas, sino que también entre las zonas geográficas y las distintas regiones del mundo (Sadaba, 2014). La globalización y el auge de Internet por sí mismos no democratizan ni permiten la distribución equitativa del conocimiento, por ello es importante adscribir a las palabras de Babini (2014), coordinadora del programa de acceso abierto de CLACSO, quien hace un llamado a la comunidad científica de tomar responsabilidad por gestionar comunicaciones académicas no comerciales, cuyo objetivo sea permitir que el conocimiento se convierta en un bien público y, por lo tanto, se gestione como tal. La experiencia latinoamericana ha logrado arribar en el puerto de la ruta verde de una forma similar al contexto anglosajón, en el estudio de Piwowar et al. (2019) se evidencia que tanto en ciencias sociales como en psicología se utiliza mayoritariamente la ruta verde para la publicación abierta (véase Figura N° 5.7). Para el caso Latinoamericano, se ha creado una estructura no comercial donde la publicación libre es manejada por institutos de investigación sin fines de lucro o por universidades estatales, dando forma a un ecosistema sustentado por Open Journals Systems (Sistema de Revistas Abiertas en español), un software libre que entrega herramientas para la administración de plataformas digitales como Latindex, Redalyc y Scielo, los principales exponentes del Open Access en la región según Becerril García &amp; Aguado López (2019). Estas plataformas sirvieron de trampolín para el desarrollo de la ciencia abierta de tipo no comercial, una distinción propia de Latinoamérica (Beigel, 2021). Figura 5.7: Piwowar, H. et al. (2019). Porcentaje de diferentes tipos de acceso de una muestra aleatoria de artículos y reseñas de WoS con un DOI publicado entre 2009 y 2015 por disciplina (Traducción propia). Algunas personas ligaran de manera exclusiva el Open Acces a metodologías de carácter cuantitativo, desconfiando del uso de estas técnicas para la investigación cualitativa con el temor de la pérdida de confidencialidad o el reproche sobre la toma de decisiones metodológicas. La evidencia levantada por Mardones et al. (2018) demuestra que existen experiencias cualitativas de trabajos publicados en abierto que no tienen repercusiones negativas, aún cuando estos declaran y describen sus diseños. Ello demuestra que la publicación abierta no afecta la particularidad y flexibilidad del diseño, siempre y cuando este se dirija con el fin de develar el fenómeno de estudio. Taylor (2020) realizó un análisis sistemático de la publicación en abierto de libros y capítulos en el área de las ciencias sociales, pues ha habido una falta de atención en la publicación de libros en abierto, muy por el contrario al análisis que se realiza casi por completo a artículos y revistas. Este estudio comprende la existencia de un gran número de científicos sociales que se abocan a publicar en libros y, dentro de los resultados de la investigación, se evidencia que el número de libros y capítulos publicados en acceso abierto es mucho más bajo que el de los artículos. Sin embargo, a través de los años ha ido en un ligero incremento, siendo estos en su gran mayoría de las disciplinas de la psicología y la economía, y en último lugar, textos del área de la filosofía. Lo anterior no solo evidencia un auge constante de la publicación de libros y capítulos en abierto, también da cuenta de que al igual que en el panorama general, dentro de las humanidades y las ciencias sociales ocurre una dicotomía entre las disciplinas. Las revistas académicas y los repositorios antes mencionados son administrados, dirigidos y financiados por instituciones académicas o por organismos no gubernamentales sin fines de lucro -como es el caso del Centro Latinoamericano de Ciencias Sociales (CLACSO)-, por lo que no se incluyen tarifas ni para autores ni para lectores. América Latina ha desarrollado una suerte de ecosistema en red, que se configura cómo un espacio virtual donde los miembros de las universidades ponen a disposición el contenido intelectual en repositorios de sus casas de estudio, los cuales a su vez se encuentran interconectados a otros repositorios académicos. Un ejemplo claro de ello es LaReferencia que integra más de 1.3 millones de archivos según Becerril García &amp; Aguado López (2019). En términos de políticas públicas, los organismos estatales han desarrollado leyes que promueven el uso de prácticas abiertas en el desarrollo de investigaciones con fondos estatales, sin embargo, por lo que señala Becerril García &amp; Aguado López (2019), los mandatos tienden a ser aún muy débiles y operan como sugerencias más que como obligaciones metodológicas. Otra debilidad indicada por el mismo estudio da cuenta de que la mayoría de los sistemas de validación social de las investigaciones descansan en el renombre de la revista, aún cuando estas se encuentren lejos de las discusiones locales o bien ajenas a los contextos latinoamericanos. El destino de las ciencias sociales en el mundo del Open Access es bastante amplio. Los beneficios que entrega este paradigma no solo contribuyen a la difusión y amplio reconocimiento de la obra y de su autoría, también aportan a la apertura del conocimiento científico que sirve a nivel local en la toma de decisiones, en la consecución de estrategias políticas y a nivel regional en tanto aporta al desarrollo cultural y económico de la sociedad en su conjunto. Sin duda, el camino que han trazado otras personas sigue su curso e invita no solo a investigadores a incurrir en este tipo de prácticas, sino que también pone la responsabilidad en las instituciones universitarias y gubernamentales en proporcionar las herramientas, guías y conocimientos necesarios para que el Open Access sea una alternativa viable por la cual la ciencia y el conocimiento se transformen. Referencias "],["referencias.html", "Referencias", " Referencias "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
